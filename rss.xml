<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"
    xmlns:dc="http://purl.org/dc/elements/1.1/">
    <channel>
        <title>The Art Gallery Guardian</title>
        <link>https://chaoxuprime.com</link>
        <description><![CDATA[Mostly notes on algorithms]]></description>
        <atom:link href="https://chaoxuprime.com/rss.xml" rel="self"
                   type="application/rss+xml" />
        <lastBuildDate>Thu, 28 Mar 2019 00:00:00 UT</lastBuildDate>
        <item>
    <title><span class="math inline">L_1</span> linear regression</title>
    <link>https://chaoxuprime.com/posts/2019-03-28-l1-linear-regression.html</link>
    <description><![CDATA[<br />
<div>
<p>I read an article on the <a href="https://medium.economist.com/mistakes-weve-drawn-a-few-8cdd8a42d368">errors in visualization</a>. The example of forcing a relationship by cherry-picking scales is delightful. I recommend reading it.</p>
<p>I am interested in misleading people while being completely honest. The article inspires the following problem. Given 2 vectors <span class="math inline">\bm{x},\bm{y}\in \R^n</span>. Let <span class="math inline">\bm{1}</span> be the all <span class="math inline">1</span> vector in <span class="math inline">\R^n</span>. We are interested in finding <span class="math inline">a,b\in \R</span>, such that <span class="math inline">\|\bm{y}-(a\bm{x}+b\bm{1})\|_p</span> is minimized. Here <span class="math inline">p</span> is either <span class="math inline">1,2</span> or <span class="math inline">\infty</span>.</p>
<p>Note the problem is precisely the same as the linear regression problem. In the linear regression problem, we are given a point set <span class="math inline">S\subset \R^2</span> of size <span class="math inline">n</span> and we are interested in find a line <span class="math inline">f(x) = ax+b</span>, such that it minimizes the <em>error</em>, defined as</p>
<p><span class="math display">\displaystyle 
\sum_{(x,y)\in S} |y - f(x)\|_p
</span></p>
<p>For <span class="math inline">p=2</span>, there is a <span class="math inline">O(n)</span> time algorithm because there is a closed formula. For <span class="math inline">p=\infty</span>, the problem can be rewritten as a linear program with <span class="math inline">3</span> variables and <span class="math inline">n</span> constraints. Using Megiddo's result <span class="citation" data-cites="Megiddo84">[<a href="#ref-Megiddo84">1</a>]</span>, there is a <span class="math inline">O(n)</span> time algorithm to solve this problem.</p>
<p>It is hard to find the worst case complexity when <span class="math inline">p=1</span>. This case is called the <em>least absolute deviations</em>. Statisticians just don't care about worst case running time as CS people do.</p>
<p>There are a few methods I found. One is to write it as a linear program on <span class="math inline">n+2</span> variables and <span class="math inline">n</span> constraints and solve it using the simplex method. There are a bunch of other algorithms that specializes the simplex algorithm on this particular problem. There are also some iterative methods. Unfortunately, those algorithms depends on the actual numbers in the input. I want a running time that only depends on <span class="math inline">n</span>.</p>
<p>There exists an optimal solution that contains two points in <span class="math inline">S</span>. The native algorithm is to try all possible <span class="math inline">O(n^2)</span> lines. For each line, the algorithm can compute the error in <span class="math inline">O(n)</span> time. The naive algorithm's running time is <span class="math inline">O(n^3)</span>. There is a smarter algorithm. The optimal line that contains the point can actually be found in <span class="math inline">O(n)</span> time. Indeed, consider the line passes through the point <span class="math inline">(x,y)</span>. We consider changing the slope of the line, while maintaining it still contain <span class="math inline">(x,y)</span>. One can see a minimum will be reached at some line. Indeed, assume we reorder the points, so <span class="math inline">\frac{y_i-y}{x_i-x}\leq \frac{y_{i+1}-y}{x_{i+1}-x}</span> (namely, increasing slope). Let <span class="math inline">k</span> be the smallest integer such that the sum of <span class="math inline">\sum_{i=1}^k |x_i-x|\geq \sum_{i=k+1}^n |x_i-x|</span>. The line determined by <span class="math inline">(x,y)</span> and <span class="math inline">(x_k,y_k)</span> is the desired line. This can be computed in linear time by finding weighted median. Hence one can show the running time is <span class="math inline">O(n^2)</span>. This is the idea of <span class="citation" data-cites="BloomfieldS80">[<a href="#ref-BloomfieldS80">2</a>]</span>. As far as I know, this seems to be the state of the art in terms of worst case complexity.</p>
<p>After discussing with <a href="https://sites.google.com/site/qizhenghe96/home">Qizheng He</a>, he suggested the following approach. Consider the function <span class="math inline">g_p(s)</span> for <span class="math inline">p\in S</span>. It is defined as the error for the line of slope <span class="math inline">s</span> that contains <span class="math inline">p</span>. The function is bitonic, therefore we can do a ternary search to find the minimum. There are only <span class="math inline">n-1</span> possible slopes, hence the ternary search will take <span class="math inline">O(\log n)</span> queries, where each query asks for the error of the line that goes through <span class="math inline">p</span> and some other point.</p>
<p>Given a line <span class="math inline">f(x)=ax+b</span>, can one compute the error quickly? It is possible to decompose it to few halfspace range counting queries (allowing weights). In halfspace counting queries problem, we are given <span class="math inline">n</span> points with weights, we can preprocess it and obtain a data structure. Each query to a data structure is a halfspace, the output is the sum of all elements in the halfspace. In <span class="math inline">2</span>D, there exists a preprocessing time <span class="math inline">\tilde{O}(n^{4/3})</span> and query time <span class="math inline">\tilde{O}(n^{1/3})</span> data structure <span class="citation" data-cites="Matousek93">[<a href="#ref-Matousek93">3</a>]</span>. Let <span class="math inline">S^+</span> be the set of points above <span class="math inline">f</span>, and <span class="math inline">S^-</span> be the set of points below <span class="math inline">f</span>. The result is precisely the following.</p>
<p><span class="math display">\displaystyle 
\sum_{(x,y)\in S^+} y - ax-b + \sum_{(x,y)\in S^-} ax+b - y
</span></p>
<p>Let's consider the second sum, <span class="math inline">\sum_{(x,y)\in S^-} ax+b - y = a\sum_{(x,y)\in S^-}x + |S^-|b -\sum_{(x,y)\in S^-}y</span>. Note the <span class="math inline">3</span> terms can each be solved with a halfspace counting query, consider all points lies below <span class="math inline">f</span>. This shows in <span class="math inline">6</span> halfspace counting queries.</p>
<p>How can one do ternary search? This would need us to be able to pick the point that gives us the <span class="math inline">i</span>th largest slope with <span class="math inline">p</span>. We need a data structure such that it can return the <span class="math inline">i</span>th largest point in the radial ordering of the points in <span class="math inline">S</span> around <span class="math inline">p</span>. It is equivalent to <a href="https://cstheory.stackexchange.com/questions/42609/data-structure-for-radial-orderings-of-points-on-the-plane">halfspace range counting up to polylog factors</a>.</p>
<p>Thus, the total running time after building the data structure in <span class="math inline">\tilde{O}(n^{4/3})</span> is <span class="math inline">n</span> times ternary search over <span class="math inline">n</span> elements, where each decision process takes <span class="math inline">\tilde{O}(n^{1/3})</span> time. Therefore the final running time is <span class="math inline">\tilde{O}(n^{4/3})</span> time.</p>
<h1 id="bibliography" class="unnumbered">References</h1>
<div id="refs" class="references">
<div id="ref-Megiddo84">
<p>[1] N. Megiddo, <strong>Linear programming in linear time when the dimension is fixed</strong>, J. ACM. 31 (1984) 114–127 <a href="https://doi.org/10.1145/2422.322418">10.1145/2422.322418</a>.</p>
</div>
<div id="ref-BloomfieldS80">
<p>[2] P. Bloomfield, W. Steiger, <strong>Least absolute deviations curve-fitting</strong>, SIAM Journal on Scientific and Statistical Computing. 1 (1980) 290–301 <a href="https://doi.org/10.1137/0901019">10.1137/0901019</a>.</p>
</div>
<div id="ref-Matousek93">
<p>[3] J. Matoušek, <strong>Range searching with efficient hierarchical cuttings</strong>, Discrete &amp; Computational Geometry. 10 (1993) 157–182 <a href="https://doi.org/10.1007/BF02573972">10.1007/BF02573972</a>.</p>
</div>
</div>

</div>
<div class="hide-on-print">
    <div class="info">Posted by <a href="https://chaoxuprime.com">Chao Xu</a> on 2019-03-28. </div>
    <div class="info">Tags: combinatorial optimization.</div>

</div>]]></description>
    <pubDate>Thu, 28 Mar 2019 00:00:00 UT</pubDate>
    <guid>https://chaoxuprime.com/posts/2019-03-28-l1-linear-regression.html</guid>
    <dc:creator>Chao Xu</dc:creator>
</item>
<item>
    <title>Densest subgraph variation</title>
    <link>https://chaoxuprime.com/posts/2019-03-24-densest-subgraph-variation.html</link>
    <description><![CDATA[<br />
<div>
<p>Let <span class="math inline">G=(V,E)</span> be a graph. Consider an edge weight function <span class="math inline">w:E\to \R^+</span> and a vertex cost function <span class="math inline">c:V\to \R^+</span>.</p>
<p>We are interested in finding <span class="math inline">S\subset V</span>, such that <span class="math inline">w(E(S))-c(S)</span> is maximized.</p>
<p>This is very close to the densest subgraph problem, as it is basically the Lagrangian relaxation of the problem.</p>
<p>This problem is equivalent to a min-<span class="math inline">st</span>-cut computation on a suitable graph. Indeed, minimizing <span class="math inline">w(E(S))-c(S)</span> is equivalent to minimizing <span class="math inline">c(S) + \frac{1}{2} w(E(S,\bar{S})) + \frac{1}{2} \sum_{v\in \bar{S}} \deg(v)</span>. This can be solved easily by modeling it as a min-<span class="math inline">st</span>-cut.</p>

</div>
<div class="hide-on-print">
    <div class="info">Posted by <a href="https://chaoxuprime.com">Chao Xu</a> on 2019-03-24. </div>
    <div class="info">Tags: combinatorial optimization.</div>

</div>]]></description>
    <pubDate>Sun, 24 Mar 2019 00:00:00 UT</pubDate>
    <guid>https://chaoxuprime.com/posts/2019-03-24-densest-subgraph-variation.html</guid>
    <dc:creator>Chao Xu</dc:creator>
</item>
<item>
    <title>Finger tree allowing apply functions to each element</title>
    <link>https://chaoxuprime.com/posts/2019-03-10-finger-tree-apply-function-to-each-element.html</link>
    <description><![CDATA[<br />
<div>
<p>Let <span class="math inline">(M,+)</span> be a monoid. We are interested in maintaining a sequence <span class="math inline">a = a_1,\ldots,a_n\in M</span> under all updates currently supported by finger tree. However, we are also interested in adding another update, which we call the function update.</p>
<p>Let <span class="math inline">f = f_1,\ldots,f_n\in M\to M</span>.</p>
<p>The functions satisfies the following property.</p>
<p><span class="math inline">f_1(x_1)+\ldots+f_n(x_n) = f_1(y_1)+\ldots+f_n(y_n)</span> if <span class="math inline">\sum_{i=1}^n x_i = \sum_{i=1}^n y_i</span>.</p>
<p>The sequence <span class="math inline">f</span> is given implicitly, where it has two methods:</p>
<ul>
<li><code>evaluate(X)</code>: It returns <span class="math inline">f_1(x_1) + \ldots +f_n(x_n)</span> for any sequence <span class="math inline">x_1,\ldots,x_n</span> such that <span class="math inline">\sum_{i=1}^n x_i = X</span>.</li>
<li><code>split(j)</code>: returns a representation for <span class="math inline">f_1,\ldots,f_j</span> and <span class="math inline">f_{j+1},\ldots,f_n</span>.</li>
</ul>
<p>We are interested in implementing <code>FunctionUpdate(a,f)</code>, the output would be a representation of the sequence <span class="math inline">f_1(a_1),\ldots,f_n(a_n)</span>.</p>
<p>Many problems actually require update to a entire interval of the sequence, which makes this extremely valuable. For example, consider the following simple problem.</p>
<p>Maintain a sequence of integers <span class="math inline">a_1,\ldots,a_n</span>, such that we can do the operation <span class="math inline">inc(i,j)</span>, which increment all numbers from <span class="math inline">i</span>th to <span class="math inline">j</span>th index by <span class="math inline">1</span>. That is, the new sequence is <span class="math inline">a_1,\ldots,a_{i-1},a_i+1,\ldots,a_j+1,a_{j+1},\ldots,a_n</span>. Also, it has a function <span class="math inline">value(i)</span> which returns <span class="math inline">a_i</span>. This problem can be solved by finger tree with function update operation.</p>
<p>I want an actual implementation of such data structure so I can implement the min-cost flow algorithm for series-parallel graphs <span class="citation" data-cites="Booth1993416">[<a href="#ref-Booth1993416">1</a>]</span>.</p>
<h1 id="bibliography" class="unnumbered">References</h1>
<div id="refs" class="references">
<div id="ref-Booth1993416">
<p>[1] H. Booth, R. Tarjan, <strong>Finding the minimum-cost maximum flow in a series-parallel network</strong>, Journal of Algorithms. 15 (1993) 416–446 <a href="https://doi.org/10.1006/jagm.1993.1048">10.1006/jagm.1993.1048</a>.</p>
</div>
</div>

</div>
<div class="hide-on-print">
    <div class="info">Posted by <a href="https://chaoxuprime.com">Chao Xu</a> on 2019-03-10. </div>
    <div class="info">Tags: data structure, lazy propagation.</div>

</div>]]></description>
    <pubDate>Sun, 10 Mar 2019 00:00:00 UT</pubDate>
    <guid>https://chaoxuprime.com/posts/2019-03-10-finger-tree-apply-function-to-each-element.html</guid>
    <dc:creator>Chao Xu</dc:creator>
</item>
<item>
    <title>Find the period of a nice eventually periodic sequence</title>
    <link>https://chaoxuprime.com/posts/2019-02-05-eventually-periodic.html</link>
    <description><![CDATA[<br />
<div>
<p>A sequence is periodic if <span class="math inline">s_i = s_{i+p}</span> for all <span class="math inline">i</span>, where <span class="math inline">p&gt;0</span> is called a period. A sequence is eventually periodic if there exists a <span class="math inline">n</span> and <span class="math inline">p</span>, such that <span class="math inline">s_i = s_{i+p}</span> for all <span class="math inline">i&gt;n</span>. The sequence with index above <span class="math inline">n</span> is the <em>periodic part</em>.</p>
<p>A sequence is called <em><span class="math inline">u</span>-normal</em>, if there exists <span class="math inline">s_i=s_{i+p}</span> for some <span class="math inline">p&gt;0</span> for all <span class="math inline">i</span> in a interval of length <span class="math inline">u</span>, then the sequence starting at <span class="math inline">s_i</span> is part of the periodic part.</p>
<p>When does <span class="math inline">u</span>-normal sequence comes up? Consider we have a recurrence relation that produces a sequence. Say it is of the form <span class="math inline">a_n = f(a_{n-1},a_{n-2},\ldots,a_{n-u})</span>. The sequence <span class="math inline">a_1,\ldots</span> is <span class="math inline">u</span>-normal.</p>
<section class="theorem-environment Problem" id="Problem-1">
<span class="theorem-header"><span class="type">Problem</span><span class="index">1</span></span>
<p>Given a oracle that can take input <span class="math inline">i</span> and return the <span class="math inline">i</span>th element in a <span class="math inline">u</span>-normal eventually periodic sequence <span class="math inline">a</span>. Find the smallest lexicographic pair <span class="math inline">(n,p)</span> where <span class="math inline">p&gt;0</span>, such that <span class="math inline">a_i=a_{i+p}</span> for all <span class="math inline">i&gt;n</span>.</p>
</section>
<p>One can solve this problem in <span class="math inline">O(u \log \frac{n}{u})</span> time. First, consider the subsequence <span class="math inline">a_u,a_{2u},\ldots</span>. We guess an upper bound on <span class="math inline">n</span> through exponential search in the subsequence. There is a <span class="math inline">O(u)</span> time algorithm to decide if <span class="math inline">n&#39;\geq n</span>. For example using the <a href="https://en.wikipedia.org/wiki/Knuth%E2%80%93Morris%E2%80%93Pratt_algorithm">KMP algorithm</a>. We can quickly locate a <span class="math inline">n&#39;</span> such that <span class="math inline">n\in [n&#39;-u,n&#39;]</span>.</p>
<p>Let's take the sequence <span class="math inline">a_{n&#39;-u},\ldots,a_{n&#39;+3u}</span>. We just need to solve the following problem. Given a <span class="math inline">O(u)</span> length string, find the longest suffix that appears at least twice in the sequence. Let such suffix be <span class="math inline">s</span>. We know <span class="math inline">|s|\geq 3u</span>, which <span class="math inline">s</span> has to overlap with any other occurrence of the sequence. The claim is that the partial match table in the KMP algorithm would give us such information. Hence we can obtain <span class="math inline">n</span>. <span class="math inline">p</span> can also be obtained in the same time. Note that KMP algorithm only uses the fact one can check equality of two elements. So the sequence can contain elements from very general space.</p>
<p>The total running time is <span class="math inline">O(\log \frac{n}{u})</span> calls to <span class="math inline">O(u)</span> time string matching. The total running time is therefore <span class="math inline">O(u\log \frac{n}{u})</span>.</p>
<p>In many applications, we do not get oracle access to <span class="math inline">i</span>th index of the sequence. But we can read the sequence from the beginning as a list. In that case, we don't do binary search, but linear search. Advance the index by <span class="math inline">u</span> and obtain <span class="math inline">n&#39;</span>, and test if <span class="math inline">n</span> is no larger than the current point. If so, again we have <span class="math inline">n\in [n&#39;-u,n&#39;]</span> and reduce to the previous problem. If not, advance the index by <span class="math inline">u</span> again and repeat. This gives us a <span class="math inline">O(n+u)</span> time algorithm.</p>

</div>
<div class="hide-on-print">
    <div class="info">Posted by <a href="https://chaoxuprime.com">Chao Xu</a> on 2019-02-05. </div>
    <div class="info">Tags: algorithms, infinite sequence.</div>

</div>]]></description>
    <pubDate>Tue, 05 Feb 2019 00:00:00 UT</pubDate>
    <guid>https://chaoxuprime.com/posts/2019-02-05-eventually-periodic.html</guid>
    <dc:creator>Chao Xu</dc:creator>
</item>
<item>
    <title>Bottleneck <span class="math inline">k</span>-link path</title>
    <link>https://chaoxuprime.com/posts/2019-01-31-bottleneck-k-link-path.html</link>
    <description><![CDATA[<br />
<div>
<p>A DAG is called complete, if there are vertices <span class="math inline">v_1,\ldots,v_n</span>, and <span class="math inline">v_iv_j</span> is an edge if and only if <span class="math inline">i&lt;j</span>. Let <span class="math inline">w(i,j)</span> be the edge weights from <span class="math inline">i</span> to <span class="math inline">j</span>. The weight is called ordered, if <span class="math inline">w(i,j)&lt;w(i,j+1)</span> and <span class="math inline">w(i+ 1,j)&lt;w(i,j)</span>.</p>
<section class="theorem-environment Problem" id="Problem-1">
<span class="theorem-header"><span class="type">Problem</span><span class="index">1</span><span class="name">Bottleneck <span class="math inline">k</span>-link path problem</span></span>
<p>Find a path consists of <span class="math inline">k</span> edges from <span class="math inline">v_1</span> to <span class="math inline">v_n</span>, such that the maximum weight of the edges in the path is minimized.</p>
</section>
<p>One can formulate a dynamic programming algorithm, which takes <span class="math inline">O(kn^2)</span> time. My <a href="https://chaoxuprime.com/posts/2013-08-16-more-algorithms-on-perfectly-balanced-photo-gallery.html">previous writing</a> shows an <span class="math inline">O(kn)</span> time algorithm using the monge property. Using binary search, there is also an <span class="math inline">O(k\log(n/k)\log M)</span> time algorithm if all weights are positive integers no larger than <span class="math inline">M</span>.</p>
<p>We show there is an <span class="math inline">O(n+k\log(n/k)\log n)</span> time algorithm. Assume <span class="math inline">\lambda^*</span> is the optimal weight. First, there is an oracle that given <span class="math inline">\lambda</span>, decides if <span class="math inline">\lambda\geq \lambda^*</span>. Indeed, we can apply the greedy algorithm. Find the sequence <span class="math inline">a_1,\ldots,a_k</span>, as follows. <span class="math inline">a_0=1</span>, <span class="math inline">a_i</span> is the largest value such that <span class="math inline">w(a_{i-1},a_i)\leq \lambda</span>. If <span class="math inline">a_k=n</span>, then it is clear that <span class="math inline">\lambda \geq \lambda^*</span>. Also, we can show if <span class="math inline">a_k&lt;n</span>, then <span class="math inline">\lambda &lt; \lambda^*</span>. <span class="math inline">O(n)</span> time seems to be a quite large bound. We could do it in <span class="math inline">O(k\log (n))</span> instead by doing binary search for each <span class="math inline">a_i</span>. Using <a href="https://en.wikipedia.org/wiki/Exponential_search">exponential search</a> instead, we can obtain a <span class="math inline">O(k\log(n/k))</span> time algorithm.</p>
<p>One need to do binary search for <span class="math inline">\lambda^*</span>. There are <span class="math inline">\Omega(n^2)</span> weights, let it be <span class="math inline">W</span>. One does not have to know all of them in order to apply binary search. Note that <span class="math inline">w</span> is a matrix sorted in both row and column, hence we need a selection algorithm that returns the <span class="math inline">k</span>th smallest element for such matrix. There is an <a href="https://chaoxuprime.com/posts/2014-04-02-selection-in-a-sorted-matrix.html"><span class="math inline">O(n)</span> time algorithm</a> for that. Hence we can do binary search on the sorted <span class="math inline">W</span> by spending <span class="math inline">O(n)</span> time to access <span class="math inline">i</span>th element. We now obtain a <span class="math inline">O((n+ k\log(n/k)) \log n) = O(n\log n)</span> time algorithm. Not bad.</p>
<p>We can speed it up even further. Instead of selection in the sorted matrix, we can do <a href="https://chaoxuprime.com/posts/2019-01-30-search-sorted-matrixhtml">search in the sorted matrix</a>. We are given an oracle to test if a value is smaller than <span class="math inline">\lambda^*</span> after all. We can do search for <span class="math inline">\lambda^*</span> using <span class="math inline">O(\log n)</span> oracle calls and <span class="math inline">O(n)</span> time. Hence this gives us a <span class="math inline">O(n+k\log (n/k) \log n)</span> time algorithm for the problem. Whenever <span class="math inline">k=O(\frac{n}{\log(n) \log \log n})</span>, this is <span class="math inline">O(n)</span> time.</p>
<p>As an application, we obtain a solution to <a href="https://leetcode.com/problems/split-array-largest-sum/">Leetcode 410 Split Array Largest Sum</a>. The problem is also called the <em>linear partitioning</em> problem. The problem asks one to partition array into <span class="math inline">k</span> contagious subarrays that minimizes the maximum sum of each subarray. It was an example for learning dynamic programming in chapter 8.5 of <span class="citation" data-cites="Skiena10book">[<a href="#ref-Skiena10book">1</a>]</span>. An <span class="math inline">O(kn^2)</span> algorithm was given. Reading the discussion online, one would find <span class="math inline">O(n\log M)</span> time algorithm is the suggested solution, where <span class="math inline">M</span> is the maximum over all integers. The algorithm is actually fairly useful for photo galleries. There is the <a href="https://www.npmjs.com/package/linear-partitioning">NPM package <code>linear-partitioning</code></a>, used by multiple photo galleries packages. My <a href="https://chaoxuprime.com/posts/2013-08-16-more-algorithms-on-perfectly-balanced-photo-gallery.html">first encountered of the problem</a> was also for photo gallery. The linear partition problem reduces to the bottleneck <span class="math inline">k</span>-link path problem because we can define <span class="math inline">w(i,j)</span> to be the sum of elements from the <span class="math inline">i</span>th index of the array to the <span class="math inline">j</span>th index of the array. After <span class="math inline">O(n)</span> preprocessing, <span class="math inline">w(i,j)</span> can be computed in <span class="math inline">O(1)</span> time. This results a <span class="math inline">O(n+k\log (n/k) \log n)</span> running time algorithm.</p>
<p>What about when <span class="math inline">k</span> is large? I've emailed <a href="https://samsonzhou.github.io/">Samson Zhou</a>, who has confirmed the algorithm in <span class="citation" data-cites="FredericksonZ17">[<a href="#ref-FredericksonZ17">2</a>]</span> can be used to solve the problem in <span class="math inline">O(n)</span> time.</p>
<h1 id="bibliography" class="unnumbered">References</h1>
<div id="refs" class="references">
<div id="ref-Skiena10book">
<p>[1] S.S. Skiena, <strong>The algorithm design manual</strong>, Springer, 2010.</p>
</div>
<div id="ref-FredericksonZ17">
<p>[2] G.N. Frederickson, S. Zhou, <strong>Optimal parametric search for path and tree partitioning</strong>, CoRR. abs/1711.00599 (2017).</p>
</div>
</div>

</div>
<div class="hide-on-print">
    <div class="info">Posted by <a href="https://chaoxuprime.com">Chao Xu</a> on 2019-01-31. </div>
    <div class="info">Tags: algorithm, data structure.</div>

</div>]]></description>
    <pubDate>Thu, 31 Jan 2019 00:00:00 UT</pubDate>
    <guid>https://chaoxuprime.com/posts/2019-01-31-bottleneck-k-link-path.html</guid>
    <dc:creator>Chao Xu</dc:creator>
</item>
<item>
    <title>Search in a sorted matrix with an oracle</title>
    <link>https://chaoxuprime.com/posts/2019-01-30-search-sorted-matrix.html</link>
    <description><![CDATA[<br />
<div>
<p>Consider a infinite matrix <span class="math inline">M</span>. Another way to think about it is a function <span class="math inline">f:\N\to \N\to X</span>. A matrix <span class="math inline">M</span> is sorted if <span class="math inline">M_{i,j}\leq M_{i,j+1}</span> and <span class="math inline">M_{i,j}\leq M_{i+1,j}</span>.</p>
<section class="theorem-environment Problem" id="Problem-1">
<span class="theorem-header"><span class="type">Problem</span><span class="index">1</span></span>
<p>Given a sorted matrix <span class="math inline">M</span>, and an oracle that takes <span class="math inline">\lambda</span> returns if a value is <span class="math inline">\lambda &lt;\lambda^*</span> or <span class="math inline">\lambda \geq \lambda^*</span>. Find the largest value no larger than <span class="math inline">\lambda^*</span>.</p>
</section>
<p>Assuming there are at most <span class="math inline">k</span> elements no larger than <span class="math inline">\lambda^*</span>, and we know the smallest <span class="math inline">n</span> and <span class="math inline">m</span> such that <span class="math inline">M_{i,j}&gt;\lambda^*</span> if <span class="math inline">i&gt;n</span> or <span class="math inline">j&gt;m</span>. Also, let <span class="math inline">t</span> be the smallest number such that <span class="math inline">M_{t,t}&gt;\lambda^*</span>. One can see that <span class="math inline">t\leq \min(n,m)</span> and <span class="math inline">k=O(\max(n,m)^2)</span>.</p>
<p>Let's first consider the case when <span class="math inline">n</span> and <span class="math inline">m</span> is known and <span class="math inline">n\leq m</span>. It is <a href="https://leetcode.com/problems/search-a-2d-matrix-ii/">Leetcode 240. Search a 2D Matrix II</a>. However, our problem is more general, because comparison with <span class="math inline">\lambda^*</span> can only be done through the oracle. Craig Gidney wrote about an <a href="http://twistedoakstudios.com/blog/Post5365_searching-a-sorted-matrix-faster">optimal algorithm</a> with <span class="math inline">O(n\log \frac{m}{n})</span> running time, matrix access algorithm. However, the oracle access is too large. There are times where the oracle access is slow. For example, when using it as a subroutine for finding a <a href="https://chaoxuprime.com/posts/2019-01-31-bottleneck-k-link-path.html">bottleneck <span class="math inline">k</span>-link path</a>. There is an algorithm with optimal running time and <span class="math inline">O(\log(nm))</span> oracle access.</p>
<p>Let's consider a special case, where <span class="math inline">n=m=2^i</span> for some <span class="math inline">i</span>. This case was shown in <span class="citation" data-cites="FredericksonZ17">[<a href="#ref-FredericksonZ17">1</a>]</span>. For each submatrix, the two vertices on the opposite diagonal indicates the largest and smallest element in the submatrix. Hence each matrix can be represented by two numbers, indicate the maximum and minimum. These numbers are called the representative of the matrix. The idea is we keep two numbers <span class="math inline">\lambda_1</span> and <span class="math inline">\lambda_2</span>, such that we know <span class="math inline">\lambda^*\in [\lambda_1,\lambda_2]</span>. The algorithm keep partition the matrix into small matrices, updating <span class="math inline">\lambda_1</span> and <span class="math inline">\lambda_2</span>, and discard matrices outside the range. We apply the following algorithm. Let <span class="math inline">R</span> consists of the multiset of representatives of the matrix, and <span class="math inline">R&#39;</span> be the representatives that lies inside <span class="math inline">[\lambda_1,\lambda_2]</span>. We find <span class="math inline">\lambda</span>, the median of <span class="math inline">R&#39;</span>. Test if <span class="math inline">\lambda&lt;\lambda^*</span>. If so, then <span class="math inline">\lambda_1</span> updates to <span class="math inline">\lambda</span>, otherwise <span class="math inline">\lambda_2</span> updates to <span class="math inline">\lambda</span>. This step is done twice. Now, we split the matrices with more than one element into <span class="math inline">4</span> equally sized matrices, and repeat the algorithm. Recall at all times, the matrices does not contain any element in <span class="math inline">[\lambda_1,\lambda_2]</span> are discarded.</p>
<p>There is at most <span class="math inline">O(\log n)</span> iterations before range shrinks to a single element, hence at most <span class="math inline">O(\log n)</span> oracle calls. The difficulty is to show that the overall time is only <span class="math inline">O(n)</span>. Intuitively, in each iteration we quadruple the number of matrices, but we half it by two calls to the oracle. Therefore in <span class="math inline">\log n</span> steps we obtain roughly <span class="math inline">2^{\log n}=O(n)</span> matrices. However, at this point, the matrices are all singletons, and no more matrix can be created. We will only decrease the number of matrices by each oracle call. Careful reader can trace the whole argument in Lemma 2.1 of <span class="citation" data-cites="FredericksonZ17">[<a href="#ref-FredericksonZ17">1</a>]</span>.</p>
<p>For the more general case, one can find the proof in <span class="citation" data-cites="FredericksonJ84">[<a href="#ref-FredericksonJ84">2</a>]</span>. Note the proof is for selection, but one can easily modify it to work for search.</p>
<p>Now, <span class="math inline">n</span> and <span class="math inline">m</span> is not known, but we can quickly using exponential search to find it. Indeed, we just have to apply exponential search in the first row and first column using the oracle. This gives us an extra <span class="math inline">O(\log n + \log m)=O(\log nm)</span> oracle calls.</p>
<p>Let <span class="math inline">k</span> to be the number of elements no larger than <span class="math inline">\lambda^*</span>. We can get running time relative to <span class="math inline">k</span>. Use exponential search until we find the first <span class="math inline">i</span> such that <span class="math inline">M_{2^i,2^i}&gt;\lambda^*</span>. So we can upper bound <span class="math inline">t</span>. Then one can solve the problem with <span class="math inline">2</span> matrices. One <span class="math inline">t\times k</span> matrix and a <span class="math inline">k\times t</span> matrix. The total running time is therefore <span class="math inline">O(\log k+t\log k/t)=O(t\log k)</span>. In fact, we get <span class="math inline">O(\log k)</span> oracle calls and <span class="math inline">O(t\log k)</span> running time. Here we can take <span class="math inline">t</span> to be <span class="math inline">\sqrt{k}</span>, and obtain <span class="math inline">O(\sqrt{k}\log k)</span> time.</p>
<p>Note if we relax on number of oracle calls. I know how to get a <span class="math inline">O(\sqrt{k})</span> running time.</p>
<section class="theorem-environment Theorem" id="Theorem-2">
<span class="theorem-header"><span class="type">Theorem</span><span class="index">2</span></span>
<p>Given <span class="math inline">\lambda^*</span> and a <span class="math inline">n\times m</span> sorted matrix such that the <span class="math inline">i</span>th row has <span class="math inline">k_i</span> elements no larger than <span class="math inline">x</span>. Let <span class="math inline">k=\sum_{i} k_i</span>. We can find <span class="math inline">\lambda^*</span> in <span class="math inline">O(\sum_{i} \log (k_{i+1}-k_i+1) ) = O(n \log \frac{k}{n^2})</span> time.</p>
</section>
<p>The idea is simple, we do exponential search on each row to find the largest element no larger than <span class="math inline">\lambda^*</span>, but we reuse information from the previous row. This gives us the running time <span class="math inline">O(\sum_{i} \log (k_{i+1}-k_i+1) )</span>. The main difficulty is to show why is is <span class="math inline">O(n \log \frac{k}{n^2})</span>.</p>
<section class="theorem-environment Lemma" id="Lemma-3">
<span class="theorem-header"><span class="type">Lemma</span><span class="index">3</span></span>
<p>If <span class="math inline">\sum_{i=1}^n k_i=k</span>, then <span class="math inline">\sum_{i=1}^n \log (k_{i+1}-k_i+1)=O(n\log k/n^2)</span>.</p>
</section>
<p>Once we show that, we can use the theorem to obtain <span class="math inline">O(\sqrt{k})</span> running time.</p>
<p>In fact, we can also get a very simple algorithm with running time <span class="math inline">O(h \log(k/h^2))</span>, where <span class="math inline">h</span> is the number of stairs in the staircase shape. However, it also uses <span class="math inline">O(h\log(k/h^2)</span> oracle calls. The idea is to use exponential search to find the boundary of the staircase, but we switch between boundaries: horizontal then vertical. It is open if we can obtain <span class="math inline">O(h\log(k/h^2))</span> running time and <span class="math inline">O(\log k)</span> oracle calls.</p>
<h1 id="remark"><span class="header-section-number">1</span> Remark</h1>
<p>There is an alternative algorithm which can be found in <span class="citation" data-cites="JacobR08">[<a href="#ref-JacobR08">3</a>]</span>. The alternative algorithm is quite close to a post about <a href="https://chaoxuprime.com/posts/2014-04-02-selection-in-a-sorted-matrix.html">selection in a sorted matrix</a>.</p>
<p>The careful reader might observe the known search algorithms follow the exact same structure as algorithms for selection. Indeed, we <em>are</em> doing selection but we do not know the rank of the element. Intuitively, many selection algorithm, the rank is <em>only used</em> to remove the correct set of candidates. Hence this suggest one can modify the algorithm to use the oracle call in place of the rank.</p>
<h1 id="bibliography" class="unnumbered">References</h1>
<div id="refs" class="references">
<div id="ref-FredericksonZ17">
<p>[1] G.N. Frederickson, S. Zhou, <strong>Optimal parametric search for path and tree partitioning</strong>, CoRR. abs/1711.00599 (2017).</p>
</div>
<div id="ref-FredericksonJ84">
<p>[2] G. Frederickson, D. Johnson, <strong>Generalized selection and ranking: Sorted matrices</strong>, SIAM Journal on Computing. 13 (1984) 14–30 <a href="https://doi.org/10.1137/0213002">10.1137/0213002</a>.</p>
</div>
<div id="ref-JacobR08">
<p>[3] R. Jacob, <strong>Binary search on two-dimensional data</strong>, Technische Universität München, 2008.</p>
</div>
</div>

</div>
<div class="hide-on-print">
    <div class="info">Posted by <a href="https://chaoxuprime.com">Chao Xu</a> on 2019-01-30. </div>
    <div class="info">Tags: algorithm, data structure.</div>

</div>]]></description>
    <pubDate>Wed, 30 Jan 2019 00:00:00 UT</pubDate>
    <guid>https://chaoxuprime.com/posts/2019-01-30-search-sorted-matrix.html</guid>
    <dc:creator>Chao Xu</dc:creator>
</item>
<item>
    <title>A Reviewer Assignment Problem</title>
    <link>https://chaoxuprime.com/posts/2019-01-29-reviewer-assignment.html</link>
    <description><![CDATA[<br />
<div>
<p>Consider there are some reviewers and some papers. Each reviewer can review exactly one paper, and each reviewer is qualified to review some subset of papers. We are interested in maximizing the number of papers reviewed by at least <span class="math inline">k</span> reviewer, then under that constraint, maximize the paper reviewed by <span class="math inline">k+1</span> reviewer, etc. This make sure we are being fair in evaluating papers. It would try to avoid the case where most paper getting small number of reviews and a few papers getting unreasonable number of reviews.</p>
<p>Formally, we are given a bipartite graph <span class="math inline">G=(A,B,E)</span> of <span class="math inline">n</span> vertices and <span class="math inline">m</span> edges. A subset of edges <span class="math inline">M</span> is called a semi-matching, if <span class="math inline">\deg_M(v)=1</span> for all <span class="math inline">v\in A</span>. For a subset of edges <span class="math inline">M</span>, let <span class="math inline">g_M(i)</span> to be the number of vertices in <span class="math inline">B</span> with degree at least <span class="math inline">i</span>. We want to find a semi-matching <span class="math inline">M</span>, such that <span class="math inline">(g_M(k),g_M(k+1),\ldots,g_M(n))</span> is lexicographically maximum.</p>
<p>When <span class="math inline">k=1</span>, if <span class="math inline">M</span> minimizes the sum of the function <span class="math inline">\sum_{v\in B} f(\deg_M(v))</span> for any strictly convex increasing function <span class="math inline">f</span>, then <span class="math inline">(g_M(1),g_M(2),\ldots,g_M(n))</span> is lexicographically maximum. The problem therefore can be reduced to min-cost flow can be applied here directly, and obtain a polynomial time algorithm <span class="citation" data-cites="HarveyLLT06">[<a href="#ref-HarveyLLT06">1</a>]</span>.</p>
<p>When <span class="math inline">k=3</span>, the problem is NP-hard, since it would imply we have to maximized <span class="math inline">g_M(3)</span>, and this is already NP-hard because exact cover by <span class="math inline">3</span>-sets. That is, given a collection of sets of size <span class="math inline">3</span> each. Decide if there exists a subcollection that forms a partition of the universe.</p>
<p>The only unresolved case is <span class="math inline">k=2</span>. Interestingly, we can show it is also polynomial time solvable. First, one can see that maximizing <span class="math inline">(g_M(2),g_M(3),\ldots,g_M(n))</span> is equivalent to minimize <span class="math inline">\sum_{v, \deg_M(v)\geq 2} f(\deg_M(v))</span> for some strictly convex increasing function <span class="math inline">v</span>, and <span class="math inline">M</span> range through all semi-matchings so each vertex in <span class="math inline">B</span> has degree exactly <span class="math inline">2</span> (Assuming it exists).</p>
<p>Apollonio and Sebő shown the following problem is polynomial time solvable <span class="citation" data-cites="ApollonioS09">[<a href="#ref-ApollonioS09">2</a>]</span>.</p>
<section class="theorem-environment Problem" id="Problem-1">
<span class="theorem-header"><span class="type">Problem</span><span class="index">1</span></span>
<p>Given a graph <span class="math inline">G=(V,E)</span>, a integer <span class="math inline">k</span>, convex functions <span class="math inline">f_v:\N \to \R</span> for each <span class="math inline">v\in V</span>, and an edge cost function <span class="math inline">c:E\to \R</span>. One can find the following in polynomial time. <span class="math display">\displaystyle \min \left\{   \sum_{v\in V} f_v(\deg_M(v)) + \sum_{e\in M} c(e) \middle| M\subseteq E, |M|=k  \right\}</span></p>
</section>
<p>It's not hard to generalize it a bit further by requiring <span class="math inline">M</span> to respect some upper and lower bound on the vertices. Indeed, we can let <span class="math inline">f_v:\N\to \R\cup \set{\infty}</span>, and set <span class="math inline">f_v(x)=\infty</span> if <span class="math inline">x</span> is not between the upper and lower bounds.</p>
<p>Now, we are going to reduce the problem. The reduction is similar to the <a href="https://cstheory.stackexchange.com/questions/33857/is-two-or-zero-matching-in-a-bipartite-graph-np-complete/33859">one for <span class="math inline">2</span>-or-<span class="math inline">0</span> matching</a>.</p>
<p>For each vertex <span class="math inline">v\in B</span>, split into two vertices <span class="math inline">v_1</span> and <span class="math inline">v_2</span>. Define <span class="math inline">B_i=\set{v_1|v\in B}</span>. The new input graph consists of vertices <span class="math inline">B_1\cup B_2 \cup A</span>. <span class="math inline">v_1</span> and <span class="math inline">v_2</span> connects to the same vertices as <span class="math inline">v</span>. We add an edge between <span class="math inline">v_1</span> and <span class="math inline">v_2</span>, with very large cost <span class="math inline">C</span>. Say <span class="math inline">C=mn^2+1</span>. <span class="math inline">v_1</span> has both an upper and lower bound of <span class="math inline">1</span>. <span class="math inline">v_2</span> has a lower bound of <span class="math inline">1</span>. For each vertex in <span class="math inline">A</span>, add an upper and lower bound of <span class="math inline">1</span>. We have a strict convex function <span class="math inline">f_{v_2}(x)=x^2</span> on each vertex <span class="math inline">v_2</span>.</p>
<p>Let <span class="math inline">r=|A|</span>, <span class="math inline">p=|B|</span>. We solve <a href="#Problem-1">Problem 1</a> repeatedly for each <span class="math inline">k</span> from <span class="math inline">r</span> to <span class="math inline">r+p</span>.</p>
<p>Say there exists an optimal solution to the original problem with exactly <span class="math inline">t</span> vertices in <span class="math inline">B</span> with degree smaller than <span class="math inline">2</span>. Find the optimal solution to the new problem with <span class="math inline">k=r+t</span>. Let it be <span class="math inline">M&#39;</span>. We obtain <span class="math inline">M</span> from <span class="math inline">M&#39;</span> by identify pairs of vertices <span class="math inline">v_1</span> and <span class="math inline">v_2</span>. <span class="math inline">M</span> would be the solution to the original problem.</p>
<h1 id="extensions"><span class="header-section-number">1</span> Extensions</h1>
<p>I first heard of the problem from <span class="citation" data-cites="YesilcimenY19">[<a href="#ref-YesilcimenY19">3</a>]</span>, where they focused on <span class="math inline">k=1</span> case, but the reviewer can review more than one paper. This case can be handled easily. We can add degree upper and lower bounds to all vertices, and only look at subgraphs in <span class="math inline">M</span> that satisfies the upper and lower bounds. That is, we can also make sure no reviewers review too many papers too. Under that constraint, find <span class="math inline">(g_M(k),\ldots,g_M(n))</span> lexicographically. This is possible but more tricky, as we have to do some reduction from capacitated <span class="math inline">b</span>-matching to <span class="math inline">b</span>-matching.</p>
<p>There is a little more generalization. Assume for each paper, we have a lower bound of reviews <span class="math inline">d_v</span>. That is, it has to be reviewed by at least <span class="math inline">d_v</span> person to be useful. So translating to the graph case, we can impose the constraint that <span class="math inline">\deg_M(v)=0</span> or <span class="math inline">\deg_M(v)\geq d_v</span>. One can see maximizing <span class="math inline">(g_M(2),g_M(3),\ldots,g_M(n))</span> is equivalent to maximizing <span class="math inline">(g_M(1),g_M(2),\ldots,g_M(n))</span> where <span class="math inline">d_v=2</span> for all vertices. Again, one can modify the reduction to handle the case when <span class="math inline">d_v</span> is either <span class="math inline">1</span> or <span class="math inline">2</span>.</p>
<h1 id="bibliography" class="unnumbered">References</h1>
<div id="refs" class="references">
<div id="ref-HarveyLLT06">
<p>[1] N.J. Harvey, R.E. Ladner, L. Lovász, T. Tamir, <strong>Semi-matchings for bipartite graphs and load balancing</strong>, Journal of Algorithms. 59 (2006) 53–78 <a href="https://doi.org/10.1016/j.jalgor.2005.01.003">10.1016/j.jalgor.2005.01.003</a>.</p>
</div>
<div id="ref-ApollonioS09">
<p>[2] N. Apollonio, A. Sebő, <strong>Minconvex factors of prescribed size in graphs</strong>, SIAM Journal on Discrete Mathematics. 23 (2009) 1297–1310 <a href="https://doi.org/10.1137/060651136">10.1137/060651136</a>.</p>
</div>
<div id="ref-YesilcimenY19">
<p>[3] A. Yeşilçimen, E.A. Yildirim, <strong>An alternative polynomial-sized formulation and an optimization based heuristic for the reviewer assignment problem</strong>, European Journal of Operational Research. (2019) <a href="https://doi.org/10.1016/j.ejor.2019.01.035">10.1016/j.ejor.2019.01.035</a>.</p>
</div>
</div>

</div>
<div class="hide-on-print">
    <div class="info">Posted by <a href="https://chaoxuprime.com">Chao Xu</a> on 2019-01-29. </div>
    <div class="info">Tags: algorithm, matching.</div>

</div>]]></description>
    <pubDate>Tue, 29 Jan 2019 00:00:00 UT</pubDate>
    <guid>https://chaoxuprime.com/posts/2019-01-29-reviewer-assignment.html</guid>
    <dc:creator>Chao Xu</dc:creator>
</item>
<item>
    <title>Soft heap and selection</title>
    <link>https://chaoxuprime.com/posts/2019-01-22-soft-heap-and-selection.html</link>
    <description><![CDATA[<br />
<div>
<p>I enjoyed the workshop <a href="https://simplicityinalgorithms.com/">SOSA</a> a lot (Disclaimer: I have a paper in SOSA). The papers are simple and fun. I liked the paper <span class="citation" data-cites="KaplanKZZ18">[<a href="#ref-KaplanKZZ18">1</a>]</span> the most, because I learned some really interesting tricks with <a href="https://en.wikipedia.org/wiki/Soft_heap">soft heap</a>.</p>
<p>Here I give a teaser of two things soft heap can do.</p>
<p>We consider a minimalistic soft heap, as there are soft heap with more operations.</p>
<ul>
<li><code>soft-heap(ε)</code>: creates an empty soft heap with error parameter <span class="math inline">\e</span>.</li>
<li><code>insert(e)</code>: insert an element into the heap.</li>
<li><code>extract-min()</code>: return the element of minimum key in heap, and set of newly corrupted elements since last extraction.</li>
</ul>
<p>The operation <code>insert</code> takes <span class="math inline">O(1)</span> time, <code>extract-min()</code> takes <span class="math inline">O(1/\e)</span> time. In this article, we can assume <span class="math inline">\e=1/4</span>.</p>
<p>During each insertion, the key of some elements might be increased. An element is corrupted if its key in the heap is strictly greater than the original key. If there are <span class="math inline">I</span> insertions into the soft heap, then at most <span class="math inline">\eI</span> elements can be corrupted.</p>
<p>Although <code>extract-min()</code> might return an element that is not necessarily the minimum, but there is a bound on the amount of possible errors. Before <span class="citation" data-cites="KaplanKZZ18">[<a href="#ref-KaplanKZZ18">1</a>]</span>, I don't know of any application of soft heap other than vaguely knowing about it was used for minimum spanning tree.</p>
<h1 id="linear-time-selection-in-unordered-list"><span class="header-section-number">1</span> Linear time selection in unordered list</h1>
<p>We insert all elements into the soft-heap, and then we apply <code>extract-min</code> <span class="math inline">(1-\e)n/2</span> times, and find the maximum element <span class="math inline">e</span>. One can see the rank of <span class="math inline">e</span> lies between <span class="math inline">(1-\e)n/2</span> and <span class="math inline">(1+\e)n/2</span>. Now we can use this to remove at least <span class="math inline">(1-\e)n/2=\frac{1+\e}{2} n</span> elements, and recurse on the remaining. Once there is only a constant number of elements, use brute force. This gives us an running time <span class="math inline">T(n) = O(n) + T(\frac{1+\e}{2} n) = O(n)</span>.</p>
<h1 id="linear-time-selection-in-heap"><span class="header-section-number">2</span> Linear time selection in heap</h1>
<p>We are given a min heap <span class="math inline">H</span>, and interested in find the <span class="math inline">k</span>th smallest element in the heap. We first insert the min element <span class="math inline">e</span> into the soft heap.</p>
<p>Whenever we apply <code>extract-min</code> to the soft heap, we obtain <span class="math inline">e</span> and a set of newly corrupted elements <span class="math inline">C</span>. For each element <span class="math inline">e&#39;\in C</span>, we add the children of <span class="math inline">e&#39;</span> in <span class="math inline">H</span> into the soft heap. If <span class="math inline">e</span> is not corrupted, we also add the children of <span class="math inline">e</span> in <span class="math inline">H</span> into the soft heap. Once we apply <code>extract-min</code> <span class="math inline">k-1</span> times we stop. Let <span class="math inline">S</span> be the set of all elements that was inserted into the soft heap. There are two important claims: <span class="math inline">|S|=O(k)</span> and the rank <span class="math inline">k</span> element has to be in <span class="math inline">S</span>. We can use a linear time selection algorithm on <span class="math inline">S</span> once we prove the two claims.</p>
<h1 id="other-useful-results"><span class="header-section-number">3</span> Other useful results</h1>
<p>There are some other nice results in the paper. Getting optimal results for selecting the rank <span class="math inline">k</span> element in <span class="math inline">m</span> sorted lists, and selecting <span class="math inline">k</span>th element in <span class="math inline">X+Y = \set{x+y | x\in X, y\in Y}</span>.</p>
<h1 id="bibliography" class="unnumbered">References</h1>
<div id="refs" class="references">
<div id="ref-KaplanKZZ18">
<p>[1] H. Kaplan, L. Kozma, O. Zamir, U. Zwick, Selection from Heaps, Row-Sorted Matrices, and X+Y Using Soft Heaps, in: J.T. Fineman, M. Mitzenmacher (Eds.), 2nd Symposium on Simplicity in Algorithms (Sosa 2019), Schloss Dagstuhl–Leibniz-Zentrum fuer Informatik, Dagstuhl, Germany, 2018: pp. 5:1–5:21 <a href="https://doi.org/10.4230/OASIcs.SOSA.2019.5">10.4230/OASIcs.SOSA.2019.5</a>.</p>
</div>
</div>

</div>
<div class="hide-on-print">
    <div class="info">Posted by <a href="https://chaoxuprime.com">Chao Xu</a> on 2019-01-22. </div>
    <div class="info">Tags: algorithm, data structure.</div>

</div>]]></description>
    <pubDate>Tue, 22 Jan 2019 00:00:00 UT</pubDate>
    <guid>https://chaoxuprime.com/posts/2019-01-22-soft-heap-and-selection.html</guid>
    <dc:creator>Chao Xu</dc:creator>
</item>
<item>
    <title>The high-degree low-degree technique and arboricity</title>
    <link>https://chaoxuprime.com/posts/2019-01-21-high-degree-low-degree-technique.html</link>
    <description><![CDATA[<br />
<div>
<p>In this piece we demonstrate the high-degree low-degree technique in graphs. Often, we obtain running times that depends on the individual degrees of the vertices. If the graph has only low degree vertices, then a faster algorithm exists. For graph with only large degrees, then it is dense, and can often be handled in another way.</p>
<p>We will also use the information of <a href="https://en.wikipedia.org/wiki/Arboricity">arboricity</a>. Mainly, there are a few useful statements.</p>
<section class="theorem-environment Theorem" id="Theorem-1">
<span class="theorem-header"><span class="type">Theorem</span><span class="index">1</span></span>
<p>For a graph <span class="math inline">G=(V,E)</span> with arboricity <span class="math inline">\alpha</span>, we have <span class="math display">\displaystyle 
    \sum_{uv\in E} \min(\deg(u),\deg(v)) \leq 2\alpha m
</span></p>
</section>
<p>Often, using the arboricity, we can obtain the same complexity algorithm without high-degree low-degree technique. Note the arboricity is <span class="math inline">O(\sqrt{m})</span>. The application of arboricity are from <span class="citation" data-cites="ChibaN85">[<a href="#ref-ChibaN85">1</a>]</span>.</p>
<p>Some of the algorithms described can be speedup by using matrix multiplication, or faster combinatorial boolean matrix multiplication. We avoid them for simplicity of exposition.</p>
<h1 id="dominating-set-with-few-edges"><span class="header-section-number">1</span> Dominating set with few edges</h1>
<p>The set cover problem, given <span class="math inline">\mathcal{S} = \set{S_1,\ldots,S_n}</span> are <span class="math inline">n</span> set contains a total of <span class="math inline">m</span> elements. <span class="math inline">U=\bigcup_{S\in \mathcal{S}} S</span> is the universe, with size <span class="math inline">u</span>.</p>
<section class="theorem-environment Theorem" id="Theorem-2">
<span class="theorem-header"><span class="type">Theorem</span><span class="index">2</span></span>
<p>There is a probability distribution <span class="math inline">D</span> over <span class="math inline">\mathcal{S}</span>, such that for each <span class="math inline">u</span>, the probability a random set <span class="math inline">S</span> covers <span class="math inline">u</span> is at least <span class="math inline">\e</span>. There exists a set cover of <span class="math inline">\ceil{\frac{\log u}{\e}}</span>.</p>
</section>
<section class="theorem-environment Proof" id="Proof-">
<span class="theorem-header"><span class="type">Proof</span></span>
<p>There exists a set that covers at least <span class="math inline">\e |U&#39;|</span> for any <span class="math inline">U&#39; \subset U</span>. Therefore each greedy iteration decrease the size of uncovered universe by an <span class="math inline">\e</span> fraction. So there can be at most <span class="math inline">t</span> iterations, where <span class="math inline">(1-\e)^t&lt;1</span>. One can show <span class="math inline">\ceil{\frac{\log u}{\e}}</span> suffices.</p>
</section>
<section class="theorem-environment Theorem" id="Theorem-3">
<span class="theorem-header"><span class="type">Theorem</span><span class="index">3</span></span>
<p>There is a dominating set incident to <span class="math inline">O(n\sqrt{n\log n})</span> edges.</p>
</section>
<section class="theorem-environment Proof" id="Proof-">
<span class="theorem-header"><span class="type">Proof</span></span>
<p>Fix a <span class="math inline">\delta</span>. We repeatedly removing vertices with degree no more than <span class="math inline">\delta</span> from the graph, and add it into a set <span class="math inline">D</span>. The total degree of <span class="math inline">D</span> is at most <span class="math inline">n\delta</span>. Now the remaining vertices has degree at least <span class="math inline">\delta</span>. Using the set cover theorem, and let the distribution to be the uniform distribution. If all elements are covered at least by <span class="math inline">\e</span> fraction of the set, then we obtain a set cover of size <span class="math inline">O(\frac{\log u}{\e})</span>. Now, let the sets <span class="math inline">N(v)</span> for each <span class="math inline">v</span>. Since degree is bounded by at most <span class="math inline">n</span>, we can obtain a dominating set of size <span class="math inline">O(\frac{n\log n}{e})</span>. We set <span class="math inline">\e=\delta/n</span>. Since the degree of each vertex is at least <span class="math inline">\delta</span>, then there is a covering of <span class="math inline">O(\frac{n^2\log n}{\delta})</span>. Add the vertices induces this set cover to <span class="math inline">D</span>. <span class="math inline">D</span> is a dominating set, and its size is <span class="math inline">O(n\delta +\frac{n^2\log n}{\delta})</span>, set <span class="math inline">\delta=\sqrt{n\log n}</span> and we obtain the desired result.</p>
</section>
<p>One can show the above result is almost optimal, as there exists graphs where every dominating set incidents <span class="math inline">\Omega(n^{3/2})</span> edges. The same bound holds for weakly connected dominating set, that is a dominating set <span class="math inline">D</span> such that the edges incident to <span class="math inline">D</span> forms a connected graph. The stronger modification of this result was used in deciding the <span class="math inline">4</span>-connectivity of a matroid <span class="citation" data-cites="Rajan87">[<a href="#ref-Rajan87">2</a>]</span>.</p>
<h1 id="finding-small-subgraphs"><span class="header-section-number">2</span> Finding small subgraphs</h1>
<h2 id="finding-a-triangle"><span class="header-section-number">2.1</span> Finding a triangle</h2>
<p>A <em>triangle</em> is <span class="math inline">3</span> vertices pairwise adjacent to each other, another name for <span class="math inline">K_3</span>.</p>
<section class="theorem-environment Theorem" id="Theorem-4">
<span class="theorem-header"><span class="type">Theorem</span><span class="index">4</span></span>
<p>There is a <span class="math inline">O(m\Delta)</span> time algorithm to decide if the graph has a triangle, where <span class="math inline">\Delta</span> is the maximum degree.</p>
</section>
<section class="theorem-environment Proof" id="Proof-">
<span class="theorem-header"><span class="type">Proof</span></span>
<p>Indeed, for each vertex <span class="math inline">v</span>, we consider its neighbors, see if any is adjacent to each other. We then delete <span class="math inline">v</span>. The algorithm takes <span class="math inline">O(\sum_{v} \deg^2(v)) = O(m\Delta)</span> time.</p>
</section>
<section class="theorem-environment Theorem" id="Theorem-5">
<span class="theorem-header"><span class="type">Theorem</span><span class="index">5</span></span>
<p>There is a <span class="math inline">O(n^3)</span> time algorithm to decide if the graph has a triangle.</p>
</section>
<section class="theorem-environment Proof" id="Proof-">
<span class="theorem-header"><span class="type">Proof</span></span>
<p>The naive algorithm, for each <span class="math inline">3</span> vertices, we decide if it forms a triangle.</p>
</section>
<section class="theorem-environment Theorem" id="Theorem-6">
<span class="theorem-header"><span class="type">Theorem</span><span class="index">6</span></span>
<p>There is a <span class="math inline">O(m^{3/2})</span> time algorithm to decide if the graph has a triangle.</p>
</section>
<section class="theorem-environment Proof" id="Proof-">
<span class="theorem-header"><span class="type">Proof</span></span>
<p>Let <span class="math inline">t</span> be a parameter we will find later. Apply the above algorithm by picking the vertex with the smallest degree, until the next vertex has degree at least <span class="math inline">t</span>. It will use at most <span class="math inline">O(mt)</span> time. Now, for the remaining graph, it is clear the maximum degree is at least <span class="math inline">t</span>. Note, there can be at most <span class="math inline">n/t</span> vertices. We use the <span class="math inline">O(n^3)</span> time algorithm. The final running time is <span class="math inline">O(mt+(m/t)^3)</span>. Set <span class="math inline">t=\sqrt{m}</span> and we are done.</p>
</section>
<section class="theorem-environment Proof" id="Proof-">
<span class="theorem-header"><span class="type">Proof</span><span class="name">Alternative</span></span>
<p>We modify the algorithm a little. For each vertex <span class="math inline">v</span>, we consider its neighbor <span class="math inline">u</span>, and check if <span class="math inline">u</span> has a neighbor that is in <span class="math inline">v</span>. Then we delete <span class="math inline">v</span>, and move on to next vertex. The running time become <span class="math inline">\sum_{v\in V} (\deg(v)+\sum_{u\in N(v)} \deg(u))</span>. Now, assume we pick vertices by the <em>largest</em> to <em>smallest</em> in term of degrees. We rearrange the sum and obtain <span class="math inline">\sum_{v\in V} (\deg(v)+\sum_{u\in N(v)} \deg(u)) = \sum_{v\in V} \deg(v) + 2 \sum_{uv\in E} \min(\deg(u),\deg(v)) = O(\alpha m)</span>. Because <span class="math inline">\alpha\leq \sqrt{m}</span>, we have the running time <span class="math inline">O(m^{3/2})</span>.</p>
</section>
<h2 id="a-motivating-problem"><span class="header-section-number">2.2</span> A motivating problem</h2>
<p>Let <span class="math inline">S_1,\ldots,S_n</span> be sets with total of <span class="math inline">m</span> elements. How quickly can we find two distinct <span class="math inline">i</span> and <span class="math inline">j</span> such that <span class="math inline">|S_i\cap S_j|\geq \ell</span>? This problem can be shown to be equivalent to finding a colored <span class="math inline">K_{2,\ell}</span> in a bipartite graph. That is, for input bipartite graph <span class="math inline">G=(A,B,E)</span>. Find a <span class="math inline">K_{2,\ell}</span> where the side of two vertices has to be in <span class="math inline">A</span>.</p>
<h2 id="finding-a-c_4-in-bipartite-graphs"><span class="header-section-number">2.3</span> Finding a <span class="math inline">C_4</span> in bipartite graphs</h2>
<p>This section we use technique that follows from <span class="citation" data-cites="AlonYZ97">[<a href="#ref-AlonYZ97">3</a>]</span>. Although we are into finding <span class="math inline">C_4</span>, but some theorems are more general for <span class="math inline">K_{2,\ell}</span>, so we will state them too. Note finding a colored <span class="math inline">K_{2,2}</span> and finding a <span class="math inline">K_{2,2}</span> is the same problem due to symmetry.</p>
<p>Let <span class="math inline">v_1,\ldots,v_n</span> be an ordering such that <span class="math inline">\deg(v_i)\geq \deg(v_j)</span>. There exists an algorithm that finds an ordering of vertices <span class="math inline">v_1,\ldots,v_n</span>, and returns <span class="math inline">N_i(v_i)\cap N_i(v_j)</span> for each <span class="math inline">i</span> and <span class="math inline">j&gt;i</span>. Here <span class="math inline">N_i(v)</span> is the set of neighbors of <span class="math inline">v</span> in <span class="math inline">G[\set{v_i,\ldots,v_n}]</span>. Here we show an algorithm solves the above problem when the arboricity is small.</p>
<p>The algorithm is as follows <span class="citation" data-cites="ChibaN85">[<a href="#ref-ChibaN85">1</a>]</span>. Take <span class="math inline">v</span>, we consider each neighbor <span class="math inline">u</span>. Maintain a set <span class="math inline">S_w</span> for each vertex <span class="math inline">w</span> distance <span class="math inline">2</span> from <span class="math inline">v</span>. Add <span class="math inline">u</span> into each of <span class="math inline">u</span>'s neighbor in <span class="math inline">w</span>. <span class="math inline">S_w</span> would give us information of <span class="math inline">N(v)\cap N(w)</span>. We delete <span class="math inline">v</span> and keep going. It is known the algorithm takes <span class="math inline">O(\alpha(G)m)</span> time. This allows us to compute <span class="math inline">C_4</span> in the same time. Hence we directly obtain <span class="math inline">O(m^{3/2})</span> running time. However, we show something better is possible if we are not interested in finding all <span class="math inline">C_4</span>, but find any <span class="math inline">C_4</span>. We also need the following theorem.</p>
<section class="theorem-environment Theorem" id="Theorem-7">
<span class="theorem-header"><span class="type">Theorem</span><span class="index">7</span></span>
<p>One can check if there exists a <span class="math inline">K_{2,\ell}</span> in the bipartite graph <span class="math inline">G=(A,B,E)</span> in <span class="math inline">O(\ell n^2)</span> time.</p>
</section>
<p>Now, we combine the two algorithms. It requires a theorem in extremal graph theory can be found in <span class="citation" data-cites="Furedi96">[<a href="#ref-Furedi96">4</a>]</span>.</p>
<section class="theorem-environment Theorem" id="Theorem-8">
<span class="theorem-header"><span class="type">Theorem</span><span class="index">8</span><span class="name"><span class="math inline">K_{2,\ell}</span>-free theorem</span></span>
<p>There exists a constant <span class="math inline">c</span>, such that each <span class="math inline">n</span> vertex graph with <span class="math inline">c n^{3/2} \ell^{1/2}</span> edges contains a <span class="math inline">K_{2,\ell}</span>.</p>
</section>
<section class="theorem-environment Theorem" id="Theorem-9">
<span class="theorem-header"><span class="type">Theorem</span><span class="index">9</span></span>
<p>There is a <span class="math inline">O(m^{4/3})</span> time algorithm to find a <span class="math inline">C_4</span> in the graph.</p>
</section>
<section class="theorem-environment Proof" id="Proof-">
<span class="theorem-header"><span class="type">Proof</span></span>
<p>If the arboricity is <span class="math inline">t</span>. We use the first algorithm and we get running time <span class="math inline">O(t m)</span>. Otherwise, we know there is a subgraph with minimum degree at least <span class="math inline">t</span>. The subgraph can be found by repeatedly deleting vertices of minimum degree. The subgraph <span class="math inline">G&#39;</span> with the previous property has <span class="math inline">n&#39;\leq n</span> vertices and <span class="math inline">m&#39;\leq n&#39;t</span> edges. One can see <span class="math inline">n&#39;\leq m&#39;/t\leq m/t</span>. If <span class="math inline">cn&#39;^{3/2}\leq m&#39; \leq n&#39;t</span>, then we know there exists a <span class="math inline">C_4</span> in <span class="math inline">G&#39;</span> by the previous theorem, and we can apply the <span class="math inline">O(n^2)</span> time algorithm in the subgraph to find the <span class="math inline">C_4</span>. The total running time is therefore <span class="math inline">O(tm + n&#39;^2) = O(tm+(m/t)^2)</span>. We set <span class="math inline">t=c^{3/2} m^{1/3}</span>. One can check after lot of algebra, it make sure the condition <span class="math inline">cn&#39;^{3/2}\leq n&#39;t</span> is satisfied. The algorithm takes <span class="math inline">O(m^{4/3})</span> time.</p>
</section>
<h2 id="finding-a-colored-k_23-in-bipartite-graphs"><span class="header-section-number">2.4</span> Finding a colored <span class="math inline">K_{2,3}</span> in bipartite graphs</h2>
<p>For finding <span class="math inline">K_{2,\ell}</span>, the low arboricity algorithm for <span class="math inline">C_4</span> works here. The <span class="math inline">O(\alpha(G)m)</span> algorithm is still fine. It's not hard to generalize and show a <span class="math inline">O(\ell^{1/3}m^{4/3})</span> running time algorithm.</p>
<p>However, in order to solve the motivating problem. We need a colored <span class="math inline">K_{2,\ell}</span>.</p>
<p>Let's consider a <span class="math inline">K_{2,\ell}</span> in <span class="math inline">G</span>, and consider the first indexed vertex <span class="math inline">v</span>. If <span class="math inline">v\in A</span>, then we are done, as the algorithm will find it. If <span class="math inline">v\in B</span>, then we will solve the problem in another way, which gives us some time improvement when <span class="math inline">\ell=3</span>.</p>
<p>For each <span class="math inline">v_i</span> in <span class="math inline">B</span>, we consider <span class="math inline">v_j\in B</span> that has distance <span class="math inline">2</span> from <span class="math inline">v_i</span> and <span class="math inline">j&gt;i</span>. We consider the set of vertices <span class="math inline">S_{i,j} = N_i(v_i)\cap N_i(v_j)</span>. If there are two sets <span class="math inline">S_{i,j}</span> and <span class="math inline">S_{a,b}</span> has intersection size at least <span class="math inline">2</span>, then we claim there exists a <span class="math inline">K_{2,3}</span> in <span class="math inline">G</span>. Now, this becomes finding a <span class="math inline">C_4</span> in the input sets. The total size of the input sets are <span class="math inline">O(\alpha(G)m)</span>. Hence we can use <span class="math inline">O((\alpha(G)m)^{4/3})</span> time to find a <span class="math inline">C_4</span>. Hence this implies a <span class="math inline">O((\alpha(G)m)^{4/3})</span> time algorithm to find a <span class="math inline">K_{2,3}</span>.</p>
<p>Using the idea for finding <span class="math inline">C_4</span>, we can mix the <span class="math inline">((\alpha(G)m)^{4/3})</span> time algorithm and the <span class="math inline">O(n^2)</span> time algorithm. Working out the algebra shows the following theorem.</p>
<section class="theorem-environment Theorem" id="Theorem-10">
<span class="theorem-header"><span class="type">Theorem</span><span class="index">10</span></span>
<p>There is a <span class="math inline">O(m^{28/15})</span> time algorithm for finding a colored <span class="math inline">K_{2,3}</span>.</p>
</section>
<h1 id="bibliography" class="unnumbered">References</h1>
<div id="refs" class="references">
<div id="ref-ChibaN85">
<p>[1] N. Chiba, T. Nishizeki, <strong>Arboricity and Subgraph Listing Algorithms</strong>, SIAM Journal on Computing. 14 (1985) 210–223 <a href="https://doi.org/10.1137/0214017">10.1137/0214017</a>.</p>
</div>
<div id="ref-Rajan87">
<p>[2] A. Rajan, Algorithmic applications of connectivity and related topics in matroid theory, PhD thesis, Northwestern University, 1987.</p>
</div>
<div id="ref-AlonYZ97">
<p>[3] N. Alon, R. Yuster, U. Zwick, <strong>Finding and counting given length cycles</strong>, Algorithmica. 17 (1997) 209–223 <a href="https://doi.org/10.1007/BF02523189">10.1007/BF02523189</a>.</p>
</div>
<div id="ref-Furedi96">
<p>[4] Z. Füredi, <strong>New asymptotics for bipartite turán numbers</strong>, Journal of Combinatorial Theory, Series A. 75 (1996) 141–144 <a href="https://doi.org/10.1006/jcta.1996.0067">10.1006/jcta.1996.0067</a>.</p>
</div>
</div>

</div>
<div class="hide-on-print">
    <div class="info">Posted by <a href="https://chaoxuprime.com">Chao Xu</a> on 2019-01-21. </div>
    <div class="info">Tags: algorithm, graph.</div>

</div>]]></description>
    <pubDate>Mon, 21 Jan 2019 00:00:00 UT</pubDate>
    <guid>https://chaoxuprime.com/posts/2019-01-21-high-degree-low-degree-technique.html</guid>
    <dc:creator>Chao Xu</dc:creator>
</item>
<item>
    <title>Lights out game on a grid</title>
    <link>https://chaoxuprime.com/posts/2019-01-12-lights-out-game.html</link>
    <description><![CDATA[<br />
<div>
<section class="theorem-environment Problem" id="Problem-1">
<span class="theorem-header"><span class="type">Problem</span><span class="index">1</span></span>
<p>Let <span class="math inline">G</span> be a graph, let <span class="math inline">A</span> be the adjacency matrix of <span class="math inline">G</span>. Solve the equation <span class="math inline">Ax=b</span> in <span class="math inline">\F_2</span>.</p>
</section>
<p>The problem is equivalent to the <a href="https://en.wikipedia.org/wiki/Lights_Out_%28game%29">lights out game</a>. Each vertex has state <span class="math inline">0</span> or <span class="math inline">1</span>. Activate a vertex flips the state of itself and all its neighbors. Find a set of activations that turns all state into <span class="math inline">0</span>. Originally I thought this problem can be solved in <span class="math inline">O(n^{\omega/2})</span> when <span class="math inline">G</span> is planar graph on <span class="math inline">n</span> vertices by <a href="https://en.wikipedia.org/wiki/Nested_dissection">nested dissection</a>. However, only recently I found out the matrix must be non-singular. Therefore nested dissection does not apply.</p>
<p>Recently I saw an algorithm that shows if the graph is a <span class="math inline">n\times n</span> grid, then it can be solved in <span class="math inline">O(n^3)</span> time. The solution in Chinese and can be seen <a href="https://zhuanlan.zhihu.com/p/53646257">here</a>.</p>
<p>Given a <span class="math inline">n\times n</span> grid graph. Let <span class="math inline">v_{i,j}</span> be the node on the <span class="math inline">i</span>th row and <span class="math inline">j</span>th column. Let <span class="math inline">b_{i,j}</span> be the state of the vertex <span class="math inline">v_{i,j}</span>. The state is in <span class="math inline">\F_2</span> If we activates a node, the state of the node and its neighbors change by <span class="math inline">1</span>. The set of activated node is called the activation set.</p>
<p>We are interested in finding an activation set <span class="math inline">S</span>, such the state of all nodes after activate <span class="math inline">S</span> is <span class="math inline">0</span>.</p>
<p>Let <span class="math inline">S</span> be the activation set, and <span class="math inline">S_1</span> to be the activation set of the first row.</p>
<section class="theorem-environment Theorem" id="Theorem-2">
<span class="theorem-header"><span class="type">Theorem</span><span class="index">2</span></span>
<p><span class="math inline">S_1</span> uniquely determines <span class="math inline">S</span>. Moreover, One can compute <span class="math inline">S</span> from <span class="math inline">S_1</span> in <span class="math inline">O(n^2)</span> time.</p>
</section>
<section class="theorem-environment Proof" id="Proof-">
<span class="theorem-header"><span class="type">Proof</span></span>
<p>Indeed, consider apply activation to the nodes in <span class="math inline">S_1</span>. Consider any vertex in row <span class="math inline">1</span>. If it <span class="math inline">0</span>, then the remaining neighbor (on the second row) cannot be activated. If it is <span class="math inline">1</span>, then the remaining neighbor has to be activated.</p>
</section>
<p>Let <span class="math inline">D[i,j]</span> indicates if we activate <span class="math inline">v_{i,j}</span> or not. We create formal variables <span class="math inline">Z=\set{z_1,\ldots,z_n}</span>. Here <span class="math inline">z_i</span> is an indicator variable that represents if <span class="math inline">v_{1,i}</span> is activated or not. The base case <span class="math inline">D[1,j] = z_j</span>. The observation shows that for each <span class="math inline">i</span> and <span class="math inline">j</span>, <span class="math inline">D[i+1,j] = 1 + D[i,j-1]+D[i,j]+D[i,j+1]+D[i-1,j]+b_{i,j}</span>. We can express <span class="math inline">D[i,j]</span> as a sum of elements in <span class="math inline">Z</span> and a constant, and we are summing a constant number of previous states. So it has size <span class="math inline">O(n)</span>. We can compute the expression of <span class="math inline">D[i,j]</span> in <span class="math inline">O(n)</span> time. So computing all <span class="math inline">D[i,j]</span> for <span class="math inline">i\geq 2</span> takes <span class="math inline">O(n^3)</span> time.</p>
<p>We are interested in <span class="math inline">D[n,1],\ldots,D[n,n]</span>. We can see it is of the following form.</p>
<p><span class="math display">\displaystyle 
\begin{aligned}
D[n,1] &amp;= c_{1,1} z_1+\ldots +c_{1,n} z_{n} + u_{1}\\
D[n,2] &amp;= c_{2,1} z_1+\ldots +c_{2,n} z_{n} + u_{2}\\
 \vdots &amp;\qquad  \vdots\\
D[n,n] &amp;= c_{m,1} z_1+\ldots + c_{m,n} z_n + u_{n}
\end{aligned}
</span></p>
<p>We solve the equation <span class="math inline">Cz=u</span>. Note here <span class="math inline">C</span> is just a <span class="math inline">n\times n</span> matrix. We finds <span class="math inline">z_1,\ldots,z_n</span>. So now we have found the activation set restricted on the first row. We can use it to find the entire activation set.</p>
<p>The total running time is <span class="math inline">O(n^3)</span>. Building the table <span class="math inline">D</span> and solving <span class="math inline">Cz=u</span>. One can generalize this a bit further. We can obtain <span class="math inline">O(m^2n)</span> running time for a <span class="math inline">m\times n</span> grid, where <span class="math inline">m\leq n</span>. Also, there is no reason we have to work in <span class="math inline">\F_2</span>, any arbitrary field is fine.</p>
<section class="theorem-environment Theorem" id="Theorem-3">
<span class="theorem-header"><span class="type">Theorem</span><span class="index">3</span></span>
<p>Let <span class="math inline">G</span> be a <span class="math inline">m\times n</span> grid and <span class="math inline">A</span> is a matrix where the non-zero entires are precisely the position of <span class="math inline">1</span>s in the adjacency matrix of <span class="math inline">A</span>. Finding <span class="math inline">Ax=b</span> can be done in <span class="math inline">O(m^2n)</span> time.</p>
</section>
<p>I did not think too much into it, but maybe it works for all integral domains too. Interestingly, this algorithm is so special, that we have no idea how to extend it to other graphs. Maybe it works for directed graph, maybe it works for subgraph of the grid graphs.</p>
<p>It would be really interesting to see an algorithm with running time <span class="math inline">O(n^{3/2})</span> for a planar graph of <span class="math inline">n</span> vertices.</p>

</div>
<div class="hide-on-print">
    <div class="info">Posted by <a href="https://chaoxuprime.com">Chao Xu</a> on 2019-01-12. </div>
    <div class="info">Tags: algorithm, algebra.</div>

</div>]]></description>
    <pubDate>Sat, 12 Jan 2019 00:00:00 UT</pubDate>
    <guid>https://chaoxuprime.com/posts/2019-01-12-lights-out-game.html</guid>
    <dc:creator>Chao Xu</dc:creator>
</item>

    </channel>
</rss>
