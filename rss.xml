<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"
    xmlns:dc="http://purl.org/dc/elements/1.1/">
    <channel>
        <title>The Art Gallery Guardian</title>
        <link>https://chaoxuprime.com/blog</link>
        <description><![CDATA[Mostly notes on algorithms]]></description>
        <atom:link href="https://chaoxuprime.com/blog/rss.xml" rel="self"
                   type="application/rss+xml" />
        <lastBuildDate>Tue, 05 Feb 2019 00:00:00 UT</lastBuildDate>
        <item>
    <title>Find the period of a nice eventually periodic sequence</title>
    <link>https://chaoxuprime.com/blog/posts/2019-02-05-eventually-periodic.html</link>
    <description><![CDATA[<br />
<div>
<p>A sequence is periodic if <span class="math inline">s_i = s_{i+p}</span> for all <span class="math inline">i</span>, where <span class="math inline">p&gt;0</span> is called a period. A sequence is eventually periodic if there exists a <span class="math inline">n</span> and <span class="math inline">p</span>, such that <span class="math inline">s_i = s_{i+p}</span> for all <span class="math inline">i&gt;n</span>. The sequence with index above <span class="math inline">n</span> is the <em>periodic part</em>.</p>
<p>A sequence is called <em><span class="math inline">u</span>-normal</em>, if there exists <span class="math inline">s_i=s_{i+p}</span> for some <span class="math inline">p&gt;0</span> for all <span class="math inline">i</span> in a interval of length <span class="math inline">u</span>, then the sequence starting at <span class="math inline">s_i</span> is part of the periodic part.</p>
<p>When does <span class="math inline">u</span>-normal sequence comes up? Consider we have a recurrence relation that produces a sequence. Say it is of the form <span class="math inline">a_n = f(a_{n-1},a_{n-2},\ldots,a_{n-u})</span>. The sequence <span class="math inline">a_1,\ldots</span> is <span class="math inline">u</span>-normal.</p>
<section class="theorem-environment Problem" id="Problem-1">
<span class="theorem-header"><span class="type">Problem</span><span class="index">1</span></span>
<p>Given a oracle that can take input <span class="math inline">i</span> and return the <span class="math inline">i</span>th element in a <span class="math inline">u</span>-normal eventually periodic sequence <span class="math inline">a</span>. Find the smallest lexicographic pair <span class="math inline">(n,p)</span> where <span class="math inline">p&gt;0</span>, such that <span class="math inline">a_i=a_{i+p}</span> for all <span class="math inline">i&gt;n</span>.</p>
</section>
<p>One can solve this problem in <span class="math inline">O(u \log \frac{n}{u})</span> time. First, consider the subsequence <span class="math inline">a_u,a_{2u},\ldots</span>. We guess an upper bound on <span class="math inline">n</span> through exponential search in the subsequence. There is a <span class="math inline">O(u)</span> time algorithm to decide if <span class="math inline">n&#39;\geq n</span>. For example using the <a href="https://en.wikipedia.org/wiki/Knuth%E2%80%93Morris%E2%80%93Pratt_algorithm">KMP algorithm</a>. We can quickly locate a <span class="math inline">n&#39;</span> such that <span class="math inline">n\in [n&#39;-u,n&#39;]</span>.</p>
<p>Let's take the sequence <span class="math inline">a_{n&#39;-u},\ldots,a_{n&#39;+3u}</span>. We just need to solve the following problem. Given a <span class="math inline">O(u)</span> length string, find the longest suffix that appears at least twice in the sequence. Let such suffix be <span class="math inline">s</span>. We know <span class="math inline">|s|\geq 3u</span>, which <span class="math inline">s</span> has to overlap with any other occurrence of the sequence. The claim is that the partial match table in the KMP algorithm would give us such information. Hence we can obtain <span class="math inline">n</span>. <span class="math inline">p</span> can also be obtained in the same time. Note that KMP algorithm only uses the fact one can check equality of two elements. So the sequence can contain elements from very general space.</p>
<p>The total running time is <span class="math inline">O(\log \frac{n}{u})</span> calls to <span class="math inline">O(u)</span> time string matching. The total running time is therefore <span class="math inline">O(u\log \frac{n}{u})</span>.</p>
<p>In many applications, we do not get oracle access to <span class="math inline">i</span>th index of the sequence. But we can read the sequence from the beginning as a list. In that case, we don't do binary search, but linear search. Advance the index by <span class="math inline">u</span> and obtain <span class="math inline">n&#39;</span>, and test if <span class="math inline">n</span> is no larger than the current point. If so, again we have <span class="math inline">n\in [n&#39;-u,n&#39;]</span> and reduce to the previous problem. If not, advance the index by <span class="math inline">u</span> again and repeat. This gives us a <span class="math inline">O(n+u)</span> time algorithm.</p>

</div>
<div class="hide-on-print">
    <div class="info">Posted by <a href="https://chaoxuprime.com">Chao Xu</a> on 2019-02-05. </div>
    <div class="info">Tags: algorithms, infinite sequence.</div>

</div>]]></description>
    <pubDate>Tue, 05 Feb 2019 00:00:00 UT</pubDate>
    <guid>https://chaoxuprime.com/blog/posts/2019-02-05-eventually-periodic.html</guid>
    <dc:creator>Chao Xu</dc:creator>
</item>
<item>
    <title>Bottleneck <span class="math inline">k</span>-link path</title>
    <link>https://chaoxuprime.com/blog/posts/2019-01-31-bottleneck-k-link-path.html</link>
    <description><![CDATA[<br />
<div>
<p>A DAG is called complete, if there are vertices <span class="math inline">v_1,\ldots,v_n</span>, and <span class="math inline">v_iv_j</span> is an edge if and only if <span class="math inline">i&lt;j</span>. Let <span class="math inline">w(i,j)</span> be the edge weights from <span class="math inline">i</span> to <span class="math inline">j</span>. The weight is called ordered, if <span class="math inline">w(i,j)&lt;w(i,j+1)</span> and <span class="math inline">w(i+ 1,j)&lt;w(i,j)</span>.</p>
<section class="theorem-environment Problem" id="Problem-1">
<span class="theorem-header"><span class="type">Problem</span><span class="index">1</span><span class="name">Bottleneck <span class="math inline">k</span>-link path problem</span></span>
<p>Find a path consists of <span class="math inline">k</span> edges from <span class="math inline">v_1</span> to <span class="math inline">v_n</span>, such that the maximum weight of the edges in the path is minimized.</p>
</section>
<p>One can formulate a dynamic programming algorithm, which takes <span class="math inline">O(kn^2)</span> time. My <a href="https://chaoxuprime.com/posts/2013-08-16-more-algorithms-on-perfectly-balanced-photo-gallery.html">previous writing</a> shows an <span class="math inline">O(kn)</span> time algorithm using the monge property. Using binary search, there is also an <span class="math inline">O(k\log(n/k)\log M)</span> time algorithm if all weights are positive integers no larger than <span class="math inline">M</span>.</p>
<p>We show there is an <span class="math inline">O(n+k\log(n/k)\log n)</span> time algorithm. Assume <span class="math inline">\lambda^*</span> is the optimal weight. First, there is an oracle that given <span class="math inline">\lambda</span>, decides if <span class="math inline">\lambda\geq \lambda^*</span>. Indeed, we can apply the greedy algorithm. Find the sequence <span class="math inline">a_1,\ldots,a_k</span>, as follows. <span class="math inline">a_0=1</span>, <span class="math inline">a_i</span> is the largest value such that <span class="math inline">w(a_{i-1},a_i)\leq \lambda</span>. If <span class="math inline">a_k=n</span>, then it is clear that <span class="math inline">\lambda \geq \lambda^*</span>. Also, we can show if <span class="math inline">a_k&lt;n</span>, then <span class="math inline">\lambda &lt; \lambda^*</span>. <span class="math inline">O(n)</span> time seems to be a quite large bound. We could do it in <span class="math inline">O(k\log (n))</span> instead by doing binary search for each <span class="math inline">a_i</span>. Using <a href="https://en.wikipedia.org/wiki/Exponential_search">exponential search</a> instead, we can obtain a <span class="math inline">O(k\log(n/k))</span> time algorithm.</p>
<p>One need to do binary search for <span class="math inline">\lambda^*</span>. There are <span class="math inline">\Omega(n^2)</span> weights, let it be <span class="math inline">W</span>. One does not have to know all of them in order to apply binary search. Note that <span class="math inline">w</span> is a matrix sorted in both row and column, hence we need a selection algorithm that returns the <span class="math inline">k</span>th smallest element for such matrix. There is an <a href="https://chaoxuprime.com/posts/2014-04-02-selection-in-a-sorted-matrix.html"><span class="math inline">O(n)</span> time algorithm</a> for that. Hence we can do binary search on the sorted <span class="math inline">W</span> by spending <span class="math inline">O(n)</span> time to access <span class="math inline">i</span>th element. We now obtain a <span class="math inline">O((n+ k\log(n/k)) \log n) = O(n\log n)</span> time algorithm. Not bad.</p>
<p>We can speed it up even further. Instead of selection in the sorted matrix, we can do <a href="https://chaoxuprime.com/posts/2019-01-30-search-sorted-matrixhtml">search in the sorted matrix</a>. We are given an oracle to test if a value is smaller than <span class="math inline">\lambda^*</span> after all. We can do search for <span class="math inline">\lambda^*</span> using <span class="math inline">O(\log n)</span> oracle calls and <span class="math inline">O(n)</span> time. Hence this gives us a <span class="math inline">O(n+k\log (n/k) \log n)</span> time algorithm for the problem. Whenever <span class="math inline">k=O(\frac{n}{\log(n) \log \log n})</span>, this is <span class="math inline">O(n)</span> time.</p>
<p>As an application, we obtain a solution to <a href="https://leetcode.com/problems/split-array-largest-sum/">Leetcode 410 Split Array Largest Sum</a>. The problem is also called the <em>linear partitioning</em> problem. The problem asks one to partition array into <span class="math inline">k</span> contagious subarrays that minimizes the maximum sum of each subarray. It was an example for learning dynamic programming in chapter 8.5 of <span class="citation" data-cites="Skiena10book">[<a href="#ref-Skiena10book">1</a>]</span>. An <span class="math inline">O(kn^2)</span> algorithm was given. Reading the discussion online, one would find <span class="math inline">O(n\log M)</span> time algorithm is the suggested solution, where <span class="math inline">M</span> is the maximum over all integers. The algorithm is actually fairly useful for photo galleries. There is the <a href="https://www.npmjs.com/package/linear-partitioning">NPM package <code>linear-partitioning</code></a>, used by multiple photo galleries packages. My <a href="https://chaoxuprime.com/posts/2013-08-16-more-algorithms-on-perfectly-balanced-photo-gallery.html">first encountered of the problem</a> was also for photo gallery. The linear partition problem reduces to the bottleneck <span class="math inline">k</span>-link path problem because we can define <span class="math inline">w(i,j)</span> to be the sum of elements from the <span class="math inline">i</span>th index of the array to the <span class="math inline">j</span>th index of the array. After <span class="math inline">O(n)</span> preprocessing, <span class="math inline">w(i,j)</span> can be computed in <span class="math inline">O(1)</span> time. This results a <span class="math inline">O(n+k\log (n/k) \log n)</span> running time algorithm.</p>
<p>What about when <span class="math inline">k</span> is large? I've emailed <a href="https://samsonzhou.github.io/">Samson Zhou</a>, who has confirmed the algorithm in <span class="citation" data-cites="FredericksonZ17">[<a href="#ref-FredericksonZ17">2</a>]</span> can be used to solve the problem in <span class="math inline">O(n)</span> time.</p>
<h1 id="bibliography" class="unnumbered">References</h1>
<div id="refs" class="references">
<div id="ref-Skiena10book">
<p>[1] S.S. Skiena, <strong>The algorithm design manual</strong>, Springer, 2010.</p>
</div>
<div id="ref-FredericksonZ17">
<p>[2] G.N. Frederickson, S. Zhou, <strong>Optimal parametric search for path and tree partitioning</strong>, CoRR. abs/1711.00599 (2017).</p>
</div>
</div>

</div>
<div class="hide-on-print">
    <div class="info">Posted by <a href="https://chaoxuprime.com">Chao Xu</a> on 2019-01-31. </div>
    <div class="info">Tags: algorithm, data structure.</div>

</div>]]></description>
    <pubDate>Thu, 31 Jan 2019 00:00:00 UT</pubDate>
    <guid>https://chaoxuprime.com/blog/posts/2019-01-31-bottleneck-k-link-path.html</guid>
    <dc:creator>Chao Xu</dc:creator>
</item>
<item>
    <title>Search in a sorted matrix with an oracle</title>
    <link>https://chaoxuprime.com/blog/posts/2019-01-30-search-sorted-matrix.html</link>
    <description><![CDATA[<br />
<div>
<p>Consider a infinite matrix <span class="math inline">M</span>. Another way to think about it is a function <span class="math inline">f:\N\to \N\to X</span>. A matrix <span class="math inline">M</span> is sorted if <span class="math inline">M_{i,j}\leq M_{i,j+1}</span> and <span class="math inline">M_{i,j}\leq M_{i+1,j}</span>.</p>
<section class="theorem-environment Problem" id="Problem-1">
<span class="theorem-header"><span class="type">Problem</span><span class="index">1</span></span>
<p>Given a sorted matrix <span class="math inline">M</span>, and an oracle that takes <span class="math inline">\lambda</span> returns if a value is <span class="math inline">\lambda &lt;\lambda^*</span> or <span class="math inline">\lambda \geq \lambda^*</span>. Find the largest value no larger than <span class="math inline">\lambda^*</span>.</p>
</section>
<p>Assuming there are at most <span class="math inline">k</span> elements no larger than <span class="math inline">\lambda^*</span>, and we know the smallest <span class="math inline">n</span> and <span class="math inline">m</span> such that <span class="math inline">M_{i,j}&gt;\lambda^*</span> if <span class="math inline">i&gt;n</span> or <span class="math inline">j&gt;m</span>. Also, let <span class="math inline">t</span> be the smallest number such that <span class="math inline">M_{t,t}&gt;\lambda^*</span>. One can see that <span class="math inline">t\leq \min(n,m)</span> and <span class="math inline">k=O(\max(n,m)^2)</span>.</p>
<p>Let's first consider the case when <span class="math inline">n</span> and <span class="math inline">m</span> is known and <span class="math inline">n\leq m</span>. It is <a href="https://leetcode.com/problems/search-a-2d-matrix-ii/">Leetcode 240. Search a 2D Matrix II</a>. However, our problem is more general, because comparison with <span class="math inline">\lambda^*</span> can only be done through the oracle. Craig Gidney wrote about an <a href="http://twistedoakstudios.com/blog/Post5365_searching-a-sorted-matrix-faster">optimal algorithm</a> with <span class="math inline">O(n\log \frac{m}{n})</span> running time, matrix access algorithm. However, the oracle access is too large. There are times where the oracle access is slow. For example, when using it as a subroutine for finding a <a href="https://chaoxuprime.com/posts/2019-01-31-bottleneck-k-link-path.html">bottleneck <span class="math inline">k</span>-link path</a>. There is an algorithm with optimal running time and <span class="math inline">O(\log(nm))</span> oracle access.</p>
<p>Let's consider a special case, where <span class="math inline">n=m=2^i</span> for some <span class="math inline">i</span>. This case was shown in <span class="citation" data-cites="FredericksonZ17">[<a href="#ref-FredericksonZ17">1</a>]</span>. For each submatrix, the two vertices on the opposite diagonal indicates the largest and smallest element in the submatrix. Hence each matrix can be represented by two numbers, indicate the maximum and minimum. These numbers are called the representative of the matrix. The idea is we keep two numbers <span class="math inline">\lambda_1</span> and <span class="math inline">\lambda_2</span>, such that we know <span class="math inline">\lambda^*\in [\lambda_1,\lambda_2]</span>. The algorithm keep partition the matrix into small matrices, updating <span class="math inline">\lambda_1</span> and <span class="math inline">\lambda_2</span>, and discard matrices outside the range. We apply the following algorithm. Let <span class="math inline">R</span> consists of the multiset of representatives of the matrix, and <span class="math inline">R&#39;</span> be the representatives that lies inside <span class="math inline">[\lambda_1,\lambda_2]</span>. We find <span class="math inline">\lambda</span>, the median of <span class="math inline">R&#39;</span>. Test if <span class="math inline">\lambda&lt;\lambda^*</span>. If so, then <span class="math inline">\lambda_1</span> updates to <span class="math inline">\lambda</span>, otherwise <span class="math inline">\lambda_2</span> updates to <span class="math inline">\lambda</span>. This step is done twice. Now, we split the matrices with more than one element into <span class="math inline">4</span> equally sized matrices, and repeat the algorithm. Recall at all times, the matrices does not contain any element in <span class="math inline">[\lambda_1,\lambda_2]</span> are discarded.</p>
<p>There is at most <span class="math inline">O(\log n)</span> iterations before range shrinks to a single element, hence at most <span class="math inline">O(\log n)</span> oracle calls. The difficulty is to show that the overall time is only <span class="math inline">O(n)</span>. Intuitively, in each iteration we quadruple the number of matrices, but we half it by two calls to the oracle. Therefore in <span class="math inline">\log n</span> steps we obtain roughly <span class="math inline">2^{\log n}=O(n)</span> matrices. However, at this point, the matrices are all singletons, and no more matrix can be created. We will only decrease the number of matrices by each oracle call. Careful reader can trace the whole argument in Lemma 2.1 of <span class="citation" data-cites="FredericksonZ17">[<a href="#ref-FredericksonZ17">1</a>]</span>.</p>
<p>For the more general case, one can find the proof in <span class="citation" data-cites="FredericksonJ84">[<a href="#ref-FredericksonJ84">2</a>]</span>. Note the proof is for selection, but one can easily modify it to work for search.</p>
<p>Now, <span class="math inline">n</span> and <span class="math inline">m</span> is not known, but we can quickly using exponential search to find it. Indeed, we just have to apply exponential search in the first row and first column using the oracle. This gives us an extra <span class="math inline">O(\log n + \log m)=O(\log nm)</span> oracle calls.</p>
<p>Let <span class="math inline">k</span> to be the number of elements no larger than <span class="math inline">\lambda^*</span>. We can get running time relative to <span class="math inline">k</span>. Use exponential search until we find the first <span class="math inline">i</span> such that <span class="math inline">M_{2^i,2^i}&gt;\lambda^*</span>. So we can upper bound <span class="math inline">t</span>. Then one can solve the problem with <span class="math inline">2</span> matrices. One <span class="math inline">t\times k</span> matrix and a <span class="math inline">k\times t</span> matrix. The total running time is therefore <span class="math inline">O(\log k+t\log k/t)=O(t\log k)</span>. In fact, we get <span class="math inline">O(\log k)</span> oracle calls and <span class="math inline">O(t\log k)</span> running time. Here we can take <span class="math inline">t</span> to be <span class="math inline">\sqrt{k}</span>, and obtain <span class="math inline">O(\sqrt{k}\log k)</span> time.</p>
<p>Note if we relax on number of oracle calls. I know how to get a <span class="math inline">O(\sqrt{k})</span> running time.</p>
<section class="theorem-environment Theorem" id="Theorem-2">
<span class="theorem-header"><span class="type">Theorem</span><span class="index">2</span></span>
<p>Given <span class="math inline">\lambda^*</span> and a <span class="math inline">n\times m</span> sorted matrix such that the <span class="math inline">i</span>th row has <span class="math inline">k_i</span> elements no larger than <span class="math inline">x</span>. Let <span class="math inline">k=\sum_{i} k_i</span>. We can find <span class="math inline">\lambda^*</span> in <span class="math inline">O(\sum_{i} \log (k_{i+1}-k_i+1) ) = O(n \log \frac{k/n^2})</span> time.</p>
</section>
<p>The idea is simple, we do exponential search on each row to find the largest element no larger than <span class="math inline">\lambda^*</span>, but we reuse information from the previous row. This gives us the running time <span class="math inline">O(\sum_{i} \log (k_{i+1}-k_i+1) )</span>. The main difficulty is to show why is is <span class="math inline">O(n \log \frac{k/n^2})</span>. Once we show that, we can use the theorem to obtain <span class="math inline">O(\sqrt{k})</span> running time.</p>
<h1 id="remark"><span class="header-section-number">1</span> Remark</h1>
<p>There is an alternative algorithm which can be found in <span class="citation" data-cites="JacobR08">[<a href="#ref-JacobR08">3</a>]</span>. The alternative algorithm is quite close to a post about <a href="https://chaoxuprime.com/posts/2014-04-02-selection-in-a-sorted-matrix.html">selection in a sorted matrix</a>.</p>
<p>The careful reader might observe the known search algorithms follow the exact same structure as algorithms for selection. Indeed, we <em>are</em> doing selection but we do not know the rank of the element. Intuitively, many selection algorithm, the rank is <em>only used</em> to remove the correct set of candidates. Hence this suggest one can modify the algorithm to use the oracle call in place of the rank.</p>
<h1 id="bibliography" class="unnumbered">References</h1>
<div id="refs" class="references">
<div id="ref-FredericksonZ17">
<p>[1] G.N. Frederickson, S. Zhou, <strong>Optimal parametric search for path and tree partitioning</strong>, CoRR. abs/1711.00599 (2017).</p>
</div>
<div id="ref-FredericksonJ84">
<p>[2] G. Frederickson, D. Johnson, <strong>Generalized selection and ranking: Sorted matrices</strong>, SIAM Journal on Computing. 13 (1984) 14–30 <a href="https://doi.org/10.1137/0213002">10.1137/0213002</a>.</p>
</div>
<div id="ref-JacobR08">
<p>[3] R. Jacob, <strong>Binary search on two-dimensional data</strong>, Technische Universität München, 2008.</p>
</div>
</div>

</div>
<div class="hide-on-print">
    <div class="info">Posted by <a href="https://chaoxuprime.com">Chao Xu</a> on 2019-01-30. </div>
    <div class="info">Tags: algorithm, data structure.</div>

</div>]]></description>
    <pubDate>Wed, 30 Jan 2019 00:00:00 UT</pubDate>
    <guid>https://chaoxuprime.com/blog/posts/2019-01-30-search-sorted-matrix.html</guid>
    <dc:creator>Chao Xu</dc:creator>
</item>
<item>
    <title>A Reviewer Assignment Problem</title>
    <link>https://chaoxuprime.com/blog/posts/2019-01-29-reviewer-assignment.html</link>
    <description><![CDATA[<br />
<div>
<p>Consider there are some reviewers and some papers. Each reviewer can review exactly one paper, and each reviewer is qualified to review some subset of papers. We are interested in maximizing the number of papers reviewed by at least <span class="math inline">k</span> reviewer, then under that constraint, maximize the paper reviewed by <span class="math inline">k+1</span> reviewer, etc. This make sure we are being fair in evaluating papers. It would try to avoid the case where most paper getting small number of reviews and a few papers getting unreasonable number of reviews.</p>
<p>Formally, we are given a bipartite graph <span class="math inline">G=(A,B,E)</span> of <span class="math inline">n</span> vertices and <span class="math inline">m</span> edges. A subset of edges <span class="math inline">M</span> is called a semi-matching, if <span class="math inline">\deg_M(v)=1</span> for all <span class="math inline">v\in A</span>. For a subset of edges <span class="math inline">M</span>, let <span class="math inline">g_M(i)</span> to be the number of vertices in <span class="math inline">B</span> with degree at least <span class="math inline">i</span>. We want to find a semi-matching <span class="math inline">M</span>, such that <span class="math inline">(g_M(k),g_M(k+1),\ldots,g_M(n))</span> is lexicographically maximum.</p>
<p>When <span class="math inline">k=1</span>, if <span class="math inline">M</span> minimizes the sum of the function <span class="math inline">\sum_{v\in B} f(\deg_M(v))</span> for any strictly convex increasing function <span class="math inline">f</span>, then <span class="math inline">(g_M(1),g_M(2),\ldots,g_M(n))</span> is lexicographically maximum. The problem therefore can be reduced to min-cost flow can be applied here directly, and obtain a polynomial time algorithm <span class="citation" data-cites="HarveyLLT06">[<a href="#ref-HarveyLLT06">1</a>]</span>.</p>
<p>When <span class="math inline">k=3</span>, the problem is NP-hard, since it would imply we have to maximized <span class="math inline">g_M(3)</span>, and this is already NP-hard because exact cover by <span class="math inline">3</span>-sets. That is, given a collection of sets of size <span class="math inline">3</span> each. Decide if there exists a subcollection that forms a partition of the universe.</p>
<p>The only unresolved case is <span class="math inline">k=2</span>. Interestingly, we can show it is also polynomial time solvable. First, one can see that maximizing <span class="math inline">(g_M(2),g_M(3),\ldots,g_M(n))</span> is equivalent to minimize <span class="math inline">\sum_{v, \deg_M(v)\geq 2} f(\deg_M(v))</span> for some strictly convex increasing function <span class="math inline">v</span>, and <span class="math inline">M</span> range through all semi-matchings so each vertex in <span class="math inline">B</span> has degree exactly <span class="math inline">2</span> (Assuming it exists).</p>
<p>Apollonio and Sebő shown the following problem is polynomial time solvable <span class="citation" data-cites="ApollonioS09">[<a href="#ref-ApollonioS09">2</a>]</span>.</p>
<section class="theorem-environment Problem" id="Problem-1">
<span class="theorem-header"><span class="type">Problem</span><span class="index">1</span></span>
<p>Given a graph <span class="math inline">G=(V,E)</span>, a integer <span class="math inline">k</span>, convex functions <span class="math inline">f_v:\N \to \R</span> for each <span class="math inline">v\in V</span>, and an edge cost function <span class="math inline">c:E\to \R</span>. One can find the following in polynomial time. <span class="math display">\displaystyle \min \left\{   \sum_{v\in V} f_v(\deg_M(v)) + \sum_{e\in M} c(e) \middle| M\subseteq E, |M|=k  \right\}</span></p>
</section>
<p>It's not hard to generalize it a bit further by requiring <span class="math inline">M</span> to respect some upper and lower bound on the vertices. Indeed, we can let <span class="math inline">f_v:\N\to \R\cup \set{\infty}</span>, and set <span class="math inline">f_v(x)=\infty</span> if <span class="math inline">x</span> is not between the upper and lower bounds.</p>
<p>Now, we are going to reduce the problem. The reduction is similar to the <a href="https://cstheory.stackexchange.com/questions/33857/is-two-or-zero-matching-in-a-bipartite-graph-np-complete/33859">one for <span class="math inline">2</span>-or-<span class="math inline">0</span> matching</a>.</p>
<p>For each vertex <span class="math inline">v\in B</span>, split into two vertices <span class="math inline">v_1</span> and <span class="math inline">v_2</span>. Define <span class="math inline">B_i=\set{v_1|v\in B}</span>. The new input graph consists of vertices <span class="math inline">B_1\cup B_2 \cup A</span>. <span class="math inline">v_1</span> and <span class="math inline">v_2</span> connects to the same vertices as <span class="math inline">v</span>. We add an edge between <span class="math inline">v_1</span> and <span class="math inline">v_2</span>, with very large cost <span class="math inline">C</span>. Say <span class="math inline">C=mn^2+1</span>. <span class="math inline">v_1</span> has both an upper and lower bound of <span class="math inline">1</span>. <span class="math inline">v_2</span> has a lower bound of <span class="math inline">1</span>. For each vertex in <span class="math inline">A</span>, add an upper and lower bound of <span class="math inline">1</span>. We have a strict convex function <span class="math inline">f_{v_2}(x)=x^2</span> on each vertex <span class="math inline">v_2</span>.</p>
<p>Let <span class="math inline">r=|A|</span>, <span class="math inline">p=|B|</span>. We solve <a href="#Problem-1">Problem 1</a> repeatedly for each <span class="math inline">k</span> from <span class="math inline">r</span> to <span class="math inline">r+p</span>.</p>
<p>Say there exists an optimal solution to the original problem with exactly <span class="math inline">t</span> vertices in <span class="math inline">B</span> with degree smaller than <span class="math inline">2</span>. Find the optimal solution to the new problem with <span class="math inline">k=r+t</span>. Let it be <span class="math inline">M&#39;</span>. We obtain <span class="math inline">M</span> from <span class="math inline">M&#39;</span> by identify pairs of vertices <span class="math inline">v_1</span> and <span class="math inline">v_2</span>. <span class="math inline">M</span> would be the solution to the original problem.</p>
<h1 id="extensions"><span class="header-section-number">1</span> Extensions</h1>
<p>I first heard of the problem from <span class="citation" data-cites="YesilcimenY19">[<a href="#ref-YesilcimenY19">3</a>]</span>, where they focused on <span class="math inline">k=1</span> case, but the reviewer can review more than one paper. This case can be handled easily. We can add degree upper and lower bounds to all vertices, and only look at subgraphs in <span class="math inline">M</span> that satisfies the upper and lower bounds. That is, we can also make sure no reviewers review too many papers too. Under that constraint, find <span class="math inline">(g_M(k),\ldots,g_M(n))</span> lexicographically. This is possible but more tricky, as we have to do some reduction from capacitated <span class="math inline">b</span>-matching to <span class="math inline">b</span>-matching.</p>
<p>There is a little more generalization. Assume for each paper, we have a lower bound of reviews <span class="math inline">d_v</span>. That is, it has to be reviewed by at least <span class="math inline">d_v</span> person to be useful. So translating to the graph case, we can impose the constraint that <span class="math inline">\deg_M(v)=0</span> or <span class="math inline">\deg_M(v)\geq d_v</span>. One can see maximizing <span class="math inline">(g_M(2),g_M(3),\ldots,g_M(n))</span> is equivalent to maximizing <span class="math inline">(g_M(1),g_M(2),\ldots,g_M(n))</span> where <span class="math inline">d_v=2</span> for all vertices. Again, one can modify the reduction to handle the case when <span class="math inline">d_v</span> is either <span class="math inline">1</span> or <span class="math inline">2</span>.</p>
<h1 id="bibliography" class="unnumbered">References</h1>
<div id="refs" class="references">
<div id="ref-HarveyLLT06">
<p>[1] N.J. Harvey, R.E. Ladner, L. Lovász, T. Tamir, <strong>Semi-matchings for bipartite graphs and load balancing</strong>, Journal of Algorithms. 59 (2006) 53–78 <a href="https://doi.org/10.1016/j.jalgor.2005.01.003">10.1016/j.jalgor.2005.01.003</a>.</p>
</div>
<div id="ref-ApollonioS09">
<p>[2] N. Apollonio, A. Sebő, <strong>Minconvex factors of prescribed size in graphs</strong>, SIAM Journal on Discrete Mathematics. 23 (2009) 1297–1310 <a href="https://doi.org/10.1137/060651136">10.1137/060651136</a>.</p>
</div>
<div id="ref-YesilcimenY19">
<p>[3] A. Yeşilçimen, E.A. Yildirim, <strong>An alternative polynomial-sized formulation and an optimization based heuristic for the reviewer assignment problem</strong>, European Journal of Operational Research. (2019) <a href="https://doi.org/10.1016/j.ejor.2019.01.035">10.1016/j.ejor.2019.01.035</a>.</p>
</div>
</div>

</div>
<div class="hide-on-print">
    <div class="info">Posted by <a href="https://chaoxuprime.com">Chao Xu</a> on 2019-01-29. </div>
    <div class="info">Tags: algorithm, matching.</div>

</div>]]></description>
    <pubDate>Tue, 29 Jan 2019 00:00:00 UT</pubDate>
    <guid>https://chaoxuprime.com/blog/posts/2019-01-29-reviewer-assignment.html</guid>
    <dc:creator>Chao Xu</dc:creator>
</item>
<item>
    <title>Soft heap and selection</title>
    <link>https://chaoxuprime.com/blog/posts/2019-01-22-soft-heap-and-selection.html</link>
    <description><![CDATA[<br />
<div>
<p>I enjoyed the workshop <a href="https://simplicityinalgorithms.com/">SOSA</a> a lot (Disclaimer: I have a paper in SOSA). The papers are simple and fun. I liked the paper <span class="citation" data-cites="KaplanKZZ18">[<a href="#ref-KaplanKZZ18">1</a>]</span> the most, because I learned some really interesting tricks with <a href="https://en.wikipedia.org/wiki/Soft_heap">soft heap</a>.</p>
<p>Here I give a teaser of two things soft heap can do.</p>
<p>We consider a minimalistic soft heap, as there are soft heap with more operations.</p>
<ul>
<li><code>soft-heap(ε)</code>: creates an empty soft heap with error parameter <span class="math inline">\e</span>.</li>
<li><code>insert(e)</code>: insert an element into the heap.</li>
<li><code>extract-min()</code>: return the element of minimum key in heap, and set of newly corrupted elements since last extraction.</li>
</ul>
<p>The operation <code>insert</code> takes <span class="math inline">O(1)</span> time, <code>extract-min()</code> takes <span class="math inline">O(1/\e)</span> time. In this article, we can assume <span class="math inline">\e=1/4</span>.</p>
<p>During each insertion, the key of some elements might be increased. An element is corrupted if its key in the heap is strictly greater than the original key. If there are <span class="math inline">I</span> insertions into the soft heap, then at most <span class="math inline">\eI</span> elements can be corrupted.</p>
<p>Although <code>extract-min()</code> might return an element that is not necessarily the minimum, but there is a bound on the amount of possible errors. Before <span class="citation" data-cites="KaplanKZZ18">[<a href="#ref-KaplanKZZ18">1</a>]</span>, I don't know of any application of soft heap other than vaguely knowing about it was used for minimum spanning tree.</p>
<h1 id="linear-time-selection-in-unordered-list"><span class="header-section-number">1</span> Linear time selection in unordered list</h1>
<p>We insert all elements into the soft-heap, and then we apply <code>extract-min</code> <span class="math inline">(1-\e)n/2</span> times, and find the maximum element <span class="math inline">e</span>. One can see the rank of <span class="math inline">e</span> lies between <span class="math inline">(1-\e)n/2</span> and <span class="math inline">(1+\e)n/2</span>. Now we can use this to remove at least <span class="math inline">(1-\e)n/2=\frac{1+\e}{2} n</span> elements, and recurse on the remaining. Once there is only a constant number of elements, use brute force. This gives us an running time <span class="math inline">T(n) = O(n) + T(\frac{1+\e}{2} n) = O(n)</span>.</p>
<h1 id="linear-time-selection-in-heap"><span class="header-section-number">2</span> Linear time selection in heap</h1>
<p>We are given a min heap <span class="math inline">H</span>, and interested in find the <span class="math inline">k</span>th smallest element in the heap. We first insert the min element <span class="math inline">e</span> into the soft heap.</p>
<p>Whenever we apply <code>extract-min</code> to the soft heap, we obtain <span class="math inline">e</span> and a set of newly corrupted elements <span class="math inline">C</span>. For each element <span class="math inline">e&#39;\in C</span>, we add the children of <span class="math inline">e&#39;</span> in <span class="math inline">H</span> into the soft heap. If <span class="math inline">e</span> is not corrupted, we also add the children of <span class="math inline">e</span> in <span class="math inline">H</span> into the soft heap. Once we apply <code>extract-min</code> <span class="math inline">k-1</span> times we stop. Let <span class="math inline">S</span> be the set of all elements that was inserted into the soft heap. There are two important claims: <span class="math inline">|S|=O(k)</span> and the rank <span class="math inline">k</span> element has to be in <span class="math inline">S</span>. We can use a linear time selection algorithm on <span class="math inline">S</span> once we prove the two claims.</p>
<h1 id="other-useful-results"><span class="header-section-number">3</span> Other useful results</h1>
<p>There are some other nice results in the paper. Getting optimal results for selecting the rank <span class="math inline">k</span> element in <span class="math inline">m</span> sorted lists, and selecting <span class="math inline">k</span>th element in <span class="math inline">X+Y = \set{x+y | x\in X, y\in Y}</span>.</p>
<h1 id="bibliography" class="unnumbered">References</h1>
<div id="refs" class="references">
<div id="ref-KaplanKZZ18">
<p>[1] H. Kaplan, L. Kozma, O. Zamir, U. Zwick, Selection from Heaps, Row-Sorted Matrices, and X+Y Using Soft Heaps, in: J.T. Fineman, M. Mitzenmacher (Eds.), 2nd Symposium on Simplicity in Algorithms (Sosa 2019), Schloss Dagstuhl–Leibniz-Zentrum fuer Informatik, Dagstuhl, Germany, 2018: pp. 5:1–5:21 <a href="https://doi.org/10.4230/OASIcs.SOSA.2019.5">10.4230/OASIcs.SOSA.2019.5</a>.</p>
</div>
</div>

</div>
<div class="hide-on-print">
    <div class="info">Posted by <a href="https://chaoxuprime.com">Chao Xu</a> on 2019-01-22. </div>
    <div class="info">Tags: algorithm, data structure.</div>

</div>]]></description>
    <pubDate>Tue, 22 Jan 2019 00:00:00 UT</pubDate>
    <guid>https://chaoxuprime.com/blog/posts/2019-01-22-soft-heap-and-selection.html</guid>
    <dc:creator>Chao Xu</dc:creator>
</item>
<item>
    <title>The high-degree low-degree technique and arboricity</title>
    <link>https://chaoxuprime.com/blog/posts/2019-01-21-high-degree-low-degree-technique.html</link>
    <description><![CDATA[<br />
<div>
<p>In this piece we demonstrate the high-degree low-degree technique in graphs. Often, we obtain running times that depends on the individual degrees of the vertices. If the graph has only low degree vertices, then a faster algorithm exists. For graph with only large degrees, then it is dense, and can often be handled in another way.</p>
<p>We will also use the information of <a href="https://en.wikipedia.org/wiki/Arboricity">arboricity</a>. Mainly, there are a few useful statements.</p>
<section class="theorem-environment Theorem" id="Theorem-1">
<span class="theorem-header"><span class="type">Theorem</span><span class="index">1</span></span>
<p>For a graph <span class="math inline">G=(V,E)</span> with arboricity <span class="math inline">\alpha</span>, we have <span class="math display">\displaystyle 
    \sum_{uv\in E} \min(\deg(u),\deg(v)) \leq 2\alpha m
</span></p>
</section>
<p>Often, using the arboricity, we can obtain the same complexity algorithm without high-degree low-degree technique. Note the arboricity is <span class="math inline">O(\sqrt{m})</span>. The application of arboricity are from <span class="citation" data-cites="ChibaN85">[<a href="#ref-ChibaN85">1</a>]</span>.</p>
<p>Some of the algorithms described can be speedup by using matrix multiplication, or faster combinatorial boolean matrix multiplication. We avoid them for simplicity of exposition.</p>
<h1 id="dominating-set-with-few-edges"><span class="header-section-number">1</span> Dominating set with few edges</h1>
<p>The set cover problem, given <span class="math inline">\mathcal{S} = \set{S_1,\ldots,S_n}</span> are <span class="math inline">n</span> set contains a total of <span class="math inline">m</span> elements. <span class="math inline">U=\bigcup_{S\in \mathcal{S}} S</span> is the universe, with size <span class="math inline">u</span>.</p>
<section class="theorem-environment Theorem" id="Theorem-2">
<span class="theorem-header"><span class="type">Theorem</span><span class="index">2</span></span>
<p>There is a probability distribution <span class="math inline">D</span> over <span class="math inline">\mathcal{S}</span>, such that for each <span class="math inline">u</span>, the probability a random set <span class="math inline">S</span> covers <span class="math inline">u</span> is at least <span class="math inline">\e</span>. There exists a set cover of <span class="math inline">\ceil{\frac{\log u}{\e}}</span>.</p>
</section>
<section class="theorem-environment Proof" id="Proof-">
<span class="theorem-header"><span class="type">Proof</span></span>
<p>There exists a set that covers at least <span class="math inline">\e |U&#39;|</span> for any <span class="math inline">U&#39; \subset U</span>. Therefore each greedy iteration decrease the size of uncovered universe by an <span class="math inline">\e</span> fraction. So there can be at most <span class="math inline">t</span> iterations, where <span class="math inline">(1-\e)^t&lt;1</span>. One can show <span class="math inline">\ceil{\frac{\log u}{\e}}</span> suffices.</p>
</section>
<section class="theorem-environment Theorem" id="Theorem-3">
<span class="theorem-header"><span class="type">Theorem</span><span class="index">3</span></span>
<p>There is a dominating set incident to <span class="math inline">O(n\sqrt{n\log n})</span> edges.</p>
</section>
<section class="theorem-environment Proof" id="Proof-">
<span class="theorem-header"><span class="type">Proof</span></span>
<p>Fix a <span class="math inline">\delta</span>. We repeatedly removing vertices with degree no more than <span class="math inline">\delta</span> from the graph, and add it into a set <span class="math inline">D</span>. The total degree of <span class="math inline">D</span> is at most <span class="math inline">n\delta</span>. Now the remaining vertices has degree at least <span class="math inline">\delta</span>. Using the set cover theorem, and let the distribution to be the uniform distribution. If all elements are covered at least by <span class="math inline">\e</span> fraction of the set, then we obtain a set cover of size <span class="math inline">O(\frac{\log u}{\e})</span>. Now, let the sets <span class="math inline">N(v)</span> for each <span class="math inline">v</span>. Since degree is bounded by at most <span class="math inline">n</span>, we can obtain a dominating set of size <span class="math inline">O(\frac{n\log n}{e})</span>. We set <span class="math inline">\e=\delta/n</span>. Since the degree of each vertex is at least <span class="math inline">\delta</span>, then there is a covering of <span class="math inline">O(\frac{n^2\log n}{\delta})</span>. Add the vertices induces this set cover to <span class="math inline">D</span>. <span class="math inline">D</span> is a dominating set, and its size is <span class="math inline">O(n\delta +\frac{n^2\log n}{\delta})</span>, set <span class="math inline">\delta=\sqrt{n\log n}</span> and we obtain the desired result.</p>
</section>
<p>One can show the above result is almost optimal, as there exists graphs where every dominating set incidents <span class="math inline">\Omega(n^{3/2})</span> edges. The same bound holds for weakly connected dominating set, that is a dominating set <span class="math inline">D</span> such that the edges incident to <span class="math inline">D</span> forms a connected graph. The stronger modification of this result was used in deciding the <span class="math inline">4</span>-connectivity of a matroid <span class="citation" data-cites="Rajan87">[<a href="#ref-Rajan87">2</a>]</span>.</p>
<h1 id="finding-small-subgraphs"><span class="header-section-number">2</span> Finding small subgraphs</h1>
<h2 id="finding-a-triangle"><span class="header-section-number">2.1</span> Finding a triangle</h2>
<p>A <em>triangle</em> is <span class="math inline">3</span> vertices pairwise adjacent to each other, another name for <span class="math inline">K_3</span>.</p>
<section class="theorem-environment Theorem" id="Theorem-4">
<span class="theorem-header"><span class="type">Theorem</span><span class="index">4</span></span>
<p>There is a <span class="math inline">O(m\Delta)</span> time algorithm to decide if the graph has a triangle, where <span class="math inline">\Delta</span> is the maximum degree.</p>
</section>
<section class="theorem-environment Proof" id="Proof-">
<span class="theorem-header"><span class="type">Proof</span></span>
<p>Indeed, for each vertex <span class="math inline">v</span>, we consider its neighbors, see if any is adjacent to each other. We then delete <span class="math inline">v</span>. The algorithm takes <span class="math inline">O(\sum_{v} \deg^2(v)) = O(m\Delta)</span> time.</p>
</section>
<section class="theorem-environment Theorem" id="Theorem-5">
<span class="theorem-header"><span class="type">Theorem</span><span class="index">5</span></span>
<p>There is a <span class="math inline">O(n^3)</span> time algorithm to decide if the graph has a triangle.</p>
</section>
<section class="theorem-environment Proof" id="Proof-">
<span class="theorem-header"><span class="type">Proof</span></span>
<p>The naive algorithm, for each <span class="math inline">3</span> vertices, we decide if it forms a triangle.</p>
</section>
<section class="theorem-environment Theorem" id="Theorem-6">
<span class="theorem-header"><span class="type">Theorem</span><span class="index">6</span></span>
<p>There is a <span class="math inline">O(m^{3/2})</span> time algorithm to decide if the graph has a triangle.</p>
</section>
<section class="theorem-environment Proof" id="Proof-">
<span class="theorem-header"><span class="type">Proof</span></span>
<p>Let <span class="math inline">t</span> be a parameter we will find later. Apply the above algorithm by picking the vertex with the smallest degree, until the next vertex has degree at least <span class="math inline">t</span>. It will use at most <span class="math inline">O(mt)</span> time. Now, for the remaining graph, it is clear the maximum degree is at least <span class="math inline">t</span>. Note, there can be at most <span class="math inline">n/t</span> vertices. We use the <span class="math inline">O(n^3)</span> time algorithm. The final running time is <span class="math inline">O(mt+(m/t)^3)</span>. Set <span class="math inline">t=\sqrt{m}</span> and we are done.</p>
</section>
<section class="theorem-environment Proof" id="Proof-">
<span class="theorem-header"><span class="type">Proof</span><span class="name">Alternative</span></span>
<p>We modify the algorithm a little. For each vertex <span class="math inline">v</span>, we consider its neighbor <span class="math inline">u</span>, and check if <span class="math inline">u</span> has a neighbor that is in <span class="math inline">v</span>. Then we delete <span class="math inline">v</span>, and move on to next vertex. The running time become <span class="math inline">\sum_{v\in V} (\deg(v)+\sum_{u\in N(v)} \deg(u))</span>. Now, assume we pick vertices by the <em>largest</em> to <em>smallest</em> in term of degrees. We rearrange the sum and obtain <span class="math inline">\sum_{v\in V} (\deg(v)+\sum_{u\in N(v)} \deg(u)) = \sum_{v\in V} \deg(v) + 2 \sum_{uv\in E} \min(\deg(u),\deg(v)) = O(\alpha m)</span>. Because <span class="math inline">\alpha\leq \sqrt{m}</span>, we have the running time <span class="math inline">O(m^{3/2})</span>.</p>
</section>
<h2 id="a-motivating-problem"><span class="header-section-number">2.2</span> A motivating problem</h2>
<p>Let <span class="math inline">S_1,\ldots,S_n</span> be sets with total of <span class="math inline">m</span> elements. How quickly can we find two distinct <span class="math inline">i</span> and <span class="math inline">j</span> such that <span class="math inline">|S_i\cap S_j|\geq \ell</span>? This problem can be shown to be equivalent to finding a colored <span class="math inline">K_{2,\ell}</span> in a bipartite graph. That is, for input bipartite graph <span class="math inline">G=(A,B,E)</span>. Find a <span class="math inline">K_{2,\ell}</span> where the side of two vertices has to be in <span class="math inline">A</span>.</p>
<h2 id="finding-a-c_4-in-bipartite-graphs"><span class="header-section-number">2.3</span> Finding a <span class="math inline">C_4</span> in bipartite graphs</h2>
<p>This section we use technique that follows from <span class="citation" data-cites="AlonYZ97">[<a href="#ref-AlonYZ97">3</a>]</span>. Although we are into finding <span class="math inline">C_4</span>, but some theorems are more general for <span class="math inline">K_{2,\ell}</span>, so we will state them too. Note finding a colored <span class="math inline">K_{2,2}</span> and finding a <span class="math inline">K_{2,2}</span> is the same problem due to symmetry.</p>
<p>Let <span class="math inline">v_1,\ldots,v_n</span> be an ordering such that <span class="math inline">\deg(v_i)\geq \deg(v_j)</span>. There exists an algorithm that finds an ordering of vertices <span class="math inline">v_1,\ldots,v_n</span>, and returns <span class="math inline">N_i(v_i)\cap N_i(v_j)</span> for each <span class="math inline">i</span> and <span class="math inline">j&gt;i</span>. Here <span class="math inline">N_i(v)</span> is the set of neighbors of <span class="math inline">v</span> in <span class="math inline">G[\set{v_i,\ldots,v_n}]</span>. Here we show an algorithm solves the above problem when the arboricity is small.</p>
<p>The algorithm is as follows <span class="citation" data-cites="ChibaN85">[<a href="#ref-ChibaN85">1</a>]</span>. Take <span class="math inline">v</span>, we consider each neighbor <span class="math inline">u</span>. Maintain a set <span class="math inline">S_w</span> for each vertex <span class="math inline">w</span> distance <span class="math inline">2</span> from <span class="math inline">v</span>. Add <span class="math inline">u</span> into each of <span class="math inline">u</span>'s neighbor in <span class="math inline">w</span>. <span class="math inline">S_w</span> would give us information of <span class="math inline">N(v)\cap N(w)</span>. We delete <span class="math inline">v</span> and keep going. It is known the algorithm takes <span class="math inline">O(\alpha(G)m)</span> time. This allows us to compute <span class="math inline">C_4</span> in the same time. Hence we directly obtain <span class="math inline">O(m^{3/2})</span> running time. However, we show something better is possible if we are not interested in finding all <span class="math inline">C_4</span>, but find any <span class="math inline">C_4</span>. We also need the following theorem.</p>
<section class="theorem-environment Theorem" id="Theorem-7">
<span class="theorem-header"><span class="type">Theorem</span><span class="index">7</span></span>
<p>One can check if there exists a <span class="math inline">K_{2,\ell}</span> in the bipartite graph <span class="math inline">G=(A,B,E)</span> in <span class="math inline">O(\ell n^2)</span> time.</p>
</section>
<p>Now, we combine the two algorithms. It requires a theorem in extremal graph theory can be found in <span class="citation" data-cites="Furedi96">[<a href="#ref-Furedi96">4</a>]</span>.</p>
<section class="theorem-environment Theorem" id="Theorem-8">
<span class="theorem-header"><span class="type">Theorem</span><span class="index">8</span><span class="name"><span class="math inline">K_{2,\ell}</span>-free theorem</span></span>
<p>There exists a constant <span class="math inline">c</span>, such that each <span class="math inline">n</span> vertex graph with <span class="math inline">c n^{3/2} \ell^{1/2}</span> edges contains a <span class="math inline">K_{2,\ell}</span>.</p>
</section>
<section class="theorem-environment Theorem" id="Theorem-9">
<span class="theorem-header"><span class="type">Theorem</span><span class="index">9</span></span>
<p>There is a <span class="math inline">O(m^{4/3})</span> time algorithm to find a <span class="math inline">C_4</span> in the graph.</p>
</section>
<section class="theorem-environment Proof" id="Proof-">
<span class="theorem-header"><span class="type">Proof</span></span>
<p>If the arboricity is <span class="math inline">t</span>. We use the first algorithm and we get running time <span class="math inline">O(t m)</span>. Otherwise, we know there is a subgraph with minimum degree at least <span class="math inline">t</span>. The subgraph can be found by repeatedly deleting vertices of minimum degree. The subgraph <span class="math inline">G&#39;</span> with the previous property has <span class="math inline">n&#39;\leq n</span> vertices and <span class="math inline">m&#39;\leq n&#39;t</span> edges. One can see <span class="math inline">n&#39;\leq m&#39;/t\leq m/t</span>. If <span class="math inline">cn&#39;^{3/2}\leq m&#39; \leq n&#39;t</span>, then we know there exists a <span class="math inline">C_4</span> in <span class="math inline">G&#39;</span> by the previous theorem, and we can apply the <span class="math inline">O(n^2)</span> time algorithm in the subgraph to find the <span class="math inline">C_4</span>. The total running time is therefore <span class="math inline">O(tm + n&#39;^2) = O(tm+(m/t)^2)</span>. We set <span class="math inline">t=c^{3/2} m^{1/3}</span>. One can check after lot of algebra, it make sure the condition <span class="math inline">cn&#39;^{3/2}\leq n&#39;t</span> is satisfied. The algorithm takes <span class="math inline">O(m^{4/3})</span> time.</p>
</section>
<h2 id="finding-a-colored-k_23-in-bipartite-graphs"><span class="header-section-number">2.4</span> Finding a colored <span class="math inline">K_{2,3}</span> in bipartite graphs</h2>
<p>For finding <span class="math inline">K_{2,\ell}</span>, the low arboricity algorithm for <span class="math inline">C_4</span> works here. The <span class="math inline">O(\alpha(G)m)</span> algorithm is still fine. It's not hard to generalize and show a <span class="math inline">O(\ell^{1/3}m^{4/3})</span> running time algorithm.</p>
<p>However, in order to solve the motivating problem. We need a colored <span class="math inline">K_{2,\ell}</span>.</p>
<p>Let's consider a <span class="math inline">K_{2,\ell}</span> in <span class="math inline">G</span>, and consider the first indexed vertex <span class="math inline">v</span>. If <span class="math inline">v\in A</span>, then we are done, as the algorithm will find it. If <span class="math inline">v\in B</span>, then we will solve the problem in another way, which gives us some time improvement when <span class="math inline">\ell=3</span>.</p>
<p>For each <span class="math inline">v_i</span> in <span class="math inline">B</span>, we consider <span class="math inline">v_j\in B</span> that has distance <span class="math inline">2</span> from <span class="math inline">v_i</span> and <span class="math inline">j&gt;i</span>. We consider the set of vertices <span class="math inline">S_{i,j} = N_i(v_i)\cap N_i(v_j)</span>. If there are two sets <span class="math inline">S_{i,j}</span> and <span class="math inline">S_{a,b}</span> has intersection size at least <span class="math inline">2</span>, then we claim there exists a <span class="math inline">K_{2,3}</span> in <span class="math inline">G</span>. Now, this becomes finding a <span class="math inline">C_4</span> in the input sets. The total size of the input sets are <span class="math inline">O(\alpha(G)m)</span>. Hence we can use <span class="math inline">O((\alpha(G)m)^{4/3})</span> time to find a <span class="math inline">C_4</span>. Hence this implies a <span class="math inline">O((\alpha(G)m)^{4/3})</span> time algorithm to find a <span class="math inline">K_{2,3}</span>.</p>
<p>Using the idea for finding <span class="math inline">C_4</span>, we can mix the <span class="math inline">((\alpha(G)m)^{4/3})</span> time algorithm and the <span class="math inline">O(n^2)</span> time algorithm. Working out the algebra shows the following theorem.</p>
<section class="theorem-environment Theorem" id="Theorem-10">
<span class="theorem-header"><span class="type">Theorem</span><span class="index">10</span></span>
<p>There is a <span class="math inline">O(m^{28/15})</span> time algorithm for finding a colored <span class="math inline">K_{2,3}</span>.</p>
</section>
<h1 id="bibliography" class="unnumbered">References</h1>
<div id="refs" class="references">
<div id="ref-ChibaN85">
<p>[1] N. Chiba, T. Nishizeki, <strong>Arboricity and Subgraph Listing Algorithms</strong>, SIAM Journal on Computing. 14 (1985) 210–223 <a href="https://doi.org/10.1137/0214017">10.1137/0214017</a>.</p>
</div>
<div id="ref-Rajan87">
<p>[2] A. Rajan, Algorithmic applications of connectivity and related topics in matroid theory, PhD thesis, Northwestern University, 1987.</p>
</div>
<div id="ref-AlonYZ97">
<p>[3] N. Alon, R. Yuster, U. Zwick, <strong>Finding and counting given length cycles</strong>, Algorithmica. 17 (1997) 209–223 <a href="https://doi.org/10.1007/BF02523189">10.1007/BF02523189</a>.</p>
</div>
<div id="ref-Furedi96">
<p>[4] Z. Füredi, <strong>New asymptotics for bipartite turán numbers</strong>, Journal of Combinatorial Theory, Series A. 75 (1996) 141–144 <a href="https://doi.org/10.1006/jcta.1996.0067">10.1006/jcta.1996.0067</a>.</p>
</div>
</div>

</div>
<div class="hide-on-print">
    <div class="info">Posted by <a href="https://chaoxuprime.com">Chao Xu</a> on 2019-01-21. </div>
    <div class="info">Tags: algorithm, graph.</div>

</div>]]></description>
    <pubDate>Mon, 21 Jan 2019 00:00:00 UT</pubDate>
    <guid>https://chaoxuprime.com/blog/posts/2019-01-21-high-degree-low-degree-technique.html</guid>
    <dc:creator>Chao Xu</dc:creator>
</item>
<item>
    <title>Lights out game on a grid</title>
    <link>https://chaoxuprime.com/blog/posts/2019-01-12-lights-out-game.html</link>
    <description><![CDATA[<br />
<div>
<section class="theorem-environment Problem" id="Problem-1">
<span class="theorem-header"><span class="type">Problem</span><span class="index">1</span></span>
<p>Let <span class="math inline">G</span> be a graph, let <span class="math inline">A</span> be the adjacency matrix of <span class="math inline">G</span>. Solve the equation <span class="math inline">Ax=b</span> in <span class="math inline">\F_2</span>.</p>
</section>
<p>The problem is equivalent to the <a href="https://en.wikipedia.org/wiki/Lights_Out_%28game%29">lights out game</a>. Each vertex has state <span class="math inline">0</span> or <span class="math inline">1</span>. Activate a vertex flips the state of itself and all its neighbors. Find a set of activations that turns all state into <span class="math inline">0</span>. Originally I thought this problem can be solved in <span class="math inline">O(n^{\omega/2})</span> when <span class="math inline">G</span> is planar graph on <span class="math inline">n</span> vertices by <a href="https://en.wikipedia.org/wiki/Nested_dissection">nested dissection</a>. However, only recently I found out the matrix must be non-singular. Therefore nested dissection does not apply.</p>
<p>Recently I saw an algorithm that shows if the graph is a <span class="math inline">n\times n</span> grid, then it can be solved in <span class="math inline">O(n^3)</span> time. The solution in Chinese and can be seen <a href="https://zhuanlan.zhihu.com/p/53646257">here</a>.</p>
<p>Given a <span class="math inline">n\times n</span> grid graph. Let <span class="math inline">v_{i,j}</span> be the node on the <span class="math inline">i</span>th row and <span class="math inline">j</span>th column. Let <span class="math inline">b_{i,j}</span> be the state of the vertex <span class="math inline">v_{i,j}</span>. The state is in <span class="math inline">\F_2</span> If we activates a node, the state of the node and its neighbors change by <span class="math inline">1</span>. The set of activated node is called the activation set.</p>
<p>We are interested in finding an activation set <span class="math inline">S</span>, such the state of all nodes after activate <span class="math inline">S</span> is <span class="math inline">0</span>.</p>
<p>Let <span class="math inline">S</span> be the activation set, and <span class="math inline">S_1</span> to be the activation set of the first row.</p>
<section class="theorem-environment Theorem" id="Theorem-2">
<span class="theorem-header"><span class="type">Theorem</span><span class="index">2</span></span>
<p><span class="math inline">S_1</span> uniquely determines <span class="math inline">S</span>. Moreover, One can compute <span class="math inline">S</span> from <span class="math inline">S_1</span> in <span class="math inline">O(n^2)</span> time.</p>
</section>
<section class="theorem-environment Proof" id="Proof-">
<span class="theorem-header"><span class="type">Proof</span></span>
<p>Indeed, consider apply activation to the nodes in <span class="math inline">S_1</span>. Consider any vertex in row <span class="math inline">1</span>. If it <span class="math inline">0</span>, then the remaining neighbor (on the second row) cannot be activated. If it is <span class="math inline">1</span>, then the remaining neighbor has to be activated.</p>
</section>
<p>Let <span class="math inline">D[i,j]</span> indicates if we activate <span class="math inline">v_{i,j}</span> or not. We create formal variables <span class="math inline">Z=\set{z_1,\ldots,z_n}</span>. Here <span class="math inline">z_i</span> is an indicator variable that represents if <span class="math inline">v_{1,i}</span> is activated or not. The base case <span class="math inline">D[1,j] = z_j</span>. The observation shows that for each <span class="math inline">i</span> and <span class="math inline">j</span>, <span class="math inline">D[i+1,j] = 1 + D[i,j-1]+D[i,j]+D[i,j+1]+D[i-1,j]+b_{i,j}</span>. We can express <span class="math inline">D[i,j]</span> as a sum of elements in <span class="math inline">Z</span> and a constant, and we are summing a constant number of previous states. So it has size <span class="math inline">O(n)</span>. We can compute the expression of <span class="math inline">D[i,j]</span> in <span class="math inline">O(n)</span> time. So computing all <span class="math inline">D[i,j]</span> for <span class="math inline">i\geq 2</span> takes <span class="math inline">O(n^3)</span> time.</p>
<p>We are interested in <span class="math inline">D[n,1],\ldots,D[n,n]</span>. We can see it is of the following form.</p>
<p><span class="math display">\displaystyle 
\begin{aligned}
D[n,1] &amp;= c_{1,1} z_1+\ldots +c_{1,n} z_{n} + u_{1}\\
D[n,2] &amp;= c_{2,1} z_1+\ldots +c_{2,n} z_{n} + u_{2}\\
 \vdots &amp;\qquad  \vdots\\
D[n,n] &amp;= c_{m,1} z_1+\ldots + c_{m,n} z_n + u_{n}
\end{aligned}
</span></p>
<p>We solve the equation <span class="math inline">Cz=u</span>. Note here <span class="math inline">C</span> is just a <span class="math inline">n\times n</span> matrix. We finds <span class="math inline">z_1,\ldots,z_n</span>. So now we have found the activation set restricted on the first row. We can use it to find the entire activation set.</p>
<p>The total running time is <span class="math inline">O(n^3)</span>. Building the table <span class="math inline">D</span> and solving <span class="math inline">Cz=u</span>. One can generalize this a bit further. We can obtain <span class="math inline">O(m^2n)</span> running time for a <span class="math inline">m\times n</span> grid, where <span class="math inline">m\leq n</span>. Also, there is no reason we have to work in <span class="math inline">\F_2</span>, any arbitrary field is fine.</p>
<section class="theorem-environment Theorem" id="Theorem-3">
<span class="theorem-header"><span class="type">Theorem</span><span class="index">3</span></span>
<p>Let <span class="math inline">G</span> be a <span class="math inline">m\times n</span> grid and <span class="math inline">A</span> is a matrix where the non-zero entires are precisely the position of <span class="math inline">1</span>s in the adjacency matrix of <span class="math inline">A</span>. Finding <span class="math inline">Ax=b</span> can be done in <span class="math inline">O(m^2n)</span> time.</p>
</section>
<p>I did not think too much into it, but maybe it works for all integral domains too. Interestingly, this algorithm is so special, that we have no idea how to extend it to other graphs. Maybe it works for directed graph, maybe it works for subgraph of the grid graphs.</p>
<p>It would be really interesting to see an algorithm with running time <span class="math inline">O(n^{3/2})</span> for a planar graph of <span class="math inline">n</span> vertices.</p>

</div>
<div class="hide-on-print">
    <div class="info">Posted by <a href="https://chaoxuprime.com">Chao Xu</a> on 2019-01-12. </div>
    <div class="info">Tags: algorithm, algebra.</div>

</div>]]></description>
    <pubDate>Sat, 12 Jan 2019 00:00:00 UT</pubDate>
    <guid>https://chaoxuprime.com/blog/posts/2019-01-12-lights-out-game.html</guid>
    <dc:creator>Chao Xu</dc:creator>
</item>
<item>
    <title>Strings with hamming distance exactly <span class="math inline">1</span></title>
    <link>https://chaoxuprime.com/blog/posts/2018-12-23-strings-with-hamming-distance-exactly-1.html</link>
    <description><![CDATA[<br />
<div>
<p><a href="http://darktef.github.io/">Lin Yang</a> asked me about the complexity for the following problem, which is the day 2 part 2 of the <a href="https://adventofcode.com/2018">advent of code 2018</a>. It is an elegant programming exercise, and also a clever algorithmic exercise. The problem can be summarized below.</p>
<section class="theorem-environment Problem" id="Problem-1">
<span class="theorem-header"><span class="type">Problem</span><span class="index">1</span></span>
<p>Given a set <span class="math inline">W</span> of <span class="math inline">n</span> length <span class="math inline">m</span> strings. Decide if there are two of them that differs at exactly one position.</p>
</section>
<p>In other words, we want to find two strings in <span class="math inline">W</span> with <a href="https://en.wikipedia.org/wiki/Hamming_distance">hamming distance</a> <span class="math inline">1</span>.</p>
<p>The naive algorithm would have running time <span class="math inline">O(n^2m)</span>. The complexity of the problem have gathered a lot of attention a while ago, for example a <a href="https://dev.to/conectado/advent-of-code-day-2-part-2-complexity-556l">post in dev.to</a>, and <a href="https://www.reddit.com/r/adventofcode/comments/a2damm/2018_day2_part_2_a_linear_time_solution/">on reddit</a>. Some of them had a running time of <span class="math inline">O(nm^2)</span> instead. Some require hashing to get the <em>expected</em> running time of <span class="math inline">O(mn)</span>. Here we are interested in an algorithm with <em>worst case</em> <span class="math inline">O(mn)</span> time.</p>
<h1 id="an-omn-time-algorithm"><span class="header-section-number">1</span> An <span class="math inline">O(mn)</span> time algorithm</h1>
<p>First, we define some equivalent classes on the strings in <span class="math inline">W</span>.</p>
<ol type="1">
<li><span class="math inline">x\equiv^i y</span>, if <span class="math inline">x[1..i-1]=y[1..i-1]</span>. Namely, if the first <span class="math inline">i-1</span> elements of <span class="math inline">x</span> and <span class="math inline">y</span> match.</li>
<li><span class="math inline">x\equiv_i y</span> if <span class="math inline">x[i+1..m]=y[i+1..m]</span>. Namely, if the last <span class="math inline">m-i+1</span> elements of <span class="math inline">x</span> and <span class="math inline">y</span> match.</li>
</ol>
<p>The algorithm uses the following idea. For each <span class="math inline">i</span>, decide if there are any strings <span class="math inline">x</span> and <span class="math inline">y</span> such that differs in precisely position <span class="math inline">i</span>.</p>
<section class="theorem-environment Lemma" id="Lemma-2">
<span class="theorem-header"><span class="type">Lemma</span><span class="index">2</span></span>
<p>For distinct <span class="math inline">x</span> and <span class="math inline">y</span>, they differ only in position <span class="math inline">i</span> if and only if <span class="math inline">x\equiv^i y</span> and <span class="math inline">x\equiv_i y</span>.</p>
</section>
<p>Let <span class="math inline">\mathcal{P}_i</span> and <span class="math inline">\mathcal{S}_i</span> be the collection of equivalent classes of <span class="math inline">\equiv^i</span> and <span class="math inline">\equiv_i</span>, respectively. We show a result related to the meet of partitions.</p>
<section class="theorem-environment Lemma" id="Lemma-3">
<span class="theorem-header"><span class="type">Lemma</span><span class="index">3</span></span>
<p>Let <span class="math inline">\mathcal{A}</span> and <span class="math inline">\mathcal{B}</span> be partitions of <span class="math inline">[n]</span>. There is an <span class="math inline">O(n)</span> time algorithm to test find the sets in <span class="math inline">\set{ A\cap B | A\in \mathcal{A}, B\in \mathcal{B}}</span>.</p>
</section>
<section class="theorem-environment Proof" id="Proof-">
<span class="theorem-header"><span class="type">Proof</span></span>
<p>Let <span class="math inline">\mathcal{A}=\set{A_1,\ldots,A_k}</span> and <span class="math inline">\mathcal{B} = \set{B_1,\ldots,B_\ell}</span>. We define <span class="math inline">I_i = (a,b)</span> such that <span class="math inline">i\in A_a</span> and <span class="math inline">i\in B_b</span>. Then we know <span class="math inline">i</span> is in <span class="math inline">A_a\cap B_b</span> if <span class="math inline">I_i=(a,b)</span>. Hence we are interested in find the largest set of elements such <span class="math inline">S</span> such that for <span class="math inline">i,j\in S</span>, <span class="math inline">I_i=I_j</span>. The simplified problem can be solved in <span class="math inline">O(n)</span> time. Indeed, the pair is just a base <span class="math inline">n</span> number with <span class="math inline">2</span> digits. We can apply radix sort with running time <span class="math inline">O(n)</span> and group by the result.</p>
</section>
<p>Note one can also directly use a <a href="https://en.wikipedia.org/wiki/Partition_refinement">partition refinement data structure</a> to get the same result.</p>
<p>As a corollary, consider <span class="math inline">\mathcal{A}=\mathcal{P}_i</span> and <span class="math inline">\mathcal{B}=\mathcal{S}_i</span>, then we obtain the following lemma.</p>
<section class="theorem-environment Lemma" id="Lemma-4">
<span class="theorem-header"><span class="type">Lemma</span><span class="index">4</span></span>
<p>Given the collections <span class="math inline">\mathcal{P}_i</span> and <span class="math inline">\mathcal{S}_i</span>, there is an <span class="math inline">O(n)</span> time algorithm to test if there are two strings <span class="math inline">x,y\in W</span> that differs in precisely position <span class="math inline">i</span>.</p>
</section>
<section class="theorem-environment Lemma" id="Lemma-5">
<span class="theorem-header"><span class="type">Lemma</span><span class="index">5</span></span>
<p>Finding <span class="math inline">\mathcal{P}_1,\ldots,\mathcal{P}_m</span> and <span class="math inline">\mathcal{S}_1,\ldots,\mathcal{S}_m</span> can be done in <span class="math inline">O(mn)</span> time.</p>
</section>
<section class="theorem-environment Proof" id="Proof-">
<span class="theorem-header"><span class="type">Proof</span></span>
<p>To find the equivalent classes, build two tries for the strings. Trie <span class="math inline">T_\mathcal{P}</span> for strings in <span class="math inline">W</span> and trie <span class="math inline">T_\mathcal{S}</span> for the reversal of strings in <span class="math inline">W</span>. Building the tries takes <span class="math inline">O(mn)</span> time. Inspect the nodes at depth <span class="math inline">i-1</span> in <span class="math inline">T_P</span> and nodes at depth <span class="math inline">m-i+1</span> in <span class="math inline">T_S</span> to recover <span class="math inline">\mathcal{P}_i</span> and <span class="math inline">\mathcal{S}_i</span> in <span class="math inline">O(n)</span> time.</p>
</section>
<section class="theorem-environment Theorem" id="Theorem-6">
<span class="theorem-header"><span class="type">Theorem</span><span class="index">6</span></span>
<p>There is an <span class="math inline">O(mn)</span> time algorithm that solves <a href="#Problem-1">Problem 1</a>.</p>
</section>
<section class="theorem-environment Proof" id="Proof-">
<span class="theorem-header"><span class="type">Proof</span></span>
<p>Finding the sequence of equivalent classes takes <span class="math inline">O(mn)</span> time by <a href="#Lemma-4">Lemma 4</a>. For each <span class="math inline">i</span>, checking if there exists <span class="math inline">x,y\in W</span> differs in precisely position <span class="math inline">i</span> takes <span class="math inline">O(n)</span> time by <a href="#Lemma-3">Lemma 3</a>. Since <span class="math inline">i</span> ranges from <span class="math inline">1</span> to <span class="math inline">m</span>, we obtain the final running time is <span class="math inline">O(mn)</span>.</p>
</section>
<h1 id="remarks"><span class="header-section-number">2</span> Remarks</h1>
<p><a href="https://dblp.uni-trier.de/pers/hd/w/Wang:Ruosong">Ruosong Wang</a> communicated another <span class="math inline">O(mn)</span> solution. It is much easier to describe. Let <span class="math inline">\diamond</span> be a symbol not in the alphabet. Build a <a href="https://en.wikipedia.org/wiki/Generalized_suffix_tree">generalized suffix tree</a> over the set of strings <span class="math inline">S&#39;=\set{x\diamond x| x\in W}</span>. Traverse the suffix tree, up to level <span class="math inline">m</span>, and output <code>true</code> if a path that contains <span class="math inline">\diamond</span> was traversed, and can lead to more than <span class="math inline">2</span> leaves. Indeed, this means the substring <span class="math inline">x\diamond y</span> appears at least twice. Hence there are at least two strings of the form <span class="math inline">yax</span> and <span class="math inline">ybx</span> in <span class="math inline">W</span>. This definitely hits the optimal running time, but implementing a generalized suffix tree is fairly hard.</p>
<p>We do assume the alphabet size is constant. If the alphabet size is <span class="math inline">\sigma</span> and ordered, then there is an extra factor of <span class="math inline">\log \sigma</span> in building the tries. The the final running time will be <span class="math inline">O(mn\log \sigma)</span>.</p>
<p><a href="#Problem-1">Problem 1</a> also reduces to finding the closest pair of elements by hamming metric <span class="citation" data-cites="MinKZ09">[<a href="#ref-MinKZ09">1</a>]</span>. It does not get us the desired running time though.</p>
<h1 id="an-implementation-in-haskell"><span class="header-section-number">3</span> An implementation in Haskell</h1>
<p>The implementation is mostly faithful to the presentation in the article. We did not implement counting sort nor radix sort.</p>
<script src="https://gist.github.com/chaoxu/a4a60408a069edf3889e8328e685f700.js"></script>
<h1 id="bibliography" class="unnumbered">References</h1>
<div id="refs" class="references">
<div id="ref-MinKZ09">
<p>[1] K. Min, M.-Y. Kao, H. Zhu, The closest pair problem under the hamming metric, in: H.Q. Ngo (Ed.), Computing and Combinatorics, Springer Berlin Heidelberg, Berlin, Heidelberg, 2009: pp. 205–214.</p>
</div>
</div>

</div>
<div class="hide-on-print">
    <div class="info">Posted by <a href="https://chaoxuprime.com">Chao Xu</a> on 2018-12-23. </div>
    <div class="info">Tags: algorithms, strings, tries.</div>

</div>]]></description>
    <pubDate>Sun, 23 Dec 2018 00:00:00 UT</pubDate>
    <guid>https://chaoxuprime.com/blog/posts/2018-12-23-strings-with-hamming-distance-exactly-1.html</guid>
    <dc:creator>Chao Xu</dc:creator>
</item>
<item>
    <title>Subset sum through balancing</title>
    <link>https://chaoxuprime.com/blog/posts/2018-12-18-subset-sum-through-balancing.html</link>
    <description><![CDATA[<br />
<div>
<p>This is a note for Pisinger's balancing algorithm for subset sum <span class="citation" data-cites="Pisinger19991">[<a href="#ref-Pisinger19991">1</a>]</span>. Let <span class="math inline">\mathcal{S}</span> be the set of all subset sums of <span class="math inline">S</span>. The subset sum problem, the input is <span class="math inline">S\subset \N</span>, and we are interested in checking if <span class="math inline">t\in \mathcal{S}</span>.</p>
<p>We define a variation of the subset sum problem. The <em>balanced subset sum problem</em>. In this problem, we are given a vector <span class="math inline">v</span> of integers(does not have to be positive). We let <span class="math inline">M=\|v\|_\infty</span>. We are interested in find a subset that sums to <span class="math inline">t\in [M]</span>.</p>
<section class="theorem-environment Theorem" id="Theorem-1">
<span class="theorem-header"><span class="type">Theorem</span><span class="index">1</span></span>
<p>Each subset sum problem on <span class="math inline">n</span> elements can be reduced to a balanced subset sum problem in <span class="math inline">n</span> elements in <span class="math inline">O(n)</span> time.</p>
</section>
<section class="theorem-environment Proof" id="Proof-">
<span class="theorem-header"><span class="type">Proof</span></span>
<p>Consider the input to the subset sum problem <span class="math inline">S</span> and <span class="math inline">t</span>. Greedily find a subset of elements <span class="math inline">S&#39;</span>, such that adding any other element will exceed <span class="math inline">t</span>. Let <span class="math inline">\|S&#39;\|_1=t&#39;</span>. Now, we negate all the elements in <span class="math inline">S&#39;</span>, and ask for balanced subset sum with input set <span class="math inline">-S&#39; \cup (S\setminus S&#39;)</span> and target number <span class="math inline">t-t&#39;</span>.</p>
</section>
<p>We partition <span class="math inline">S</span> into <span class="math inline">A = [-M..0]\cap S</span> and <span class="math inline">B=S\setminus A</span>. We also define <span class="math inline">A_i = \set{a_1,\ldots,a_i}</span> and <span class="math inline">B_i=\set{b_1,\ldots,b_i}</span>.</p>
<p>A set is balanced by the following recursive definition. Let <span class="math inline">S</span> be a set.</p>
<ul>
<li><span class="math inline">S=\emptyset</span> is balanced.</li>
<li><span class="math inline">\|S\|_1&gt; t</span>, then <span class="math inline">S\cup \set{a}</span> is balanced, where <span class="math inline">a\in A</span>.</li>
<li><span class="math inline">\|S\|_1\leq t</span>, then <span class="math inline">S\cup \set{b}</span> is balanced, where <span class="math inline">b\in B</span>.</li>
</ul>
<p>Consider a set <span class="math inline">T</span>, such that <span class="math inline">(i,j,k)\in T</span> if and only if <span class="math inline">k</span> is a subset sum of <span class="math inline">A_i\cup B_j</span>. Certainly, we are interested if <span class="math inline">(|A|,|B|,t)</span> is in <span class="math inline">T</span>. However, the state space is already <span class="math inline">O(n^2M)</span>, which is no better than the standard dynamic programming algorithm.</p>
<p>There is a nice dominance relation. If <span class="math inline">(i,j,k)\in T</span>, then for <span class="math inline">(i&#39;,j&#39;)\geq (i,j)</span>, we have <span class="math inline">(i&#39;,j&#39;,k)\in T</span>. We can ask for each <span class="math inline">k</span>, what are all the minimal <span class="math inline">(i,j)</span> pairs where <span class="math inline">(i,j,k)\in T</span>. Such value will be <span class="math inline">g(j,k)</span>. Formally, <span class="math inline">g(j,k) = \min \set{i | (i,j,k)\in T}</span>, one can see that <span class="math inline">g(j,k) \geq g(j+1,k)</span>. Also, we know the solution corresponding to <span class="math inline">g(j,k)</span> must contain <span class="math inline">a_{g(j,k)}</span> as an element.</p>
<p>One can get a recurrence relation for <span class="math inline">g</span> as below.</p>
<p><span class="math display">\displaystyle 
g(j,k)= \min \begin{cases}
g(j-1,k)\\
g(j-1,k-b_j) &amp; \text{if }k-b_j\leq t\\
i &amp; \text{if }k-a_i &gt; t \text{ and } i&gt;g(j,k-a_i)
\end{cases}
</span></p>
<p>Fix a <span class="math inline">k</span> and <span class="math inline">j</span>, let <span class="math inline">i</span> to be as small as possible, such that there is <span class="math inline">A_i&#39;\subset A_i</span> and <span class="math inline">B_j&#39;\subset B_j</span> such that <span class="math inline">A_i&#39;\cup B_j&#39;</span> is balanced and sums to <span class="math inline">k</span>. Note that <span class="math inline">a_i\in A_i&#39;</span>.</p>
<p>We obtained <span class="math inline">A_i&#39;\cup B_j&#39;</span> by inserting an element in <span class="math inline">B</span> or <span class="math inline">A</span> to another balanced set. If the inserted element is in <span class="math inline">B</span>, but not <span class="math inline">b_j</span>, then we know <span class="math inline">i=g(j-1,k)</span>. If it is <span class="math inline">b_j</span>, then <span class="math inline">i=g(j-1,k-b_j)</span>. If the last inserted is <span class="math inline">a_i</span>, then <span class="math inline">g(j,k)=i</span>. Note we observe in this case, <span class="math inline">g(j,k-a_i)&lt;i</span>. A direct dynamic programming implementation seems to imply a <span class="math inline">O(n^2M)</span> time algorithm, since there does not seem to be a quick way to obtain <span class="math inline">i</span>.</p>
<p>On the other hand, if we think bottom up instead of top down, we can obtain a better result. Below is the algorithm.</p>
<figure>
<img src="/files/balanced_subsetsum.png" alt="The algorithm" /><figcaption>The algorithm</figcaption>
</figure>
<p>The value <span class="math inline">D[j,k]</span> eventually equals <span class="math inline">g(j,k)</span>. Note we can argue the running time is <span class="math inline">O(nM)</span>, since for each fixed <span class="math inline">k</span>, the final for loop can ran at most <span class="math inline">n</span> times. It is frustrating that the DP algorithm cannot be inferred directly from the recurrence relation. Indeed, we mainly obtained this through the fact that we can prune the search space if we start bottom up, which is unclear from the recurrence relation.</p>
<h1 id="bibliography" class="unnumbered">References</h1>
<div id="refs" class="references">
<div id="ref-Pisinger19991">
<p>[1] D. Pisinger, <strong>Linear time algorithms for knapsack problems with bounded weights</strong>, Journal of Algorithms. 33 (1999) 1–14 <a href="https://doi.org/10.1006/jagm.1999.1034">10.1006/jagm.1999.1034</a>.</p>
</div>
</div>

</div>
<div class="hide-on-print">
    <div class="info">Posted by <a href="https://chaoxuprime.com">Chao Xu</a> on 2018-12-18. </div>
    <div class="info">Tags: algorithms, subset sum.</div>

</div>]]></description>
    <pubDate>Tue, 18 Dec 2018 00:00:00 UT</pubDate>
    <guid>https://chaoxuprime.com/blog/posts/2018-12-18-subset-sum-through-balancing.html</guid>
    <dc:creator>Chao Xu</dc:creator>
</item>
<item>
    <title>Global min-cut with parity constraint on the edges</title>
    <link>https://chaoxuprime.com/blog/posts/2018-11-06-global-min-cut-with-parity-constraint-on-the-edges.html</link>
    <description><![CDATA[<br />
<div>
<p>In a discussion with <a href="https://patrickl.in/">Patrick Lin</a>, a nice problem was born.</p>
<p>Let <span class="math inline">\delta(S)</span> to be the set of edges with exactly one endpoint in <span class="math inline">S</span>. <span class="math inline">\delta^-(S)</span> to be the set of edges with its head in <span class="math inline">S</span> and tail in <span class="math inline">V\setminus S</span>. Given a non-negative weighted graph, we define the cut function <span class="math inline">f:2^V\to \R^+</span> to be <span class="math inline">f(S) = \sum_{e\in \delta(S)} w(e)</span>. For directed graphs, <span class="math inline">f(S) = \sum_{e\in \delta^-(S)} w(e)</span>. <span class="math inline">f(S)</span> is called the value of the cut <span class="math inline">S</span>.</p>
<p>Let <span class="math inline">k</span> be a constant, we consider the following problem.</p>
<section class="theorem-environment Problem" id="Problem-1">
<span class="theorem-header"><span class="type">Problem</span><span class="index">1</span></span>
<p>Give a graph and <span class="math inline">k</span> set of edges <span class="math inline">F_1,\ldots,F_k</span>, <span class="math inline">a_1,\ldots,a_k,b</span>. Find a cut <span class="math inline">S</span> satisfies that <span class="math inline">|\delta(S)\cap F_i|\equiv a_i \pmod b</span> for all <span class="math inline">i</span>, and the value is minimized.</p>
</section>
<p>We will try to reduce this problem to the following</p>
<section class="theorem-environment Problem" id="Problem-2">
<span class="theorem-header"><span class="type">Problem</span><span class="index">2</span><span class="name">submodular minimization under congruence constraints</span></span>
<p>Given <span class="math inline">T_1,\ldots,T_k</span> and a submodular function <span class="math inline">f</span>. Find a set <span class="math inline">S</span> such that <span class="math inline">|T_i\cap S| \equiv a_i\pmod b_i</span>, and <span class="math inline">f(S)</span> is minimized.</p>
</section>
<p>The above problem is known as submodular minimization under congruence constraints. It is known to be solvable in polynomial time under certain conditions on the <span class="math inline">b_i</span>'s <span class="citation" data-cites="NageleSZ18">[<a href="#ref-NageleSZ18">1</a>]</span>. We sketch the reductions.</p>
<h1 id="undirected-case"><span class="header-section-number">1</span> Undirected case</h1>
<p>In the undirected case, we only consider when <span class="math inline">b=2</span>. Patrick showed a the following construction. Create a new graph <span class="math inline">G&#39;</span> as follows. For each <span class="math inline">uv</span> in <span class="math inline">E</span>, split it into edges <span class="math inline">ux</span>, <span class="math inline">xy</span>, <span class="math inline">yv</span>, <span class="math inline">w(ux)=w(yv)=\infty</span>, and <span class="math inline">w(xy)=w(uv)</span>. Let <span class="math inline">T_i</span> contains the vertex <span class="math inline">x</span> and <span class="math inline">y</span> if <span class="math inline">uv\in F_i</span>.<br />
We now solve the submodular minimization under congruence constraints problem on input <span class="math inline">f</span>, which is the cut function for <span class="math inline">G&#39;</span>, and same <span class="math inline">a_1,\ldots,a_k</span> and <span class="math inline">b_1,\ldots,b_k=2</span>.</p>
<h1 id="directed-case"><span class="header-section-number">2</span> Directed case</h1>
<p>In the directed case, a similar approach works. But now, instead of <span class="math inline">\mod 2</span>, we can do <span class="math inline">\mod b</span> for any <span class="math inline">b</span>. We consider the same approach.<br />
<span class="math inline">(u,v) \in E</span> split into <span class="math inline">(u,x_1),\ldots,(x_b,v)</span> and <span class="math inline">w(u,x_1)=w(u,v)</span>, <span class="math inline">w(x_i,x_{i+1})=\infty</span>, <span class="math inline">w(x_b,v)=\infty</span>. Now, let <span class="math inline">T_i</span> contain vertices <span class="math inline">x_1,\ldots,x_b</span> of <span class="math inline">uv\in F_i</span>.</p>
<h1 id="bibliography" class="unnumbered">References</h1>
<div id="refs" class="references">
<div id="ref-NageleSZ18">
<p>[1] M. Nägele, B. Sudakov, R. Zenklusen, Submodular minimization under congruency constraints, in: Proceedings of the Twenty-Ninth Annual Acm-Siam Symposium on Discrete Algorithms, Society for Industrial; Applied Mathematics, Philadelphia, PA, USA, 2018: pp. 849–866.</p>
</div>
</div>

</div>
<div class="hide-on-print">
    <div class="info">Posted by <a href="https://chaoxuprime.com">Chao Xu</a> on 2018-11-06. </div>
    <div class="info">Tags: algorithms, min-cut.</div>

</div>]]></description>
    <pubDate>Tue, 06 Nov 2018 00:00:00 UT</pubDate>
    <guid>https://chaoxuprime.com/blog/posts/2018-11-06-global-min-cut-with-parity-constraint-on-the-edges.html</guid>
    <dc:creator>Chao Xu</dc:creator>
</item>

    </channel>
</rss>
