<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"
    xmlns:dc="http://purl.org/dc/elements/1.1/">
    <channel>
        <title>The Art Gallery Guardian</title>
        <link>https://chaoxuprime.com</link>
        <description><![CDATA[Mostly notes on algorithms]]></description>
        <atom:link href="https://chaoxuprime.com/rss.xml" rel="self"
                   type="application/rss+xml" />
        <lastBuildDate>Thu, 19 Sep 2019 00:00:00 UT</lastBuildDate>
        <item>
    <title>Word break with cost</title>
    <link>https://chaoxuprime.com/posts/2019-09-19-word-break-with-cost.html</link>
    <description><![CDATA[<br />
<div>
<div class="theorem-environment Problem" data-index="1" type="Problem">
<span class="theorem-header"><span class="type">Problem</span><span class="index">1</span></span>
<p>Given a set of strings <span class="math inline">W</span>, a cost function <span class="math inline">c:W\to \R</span> and a string <span class="math inline">s</span>. Find elements <span class="math inline">w_1,\ldots,w_k\in W</span> such that <span class="math inline">s=w_1\ldots w_k</span>, and <span class="math inline">\sum_{i=1}^k c(w_i)</span> is minimized.</p>
</div>
<p>This problem is a generalization of the <a href="https://leetcode.com/problems/word-break/">word break</a> problem on leetcode. Many algorithms you see online assumes that string in <span class="math inline">W</span> has constant length, checking the hash table takes <span class="math inline">O(1)</span> time, and obtain an <span class="math inline">O(n^2)</span> time algorithm. It is not as easy. Here we show an algorithm that considers the strings in <span class="math inline">W</span> have arbitrary length.</p>
<p>Consider the following graph <span class="math inline">G=(V,E)</span>, where <span class="math inline">V=\set{0,\ldots,n}</span>, and there is an edge from <span class="math inline">i</span> and <span class="math inline">j</span>, if <span class="math inline">s[i+1..j]=w\in W</span>, and the label of the edge <span class="math inline">(i,j)</span> is the string <span class="math inline">w</span>, and the cost is <span class="math inline">c(w)</span>. Let <span class="math inline">z</span> be number of substrings in <span class="math inline">s</span> matches some element in <span class="math inline">W</span>. The graph has <span class="math inline">z</span> edges. Note <span class="math inline">z=O(n\sqrt{L})</span>. Indeed, the sum of the length of the labels of all outgoing edges cannot be more than <span class="math inline">L</span>, and the length of each label is different. Hence each vertex can have at most <span class="math inline">O(\sqrt{L})</span> outgoing edges. The graph is a DAG, so we can find the shortest path from <span class="math inline">0</span> to <span class="math inline">n</span> in linear time with respect to the number of edges. This shows if we can compute the graph in <span class="math inline">O(z+L)</span> time, then we solve the problem in <span class="math inline">O(z+L)</span> time.</p>
<p>We can build the Aho–Corasick automaton for <span class="math inline">W</span> in <span class="math inline">O(L)</span> time. It can be used to find all substrings of <span class="math inline">s</span> that matches something in <span class="math inline">W</span> by traversing the automaton once. The running time is the total number of substrings matched, which is <span class="math inline">O(z)</span>. Hence building the graph takes <span class="math inline">O(z+L)</span> time. <span class="math inline">z</span> is clearly no more than <span class="math inline">nm</span>, where <span class="math inline">m=|W|</span>. Also, it is also clear <span class="math inline">z=O(n\sqrt{L})</span>. Indeed, there can be at most <span class="math inline">O(\sqrt{L})</span> edges start from <span class="math inline">i</span>, since each edge has a label of different length, and sum of those length labels is no larger than <span class="math inline">L</span>.</p>
<p>If we only want to know if there exists a solution, then there is a <span class="math inline">\tilde{O}(nL^{1/3}+L)</span> time algorithm <span class="citation" data-cites="BringmannGL17">[<a href="#ref-BringmannGL17" role="doc-biblioref">1</a>]</span>. The algorithm is close to optimal assuming the algorithm is combinatorial and the alphabet can be arbitrarily large.</p>
<p>Can we obtain similar running time for the word break with cost problem? There are evidence against it. If the alphabet is unary, this problem is equivalent to the unbounded knapsack problem, which likely does not have an algorithm with running time <span class="math inline">O((n+n)^{2-\e})</span> for any <span class="math inline">\e&gt;0</span> <span class="citation" data-cites="CyganMWW19">[<a href="#ref-CyganMWW19" role="doc-biblioref">2</a>]</span> and <span class="math inline">m</span> can be as large as <span class="math inline">\Omega(\sqrt{L})</span>. Of course, this does not mean there might not be a <span class="math inline">O(nL^{1/3}+L)</span> time algorithm, since the reduction involved in the paper might not hold when we require <span class="math inline">m=\Omega(\sqrt{L})</span>.</p>
<h1 id="bibliography" class="unnumbered">References</h1>
<div id="refs" class="references" role="doc-bibliography">
<div id="ref-BringmannGL17">
<p>[1] K. Bringmann, A. Grønlund, K.G. Larsen, A dichotomy for regular expression membership testing, in: 2017 Ieee 58th Annual Symposium on Foundations of Computer Science (Focs), 2017: pp. 307–318 <a href="https://doi.org/10.1109/FOCS.2017.36">10.1109/FOCS.2017.36</a>.</p>
</div>
<div id="ref-CyganMWW19">
<p>[2] M. Cygan, M. Mucha, K. Węgrzycki, M. W, <strong>On problems equivalent to (min,+)-convolution</strong>, ACM Trans. Algorithms. 15 (2019) 14:1–14:25 <a href="https://doi.org/10.1145/3293465">10.1145/3293465</a>.</p>
</div>
</div>
</div>
<div class="hide-on-print">
    <div class="info">Posted by <a href="https://chaoxuprime.com">Chao Xu</a> on <time datetime="2019-09-19">2019-09-19</time>. </div>
    <div class="info">Tags: Algorithm.</div>
</div>]]></description>
    <pubDate>Thu, 19 Sep 2019 00:00:00 UT</pubDate>
    <guid>https://chaoxuprime.com/posts/2019-09-19-word-break-with-cost.html</guid>
    <dc:creator>Chao Xu</dc:creator>
</item>
<item>
    <title>Traditional vs Roth IRA under fixed amount of investment</title>
    <link>https://chaoxuprime.com/posts/2019-09-06-traditional-ira-vs-roth-ira.html</link>
    <description><![CDATA[<br />
<div>
<p>I’ve read a lot of articles on Traditional vs Roth IRA, however one can do a serious mathematical analysis of which one is better, given that you want to invest a total of <span class="math inline">x</span> income into the account for a particular year. This means, money over than the contribution limit will be put in a normal investment account.</p>
<p>There is a widely held belief that if your effective tax rate is higher today than when you cash out, it is always better to do pre-tax contribution (Traditional IRA). However, we can show this is not always the case. You need effective tax rate to be somewhat lower unless you are in the lowest of tax bracket. Assume for simplicity, you live in a place without state taxes.</p>
<p>We make the assumption you have enough money to maximize the contribution, but you have even more money left to put in a normal account.</p>
<p>Here are the 3 options.</p>
<ul>
<li>Type 1: (Traditional IRA, 401(k)) No tax when contributing, taxed as ordinary income afterwards.</li>
<li>Type 2: (Roth IRA, Roth 401(k)) Taxed when contributing, and no taxes afterwards.</li>
<li>Type 3: Normal account, taxed when contributing, and tax with either ordinary income or capital gain taxes depending on type.</li>
</ul>
<p>Consider the simplest model. You have a stock that you buy and hold. It generates no dividends. At the time when you sell it, it worths <span class="math inline">k</span> times more. All your money will be going into that stock.</p>
<p>Assume you allocate <span class="math inline">x</span> income into <span class="math inline">x_1,x_2,x_3</span>, which is the amount of income allocated into Type <span class="math inline">1,2,3</span> accounts, respectively.</p>
<p>How much after tax income is generated when you sell the stock?</p>
<p>Let <span class="math inline">\alpha</span> be the (approximate) effective tax rate today, <span class="math inline">\alpha&#39;</span> is an (approximate) effective tax rate when you sell. <span class="math inline">\beta&#39;</span> is the capital gain tax rate.</p>
<p>The after-tax income contributed by each account is</p>
<ul>
<li>Type 1: <span class="math inline">kx_1(1-\alpha&#39;)</span></li>
<li>Type 2: <span class="math inline">kx_2(1-\alpha)</span></li>
<li>Type 3: <span class="math inline">(k-1)x_3(1-\alpha)(1-\beta&#39;) + x_3(1-\alpha) = x_3(1-\alpha)((k-1)(1-\beta&#39;)+1)</span></li>
</ul>
<p>Now, we also have the following constraint. <span class="math inline">x_1+x_2(1-\alpha)=B</span>, where <span class="math inline">B</span> is the maximum contribution into type 1 and type 2 accounts. This happens because they share the same bound (this is true for both 401(k) and IRA). <span class="math inline">x_1+x_2+x_3=x</span>. Since <span class="math inline">B</span> and <span class="math inline">x</span> are fixed, we have <span class="math inline">x_2 = \frac{B-x_1}{1-\alpha}</span>, and <span class="math inline">x_3 = x-x_1-\frac{B-x_1}{1-\alpha}</span></p>
<p>Define <span class="math inline">f(x_1)=kx_1(1-\alpha&#39;) + k(B-x_1) + (x-x_1-\frac{B-x_1}{1-\alpha})(1-\alpha)((k-1)(1-\beta&#39;)+1)</span>, which is a linear function. We take the derivative of <span class="math inline">f</span> and obtain the slope if <span class="math inline">k(\alpha-\alpha&#39;)- (k-1)\alpha\beta&#39;</span>. If the slope is positive, it means when should maximize type <span class="math inline">1</span> account, and if the slope is negative, we should maximize type <span class="math inline">2</span> account.</p>
<p>In order for the inequality to work for all <span class="math inline">k&gt;1</span>, we need <span class="math inline">\alpha-\alpha&#39;\geq \alpha\beta&#39;</span>. In other words, we need <span class="math inline">\alpha&#39;\leq \alpha(1-\beta&#39;)</span> in order to safely say it is better to maximize type 1.</p>
<p>We didn’t even consider what happens if there are dividend involved. It would shift the scale even more toward type 2.</p>
<p>I think the moral of the story is you have to be careful and actually model everything correctly. Also, since there is no way to know the tax rate in the future, some people hedge by putting money in both type 1 and type 2 accounts.</p>
<p>Good thing is that it still suggest pre-tax is better than after-tax if your tax rate is much higher than your future tax rate. Which might not be true if you are very conscious about saving money (for example, save 80% of your income), even you are in the highest tax bracket.</p>
</div>
<div class="hide-on-print">
    <div class="info">Posted by <a href="https://chaoxuprime.com">Chao Xu</a> on <time datetime="2019-09-06">2019-09-06</time>. </div>
    <div class="info">Tags: Tax.</div>
</div>]]></description>
    <pubDate>Fri, 06 Sep 2019 00:00:00 UT</pubDate>
    <guid>https://chaoxuprime.com/posts/2019-09-06-traditional-ira-vs-roth-ira.html</guid>
    <dc:creator>Chao Xu</dc:creator>
</item>
<item>
    <title>Impossibility theorem of marriage tax</title>
    <link>https://chaoxuprime.com/posts/2019-08-28-impossibility-theorm-marriage-tax.html</link>
    <description><![CDATA[<br />
<div>
<p>It is well known that there could be <a href="https://en.wikipedia.org/wiki/Marriage_penalty">marriage penalty or marriage bonus</a>. For example, in 2019, if two people each make more than $306,175, then they have to pay more tax after getting married. In the worst case, they have to pay $8,165 more. Not that bad. However, if one person make all the money, and the other has no income, then together they will always pay a smaller amount of tax.</p>
<p>I always thought this is because the tax code is designed to make sure in a family, there is a sole breadwinner. But recently I realized it is just mathematically impossible to have anything other than a linear tax and preserve some other nice properties.</p>
<p>Indeed, this was shown by Lovell <span class="citation" data-cites="Lovell82">[<a href="#ref-Lovell82" role="doc-biblioref">1</a>]</span>.</p>
<p>Let <span class="math inline">\R_+</span> be the positive reals. Consider functions <span class="math inline">S:\R_+ \to \R_+</span> and <span class="math inline">J:\R_+ \to\R_+</span>. The first is for tax paid for a single person and tax paid for a married couple file jointly. The input for married file jointly is a single number, which is the combination of the taxable income of the couple. This is called horizontal equity in marriage.</p>
<p>Marriage neutral is precisely when <span class="math inline">S(x)+S(y) = J(x+y)</span>. We define a few notions, it is not completely the same as the ones in Lovell’s paper <span class="citation" data-cites="Lovell82">[<a href="#ref-Lovell82" role="doc-biblioref">1</a>]</span>, but it essentially demonstrate the same idea.</p>
<p>A tax function <span class="math inline">T</span> should have the following properties.</p>
<ol type="1">
<li>Reasonable Tax: <span class="math inline">0\leq T(x)\leq x</span>.</li>
<li>Principal of Progressiveness: there is some <span class="math inline">c&gt;0</span> such that <span class="math inline">\frac{T(x)}{x} &gt; \frac{T(y)}{y}</span> for all <span class="math inline">x&gt;y&gt;c</span>.</li>
</ol>
<p>The second one tries to tax the rich more, as in larger proportion of their money. The reasonable tax requirement makes sure <span class="math inline">S(x) = ax</span> for <span class="math inline">a\in[0,1]</span>. It is easy to see we cannot hope to have principal of progressiveness.</p>
<div class="theorem-environment Remark" type="Remark">
<span class="theorem-header"><span class="type">Remark</span></span>
<p>Married filing separately is always no better than them being single and file their own taxes.</p>
</div>
<p>I personally think there should not be a marriage penalty at any income level to encourage marriage. Of course, people might disagree and think the rich should have a marriage penalty, since it is a small amount compare to their total income so they won’t care anyways.</p>
<p>Anyway, consider the world where there can only be marriage bonus. That is we have the property <span class="math inline">S(x)+S(y)\geq J(x+y)</span>. An <em>easy tax function</em> is a function that has reasonable tax property, and is a piecewise-linear convex that has at least <span class="math inline">1</span> breakpoint larger than <span class="math inline">0</span>. This is strictly stronger than principal of progressiveness. This is satisfied by the current personal income tax function used by the IRS.</p>
<p>Let <span class="math inline">S</span> be a easy tax function, then we can obtain an easy tax function <span class="math inline">J</span> that always gives a marriage bonus. Indeed, let <span class="math inline">J = \inf_{a+b=x,a,b\geq 0} S(a)+S(b)</span>. <span class="math inline">J</span> is extreme in a way that any function greater than it at any point will cause marriage penalty. <span class="math inline">J</span> is the infimal convolution of <span class="math inline">S</span> and itself, which would also be piecewise-linear convex. If <span class="math inline">S</span> is the personal income tax function for 2019, then <span class="math inline">J</span> matches the 2019 IRS married file jointly function up to $612,350! It’s just for some reason the IRS decide to cut this <span class="math inline">J</span> off at $612,350, and then impose a higher rate just to penalize families with two very high income earners.</p>
<h1 id="bibliography" class="unnumbered">References</h1>
<div id="refs" class="references" role="doc-bibliography">
<div id="ref-Lovell82">
<p>[1] M.C. LOVELL, <strong>ON taxing marriages</strong>, National Tax Journal. 35 (1982) 507–510.</p>
</div>
</div>
</div>
<div class="hide-on-print">
    <div class="info">Posted by <a href="https://chaoxuprime.com">Chao Xu</a> on <time datetime="2019-08-28">2019-08-28</time>. </div>
    <div class="info">Tags: Tax.</div>
</div>]]></description>
    <pubDate>Wed, 28 Aug 2019 00:00:00 UT</pubDate>
    <guid>https://chaoxuprime.com/posts/2019-08-28-impossibility-theorm-marriage-tax.html</guid>
    <dc:creator>Chao Xu</dc:creator>
</item>
<item>
    <title>Long distance couple back-to-back ticketing</title>
    <link>https://chaoxuprime.com/posts/2019-06-18-long-distance-couple-back-to-back-ticketing.html</link>
    <description><![CDATA[<br />
<div>
<p>The reason I explored <a href="https://chaoxuprime.com/posts/2019-06-15-covert-back-to-back-ticketing.html">an algorithm for covert back-to-back ticketing</a> in the previous blog post, was because as someone currently in a long distance relationship. It is important to save money on travel.</p>
<p>For long distance couples, two people can fly. Consider if the couple decides be together each weekend, one can fly to the city of the other on Friday night, and comes back on Sunday night. Again we can take advantage of the back-to-back ticketing.</p>
<p>Let <span class="math inline">M</span> be a matching of a graph <span class="math inline">G</span> where the edges are two colored. <span class="math inline">M</span> is called <em>valid</em> if vertex <span class="math inline">2i</span> and <span class="math inline">2i-1</span> are contained in the same colored edge in <span class="math inline">M</span>.</p>
<div class="theorem-environment Problem" data-index="1" type="Problem" title="Couple back-to-back ticketing problem">
<span class="theorem-header"><span class="type">Problem</span><span class="index">1</span><span class="name">Couple back-to-back ticketing problem</span></span>
<p><strong>Input:</strong> A multigraph <span class="math inline">G=(V,E)</span> where <span class="math inline">V\subseteq [n]</span>, where each edge can be either red or blue, and there is an edge cost function <span class="math inline">c:E\to \R^+</span>.</p>
<p><strong>Output:</strong> A valid perfect matching <span class="math inline">M</span> (allowing self-loops), such that the cost is minimized.</p>
</div>
<p>Unfortunately, I don’t see how to solve this problem in polynomial time. I could convert this problem to something that might be solved in polynomial time in the future.</p>
<p>Note we can split the vertices. That is, for vertex <span class="math inline">i</span>, we split it into <span class="math inline">(i,R)</span> and <span class="math inline">(i,B)</span> for its blue and red counter part. A matching is <em>paired</em> if <span class="math inline">(2i,C)</span> and <span class="math inline">(2i-1,C)</span> both has to be matched, where <span class="math inline">C\in \set{R,B}</span>. The matching is <em>split</em> if <span class="math inline">(i,R)</span> and <span class="math inline">(i,B)</span> cannot be both in the matching.</p>
<p>If we just enforce one property – paired or split – then it is solvable in polynomial time. Indeed, both are matching under restrictions. We are interested in finding a matching <span class="math inline">M</span>, such that the vertices covered by <span class="math inline">M</span> is in some special structure. Namely <span class="math inline">\Delta</span>-matroid. Since the paired property is a very special <span class="math inline">\Delta</span>-matroid <span class="citation" data-cites="KakimuraT14">[<a href="#ref-KakimuraT14" role="doc-biblioref">1</a>]</span>, which was first solved in <span class="citation" data-cites="HefnerK95">[<a href="#ref-HefnerK95" role="doc-biblioref">2</a>]</span>. The second property is partition matroid, which can be handled by <a href="/posts/2019-04-27-maximum-weight-hierarchical-b-matching.html">hierarchical <span class="math inline">b</span>-matching</a>. Reader can see each individual restriction, the problem can be turned into a maximum weight perfect matching.</p>
<p>If we enforce both property, the problem is open. Although the structure is still very special, it is an <a href="https://en.wikipedia.org/wiki/Delta-matroid">even <span class="math inline">\Delta</span>-matroid</a>. <a href="http://www.math.keio.ac.jp/~kakimura/">Naonori Kakimura</a> communicated a more fundamental problem which can be solved by this problem.</p>
<div class="theorem-environment Problem" data-index="2" type="Problem" title="Matching with disjoint pair constraints">
<span class="theorem-header"><span class="type">Problem</span><span class="index">2</span><span class="name">Matching with disjoint pair constraints</span></span>
<p>Given a graph where the edges are partitioned into pairs. Find a maximum matching where it uses at most one edge of each pair.</p>
</div>
<p>I would be very interested to know the solution to that problem.</p>
<h1 id="bibliography" class="unnumbered">References</h1>
<div id="refs" class="references" role="doc-bibliography">
<div id="ref-KakimuraT14">
<p>[1] N. Kakimura, M. Takamatsu, <strong>Matching Problems with Delta-Matroid Constraints</strong>, SIAM Journal on Discrete Mathematics. 28 (2014) 942–961 <a href="https://doi.org/10.1137/110860070">10.1137/110860070</a>.</p>
</div>
<div id="ref-HefnerK95">
<p>[2] A. Hefner, P. Kleinschmidt, <strong>A constrained matching problem</strong>, Annals of Operations Research. 57 (1995) 135–145 <a href="https://doi.org/10.1007/BF02099694">10.1007/BF02099694</a>.</p>
</div>
</div>
</div>
<div class="hide-on-print">
    <div class="info">Posted by <a href="https://chaoxuprime.com">Chao Xu</a> on <time datetime="2019-06-18">2019-06-18</time>. </div>
    <div class="info">Tags: Optimization, algorithm, airline.</div>
</div>]]></description>
    <pubDate>Tue, 18 Jun 2019 00:00:00 UT</pubDate>
    <guid>https://chaoxuprime.com/posts/2019-06-18-long-distance-couple-back-to-back-ticketing.html</guid>
    <dc:creator>Chao Xu</dc:creator>
</item>
<item>
    <title>An algorithm for covert back-to-back ticketing</title>
    <link>https://chaoxuprime.com/posts/2019-06-15-covert-back-to-back-ticketing.html</link>
    <description><![CDATA[<br />
<div>
<p><a href="https://en.wikipedia.org/wiki/Airline_booking_ploys">Airline booking ploys</a> are ways to circumventing airlines ticket rules in order to spend less on the ticket. We consider a special case, the back-to-back ticketing/nested ticketing. <a href="https://www.tripsavvy.com/back-to-back-ticketing-468287">TripSavvy has a good article on back-to-back ticketing</a>.</p>
<p>For many airlines, back-to-back ticketing is explicitly forbidden, this includes <a href="https://www.aa.com/i18n/customer-service/support/conditions-of-carriage.jsp?anchorEvent=false&amp;from=footer?#ticketvalidity">American Airlines</a>, <a href="https://www.delta.com/us/en/booking-information/fare-classes-and-tickets/ticket-rules-restrictions">Delta</a> and <a href="https://www.united.com/ual/en/us/fly/contract-of-carriage.html">United</a>.</p>
<p>We want to model back-to-back ticketing into an algorithmic problem. There is a sequence of trips between two locations, and it can be grouped into different round trips. Each round trip itinerary has a different cost. A round trip itinerary is no more than a matching between two trips.</p>
<p>This can be seen as simple matching problem. The vertices are trips, which we can assume a trip means “traveling from A to B on date x”. There is an edge between two trips, if there is a round trip itinerary containing the trips. The cost of the edge is the cost of buying a round trip for those two trips. Since it is also possible that we buy a one-way ticket, there are also self-loops. Also, we can consider a multigraph, where the edges are colored. Each color class represents an airline.</p>
<p>If one does not care about the airline finding out, it is just a minimum weight perfect matching problem allowing self-loops. However, people might actually care about airline not happy about this practice. Hence we are interested in making sure in each airline, we have no overlapping itineraries. However, we do allow overlapping itineraries across airlines.</p>
<p>For two edges <span class="math inline">\set{a,b}</span> and <span class="math inline">\set{c,d}</span> defined over integers, it is <em>independent</em> if <span class="math inline">[a,b]\cap [c,d]= \emptyset</span>. A set of edges is <em>independent</em> if the edges are pairwise independent.</p>
<div class="theorem-environment Problem" data-index="1" type="Problem" title="Covert back-to-back ticketing problem">
<span class="theorem-header"><span class="type">Problem</span><span class="index">1</span><span class="name">Covert back-to-back ticketing problem</span></span>
<p><strong>Input:</strong> A multigraph <span class="math inline">G=(V,E)</span> where <span class="math inline">V\subseteq [n]</span>, each edge can be one of <span class="math inline">k</span> colors, and there is an edge cost function <span class="math inline">c:E\to \R^+</span>.</p>
<p><strong>Output:</strong> A perfect matching <span class="math inline">M</span> (allowing self-loops), such that each color class of <span class="math inline">M</span> is independent, and the cost is minimized.</p>
</div>
<p>I suspect for arbitrary <span class="math inline">k</span>, the problem is NP-hard. We show how to solve the problem in polynomial time for <span class="math inline">k=2</span>.</p>
<p><a href="https://yizhis.github.io/">Yizhi Song</a> stated the idea that if one edge in a color is picked, it forces some edges of the other color to be picked. We can use the idea to obtain an <span class="math inline">O(n^3)</span> time algorithm for this problem.</p>
<p>Since we are only working with <span class="math inline">k=2</span> case, we will let <span class="math inline">\bar{a}</span> to be the color that is not <span class="math inline">a</span>. Recall <span class="math inline">[n]=\set{1,\ldots,n}</span> and <span class="math inline">[a..b] = \set{a,a+1,\ldots,b}</span>. We assume the vertices <span class="math inline">V=[n]</span>. For a graph with <span class="math inline">k</span> color classes, we define <span class="math inline">G_a</span> to be the subgraph consists of all edges of color <span class="math inline">a</span>. <span class="math inline">c_a(x,y)</span> is the cost of a color <span class="math inline">a</span> edge <span class="math inline">xy</span>. We define <span class="math inline">D(a,y,z)</span> as the optimal solution when the input graph is <span class="math inline">G_{\bar{a}}[[z-1]\setminus \set{y}] \cup G_a[[y-1]]</span>. Intuitively, this is the optimal solution where we need to match all vertices in <span class="math inline">Z = [z-1] \setminus \set{y}</span>, but can only use <span class="math inline">a</span> colored that is fully contained in <span class="math inline">[y-1]</span>, and <span class="math inline">\bar{a}</span> colored edges fully contained <span class="math inline">Z</span>. We also define <span class="math inline">C_{a}(x,y)</span> to be the optimal solution when the input graph is <span class="math inline">G_a[[x..y]]</span>. Namely, a min-cost perfect matching covering all vertices <span class="math inline">[x..y]</span> but we can only use <span class="math inline">a</span> colored edges contained in <span class="math inline">[x..y]</span>.</p>
<p>The optimal solution is <span class="math inline">D(a,n+1,n+1)</span> for either color <span class="math inline">a</span>.</p>
<p>We express the recursive relation. For <span class="math inline">y&lt;z</span>, we have the following. <span class="math display">
D(a,y,z) =\min \begin{cases}
\min_{x&lt;y} \set{ C_{\bar{a}}(y+2,z-1) + c_{\bar{a}}(x,y+1) + D(\bar{a},x,y)}\\
C_{\bar{a}}(y+1,z-1) + D(\bar{a},y,y)
\end{cases}
</span> It might be beneficial to see the intuition behind the two cases through the following pictures.</p>
<figure>
<img src="/files/ticketing_case1.png" alt="" /><figcaption>First case.</figcaption>
</figure>
<figure>
<img src="/files/ticketing_case2.png" alt="" /><figcaption>Second case.</figcaption>
</figure>
<p>On the other hand, when <span class="math inline">y=z</span> <span class="math display">
D(a,y,y) =\min_{x&lt;y} \set{
D(a,x,y) + c_a(x,y),
D(\bar{a},x,y) + c_{\bar{a}}(x,y)}
</span> One can easily infer the base case through definition. Note that all values of <span class="math inline">C_a</span> can be computed in <span class="math inline">O(n^2)</span> time. It takes <span class="math inline">O(n)</span> time to compute one value in <span class="math inline">D</span>. Therefore, the total running time is <span class="math inline">O(n^3)</span>.</p>
<p>One can show that even with <span class="math inline">k</span> different airlines, there is an algorithm with running time <span class="math inline">O(n^{O(k)})</span>.</p>
</div>
<div class="hide-on-print">
    <div class="info">Posted by <a href="https://chaoxuprime.com">Chao Xu</a> on <time datetime="2019-06-15">2019-06-15</time>. </div>
    <div class="info">Tags: Optimization, algorithm, airline.</div>
</div>]]></description>
    <pubDate>Sat, 15 Jun 2019 00:00:00 UT</pubDate>
    <guid>https://chaoxuprime.com/posts/2019-06-15-covert-back-to-back-ticketing.html</guid>
    <dc:creator>Chao Xu</dc:creator>
</item>
<item>
    <title>Arrays and permutation</title>
    <link>https://chaoxuprime.com/posts/2019-06-15-array-and-permutation.html</link>
    <description><![CDATA[<br />
<div>
<h1 id="permutation-functional-form"><span class="header-section-number">1</span> Permutation, functional form</h1>
<p>What exactly is an array. In functional form, an array just have to support the following two operations in constant time.</p>
<ol type="1">
<li><span class="math inline">get(A,i)</span>: returns <span class="math inline">A[i]</span>.</li>
<li><span class="math inline">set(A,i,x)</span>: update the array <span class="math inline">A</span> such that <span class="math inline">A[i]</span> returns <span class="math inline">x</span>.</li>
</ol>
<p>So in some sense, array is just encoding a function <span class="math inline">f:[n]\to X</span>. A permutation would be a bijective function <span class="math inline">\pi:[n]\to [n]</span>. If we are interested in applying a permutation <span class="math inline">\pi</span>, then to program it is easy, we need to output a new function <span class="math inline">g</span> such that <span class="math inline">g(i) = f(\pi(i))</span>.</p>
<p>This allows us to apply permutations pretty easily by composing functions and cache outputs. In the purely functional view, the layout of the array in memory and the indexing can be different.</p>
<h1 id="permutation-physically"><span class="header-section-number">2</span> Permutation, physically</h1>
<p>Sometimes one might ask to physically apply the permutation to an array. That is, the <span class="math inline">i</span>th position in the array contains the element in <span class="math inline">\pi(i)</span>. This is helpful because it helps with cache locality: accessing consecutive elements would be in the same location. Although if the ordering of loops does not matter, there is no harm considering the functional view.</p>
<p>Often, one is tasked to apply permutation to an array physically. It usually ask for <span class="math inline">O(n)</span> running time and <span class="math inline">O(1)</span> space. Unfortunately, there is no way to obtain this running time for all permutations. There are some permutations where this is impossible. <a href="https://cstheory.stackexchange.com/questions/6711/complexity-of-applying-a-permutation-in-place">A discussion can be found in cstheory</a>.</p>
<h1 id="mix-and-match"><span class="header-section-number">3</span> Mix and match</h1>
<p><a href="https://www.linkedin.com/in/lingyu-xu-9b87a565/">Lingyu Xu</a> asked me about <a href="https://leetcode.com/problems/wiggle-sort-ii/">Wiggle Sort</a>, where the actual <strong>physical layout</strong> has to be changed, but it takes both the functional and physical view of the array.</p>
<p>Let’s consider the simple case where every element is distinct. One simple solution is the following. Partition the numbers into the median, elements smaller than median, and elements larger than the median. We map the smallest <span class="math inline">n/2</span> elements into even positions, and remaining elements into the odd position. The algorithm has <span class="math inline">O(n)</span> time. The problem is how to get constant extra place. Because it is unclear how to apply the following permutation in place. The permutation <span class="math inline">\sigma(i) = (1+2i) \% (n|1)</span>.</p>
<p>However, one we take the functional view, the problem can be solved, physically too. The <a href="https://leetcode.com/problems/wiggle-sort-ii/discuss/77677/ono1-after-median-virtual-indexing/81756">answer by</a> <a href="http://www.stefan-pochmann.info/">Stefan Pochmann</a> shows one can simply do the mapping in place.</p>
<p>What is happening in the physical location. If we applied index transform <span class="math inline">\pi</span>, then apply physical permutation <span class="math inline">\sigma</span> on the index, what happens for the physical array? It is the same as applying <span class="math inline">\pi^{-1}\sigma\pi</span> to the physical array. Note this means we can only use this trick to obtain conjugates of <span class="math inline">\sigma</span>.</p>
</div>
<div class="hide-on-print">
    <div class="info">Posted by <a href="https://chaoxuprime.com">Chao Xu</a> on <time datetime="2019-06-15">2019-06-15</time>. </div>
    <div class="info">Tags: Permutation.</div>
</div>]]></description>
    <pubDate>Sat, 15 Jun 2019 00:00:00 UT</pubDate>
    <guid>https://chaoxuprime.com/posts/2019-06-15-array-and-permutation.html</guid>
    <dc:creator>Chao Xu</dc:creator>
</item>
<item>
    <title>Union of intervals in SQL</title>
    <link>https://chaoxuprime.com/posts/2019-04-27-union-of-intervals-in-sql.html</link>
    <description><![CDATA[<br />
<div>
<h1 id="introduction"><span class="header-section-number">1</span> Introduction</h1>
<p>We given a collection of <span class="math inline">n</span> intervals, and we want to find its union, represented by a set of disjoint intervals. Assume the intervals are of the form <span class="math inline">[a,b)</span>, where <span class="math inline">a&lt;b</span>. However, I have to solve this problem in Hive. So this is a problem I have to solve in Hive’s SQL variant.</p>
<p>First, here is the schema of the table and some sample inputs.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode sql"><code class="sourceCode sql"><span id="cb1-1"><a href="#cb1-1"></a><span class="kw">CREATE</span> <span class="kw">TABLE</span> t (</span>
<span id="cb1-2"><a href="#cb1-2"></a>  a <span class="dt">int</span>,</span>
<span id="cb1-3"><a href="#cb1-3"></a>  b <span class="dt">int</span></span>
<span id="cb1-4"><a href="#cb1-4"></a>);</span>
<span id="cb1-5"><a href="#cb1-5"></a><span class="kw">INSERT</span> <span class="kw">INTO</span> t <span class="kw">VALUES</span></span>
<span id="cb1-6"><a href="#cb1-6"></a>  (<span class="dv">0</span>,<span class="dv">10</span>),</span>
<span id="cb1-7"><a href="#cb1-7"></a>  (<span class="dv">20</span>,<span class="dv">30</span>),</span>
<span id="cb1-8"><a href="#cb1-8"></a>  (<span class="dv">5</span>,<span class="dv">15</span>);</span></code></pre></div>
<p>The correct output should be the following.</p>
<pre><code>a    b
-------
0    15
20   30</code></pre>
<p>We do not allow empty intervals, so we cannot have <span class="math inline">a=b</span>.</p>
<h1 id="previous-works"><span class="header-section-number">2</span> Previous Works</h1>
<p>Note this is a common interview problem, <a href="https://leetcode.com/problems/merge-intervals/">LeetCode 56. Merge Intervals</a>. There is a <span class="math inline">\Omega(n\log n)</span> running time lower bound. There is an <span class="math inline">O(n\log p)</span> upper bound, where <span class="math inline">p</span> is the number of points required to stab all intervals. In higher dimension, this is called the <a href="https://en.wikipedia.org/wiki/Klee%27s_measure_problem">Klee’s measure problem</a>.</p>
<p>However, one would wonder how efficient can we solve the problem in SQL. I was surprised find a <a href="https://stackoverflow.com/a/8120432/303863">very short solution on stackoverflow</a>.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode sql"><code class="sourceCode sql"><span id="cb3-1"><a href="#cb3-1"></a><span class="kw">SELECT</span> </span>
<span id="cb3-2"><a href="#cb3-2"></a>       t1.a,</span>
<span id="cb3-3"><a href="#cb3-3"></a>       <span class="fu">MIN</span>(t2.b) <span class="kw">AS</span> b</span>
<span id="cb3-4"><a href="#cb3-4"></a><span class="kw">FROM</span> t t1 </span>
<span id="cb3-5"><a href="#cb3-5"></a><span class="kw">INNER</span> <span class="kw">JOIN</span> t t2 <span class="kw">ON</span> t1.a <span class="op">&lt;=</span> t2.b</span>
<span id="cb3-6"><a href="#cb3-6"></a>  <span class="kw">AND</span> <span class="kw">NOT</span> <span class="kw">EXISTS</span>(<span class="kw">SELECT</span> <span class="op">*</span> <span class="kw">FROM</span> t </span>
<span id="cb3-7"><a href="#cb3-7"></a>                 <span class="kw">WHERE</span> t2.b <span class="op">&gt;=</span> t.a <span class="kw">AND</span> t2.b <span class="op">&lt;</span> t.b) </span>
<span id="cb3-8"><a href="#cb3-8"></a><span class="kw">WHERE</span> <span class="kw">NOT</span> <span class="kw">EXISTS</span>(<span class="kw">SELECT</span> <span class="op">*</span> <span class="kw">FROM</span> t</span>
<span id="cb3-9"><a href="#cb3-9"></a>                 <span class="kw">WHERE</span> t1.a <span class="op">&gt;</span> t.a <span class="kw">AND</span> t1.a <span class="op">&lt;=</span> t.b) </span>
<span id="cb3-10"><a href="#cb3-10"></a><span class="kw">GROUP</span> <span class="kw">BY</span> t1.a</span>
<span id="cb3-11"><a href="#cb3-11"></a><span class="kw">ORDER</span> <span class="kw">BY</span> t1.a</span></code></pre></div>
<p>Unfortunately, once you know how the entire algorithm goes, one can see its performance does not look promising. Indeed, this is a <span class="math inline">O(n^2)</span> time algorithm. After generating <span class="math inline">10000</span> random intervals in PostgreSQL, it took 13 seconds to run. Also making it work in Hive is next to impossible due to Hive’s limitations on joins and subqueries.</p>
<p><a href="http://tsql.solidq.com/">Itzik Ben-Gan</a> has <a href="https://www.itprotoday.com/development-techniques-and-management/packing-date-intervals">written</a> <a href="https://blogs.solidq.com/en/sqlserver/packing-intervals/">multiple</a> <a href="https://www.itprotoday.com/sql-server/new-solution-packing-intervals-problem">articles</a> on how to solve this problem. I recommend reading them to learn various tricks. In fact, my solution here is quite similar to one of Ben-Gan’s.</p>
<p>Thanks to <a href="https://scholar.google.com/citations?user=jB4qJYEAAAAJ&amp;hl=en">Peng Yu</a> who pointed out this kind of queries is very common in sessionization.</p>
<h1 id="using-basic-sql"><span class="header-section-number">3</span> Using basic SQL</h1>
<p>Here we will try to implement an algorithm using the most basic of SQL, so it would even work in Hive.</p>
<h2 id="solution-by-simulate-the-standard-sweep-line-algorithm"><span class="header-section-number">3.1</span> Solution by simulate the standard sweep-line algorithm</h2>
<p>We first build a table, such that <span class="math inline">(a,c)</span> is in the table shows that there are <span class="math inline">c</span> intervals the endpoint directly before <span class="math inline">a</span>. Next, we notice that <span class="math inline">c=0</span> if and only if <span class="math inline">a</span> is the start of a new interval in the union. Hence we can assign everything between consecutive <span class="math inline">c=0</span> a name.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode sql"><code class="sourceCode sql"><span id="cb4-1"><a href="#cb4-1"></a><span class="kw">WITH</span> </span>
<span id="cb4-2"><a href="#cb4-2"></a>  weighted_endpoints <span class="kw">AS</span> (</span>
<span id="cb4-3"><a href="#cb4-3"></a>    <span class="kw">SELECT</span> a, <span class="fu">Sum</span>(d) <span class="kw">AS</span> d</span>
<span id="cb4-4"><a href="#cb4-4"></a>    <span class="kw">FROM</span>   (<span class="kw">SELECT</span> a,  <span class="dv">1</span> <span class="kw">AS</span> d <span class="kw">FROM</span> t</span>
<span id="cb4-5"><a href="#cb4-5"></a>            <span class="kw">UNION</span> <span class="kw">ALL</span></span>
<span id="cb4-6"><a href="#cb4-6"></a>            <span class="kw">SELECT</span> b, <span class="op">-</span><span class="dv">1</span> <span class="kw">AS</span> d <span class="kw">FROM</span> t) e</span>
<span id="cb4-7"><a href="#cb4-7"></a>    <span class="kw">GROUP</span>  <span class="kw">BY</span> a),</span>
<span id="cb4-8"><a href="#cb4-8"></a>  endpoints_with_coverage <span class="kw">AS</span> (</span>
<span id="cb4-9"><a href="#cb4-9"></a>    <span class="kw">SELECT</span> <span class="op">*</span>, <span class="fu">Sum</span>(d) <span class="kw">OVER</span> (<span class="kw">ORDER</span> <span class="kw">BY</span> a) <span class="op">-</span> d <span class="kw">AS</span> c</span>
<span id="cb4-10"><a href="#cb4-10"></a>    <span class="kw">FROM</span> weighted_endpoints),</span>
<span id="cb4-11"><a href="#cb4-11"></a>  equivalence_classes <span class="kw">AS</span> (</span>
<span id="cb4-12"><a href="#cb4-12"></a>    <span class="kw">SELECT</span> a, <span class="fu">COUNT</span>(<span class="cf">CASE</span> <span class="cf">WHEN</span> c<span class="op">=</span><span class="dv">0</span> <span class="cf">THEN</span> <span class="dv">1</span> <span class="cf">END</span>) <span class="kw">OVER</span> (<span class="kw">ORDER</span> <span class="kw">BY</span> a) <span class="kw">AS</span> <span class="kw">class</span></span>
<span id="cb4-13"><a href="#cb4-13"></a>    <span class="kw">FROM</span> endpoints_with_coverage)</span>
<span id="cb4-14"><a href="#cb4-14"></a><span class="kw">SELECT</span> <span class="fu">min</span>(a) <span class="kw">AS</span> a, <span class="fu">max</span>(a) <span class="kw">AS</span> b</span>
<span id="cb4-15"><a href="#cb4-15"></a><span class="kw">FROM</span> equivalence_classes</span>
<span id="cb4-16"><a href="#cb4-16"></a><span class="kw">GROUP</span> <span class="kw">BY</span> <span class="kw">class</span>;</span></code></pre></div>
<p>The equivalence classes idea is from Peng Yu. This code took 100ms to handle 10000 random intervals in PostgreSQL. You can find <a href="https://www.db-fiddle.com/f/aVaF6NDTVYmxBpifsHDFBf/9">the example in DB-fiddle</a>. I am interested to seeing simpler and faster code using the simplest of SQL.</p>
<h2 id="solution-through-gaps"><span class="header-section-number">3.2</span> Solution through gaps</h2>
<p>There is another solution, which uses the idea of gaps. Interestingly, gaps are much easier to compute. Here we modify <a href="https://stackoverflow.com/a/53163029/303863">Oleg K’s solution</a>.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode sql"><code class="sourceCode sql"><span id="cb5-1"><a href="#cb5-1"></a><span class="kw">WITH</span> largest_prev <span class="kw">AS</span> (<span class="kw">SELECT</span> </span>
<span id="cb5-2"><a href="#cb5-2"></a>                      <span class="fu">MAX</span>(b) <span class="kw">OVER</span> (<span class="kw">ORDER</span> <span class="kw">BY</span> a) <span class="kw">AS</span> b,</span>
<span id="cb5-3"><a href="#cb5-3"></a>                      <span class="fu">LEAD</span>(a) <span class="kw">OVER</span> (<span class="kw">ORDER</span> <span class="kw">BY</span> a) <span class="kw">AS</span> a </span>
<span id="cb5-4"><a href="#cb5-4"></a>                      <span class="kw">FROM</span> t),</span>
<span id="cb5-5"><a href="#cb5-5"></a>     gaps <span class="kw">AS</span> (<span class="kw">SELECT</span> <span class="op">*</span> <span class="kw">FROM</span> largest_prev <span class="kw">WHERE</span> b<span class="op">&lt;</span>a</span>
<span id="cb5-6"><a href="#cb5-6"></a>              <span class="kw">UNION</span> <span class="kw">ALL</span></span>
<span id="cb5-7"><a href="#cb5-7"></a>              <span class="kw">SELECT</span> <span class="fu">min</span>(a), <span class="fu">min</span>(a) <span class="kw">from</span> t</span>
<span id="cb5-8"><a href="#cb5-8"></a>              <span class="kw">UNION</span> <span class="kw">ALL</span></span>
<span id="cb5-9"><a href="#cb5-9"></a>              <span class="kw">SELECT</span> <span class="fu">max</span>(b), <span class="kw">null</span> <span class="kw">from</span> t),</span>
<span id="cb5-10"><a href="#cb5-10"></a>     intervals <span class="kw">AS</span> (<span class="kw">SELECT</span> a, <span class="fu">LEAD</span>(b) <span class="kw">OVER</span> (<span class="kw">ORDER</span> <span class="kw">BY</span> b) <span class="kw">as</span> b <span class="kw">FROM</span> gaps)</span>
<span id="cb5-11"><a href="#cb5-11"></a><span class="kw">SELECT</span> <span class="op">*</span> <span class="kw">FROM</span> intervals <span class="kw">WHERE</span> a <span class="kw">IS</span> <span class="kw">NOT</span> <span class="kw">null</span>;</span></code></pre></div>
<p>This one can also be tested on <a href="https://www.db-fiddle.com/f/k1GTRiRgaiPmRfxZoWBhTs/1">DB-fiddle</a>. This code took 70ms to handle 10000 random intervals in PostgreSQL.</p>
<p>As a real application, for example, if we want to know the length of union of intervals grouped by some keys. The following is how we do it in hive. Note in this application, we don’t have to remove the null rows because we are taking a sum.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode sql"><code class="sourceCode sql"><span id="cb6-1"><a href="#cb6-1"></a><span class="kw">SET</span> hivevar<span class="ch">:key</span><span class="op">=</span>id1,id2;</span>
<span id="cb6-2"><a href="#cb6-2"></a><span class="kw">SET</span> hivevar<span class="ch">:input</span><span class="op">=</span>t;</span>
<span id="cb6-3"><a href="#cb6-3"></a><span class="kw">WITH</span> largest_prev <span class="kw">AS</span> (<span class="kw">SELECT</span></span>
<span id="cb6-4"><a href="#cb6-4"></a>                      ${<span class="kw">key</span>},</span>
<span id="cb6-5"><a href="#cb6-5"></a>                      <span class="fu">MAX</span>(b) <span class="kw">OVER</span> (<span class="kw">PARTITION</span> <span class="kw">BY</span> ${<span class="kw">key</span>} <span class="kw">ORDER</span> <span class="kw">BY</span> a) <span class="kw">AS</span> b,</span>
<span id="cb6-6"><a href="#cb6-6"></a>                      <span class="fu">LEAD</span>(a) <span class="kw">OVER</span> (<span class="kw">PARTITION</span> <span class="kw">BY</span> ${<span class="kw">key</span>} <span class="kw">ORDER</span> <span class="kw">BY</span> a) <span class="kw">AS</span> a</span>
<span id="cb6-7"><a href="#cb6-7"></a>                      <span class="kw">FROM</span> ${input}),</span>
<span id="cb6-8"><a href="#cb6-8"></a>     gaps <span class="kw">AS</span> (<span class="kw">SELECT</span> <span class="op">*</span> <span class="kw">FROM</span> largest_prev <span class="kw">WHERE</span> b<span class="op">&lt;</span>a</span>
<span id="cb6-9"><a href="#cb6-9"></a>              <span class="kw">UNION</span> <span class="kw">ALL</span></span>
<span id="cb6-10"><a href="#cb6-10"></a>              <span class="kw">SELECT</span> ${<span class="kw">key</span>}, <span class="fu">min</span>(a), <span class="fu">min</span>(a) <span class="kw">from</span> ${input} <span class="kw">GROUP</span> <span class="kw">BY</span> ${<span class="kw">key</span>}</span>
<span id="cb6-11"><a href="#cb6-11"></a>              <span class="kw">UNION</span> <span class="kw">ALL</span></span>
<span id="cb6-12"><a href="#cb6-12"></a>              <span class="kw">SELECT</span> ${<span class="kw">key</span>}, <span class="fu">max</span>(b), <span class="kw">null</span> <span class="kw">from</span> ${input} <span class="kw">GROUP</span> <span class="kw">BY</span> ${<span class="kw">key</span>}),</span>
<span id="cb6-13"><a href="#cb6-13"></a>     intervals <span class="kw">AS</span> (<span class="kw">SELECT</span> ${<span class="kw">key</span>}, </span>
<span id="cb6-14"><a href="#cb6-14"></a>                          a,</span>
<span id="cb6-15"><a href="#cb6-15"></a>                          <span class="fu">LEAD</span>(b) <span class="kw">OVER</span> (<span class="kw">PARTITION</span> <span class="kw">BY</span> ${<span class="kw">key</span>} <span class="kw">ORDER</span> <span class="kw">BY</span> b) <span class="kw">as</span> b</span>
<span id="cb6-16"><a href="#cb6-16"></a>                   <span class="kw">FROM</span> gaps)</span>
<span id="cb6-17"><a href="#cb6-17"></a><span class="kw">SELECT</span> ${<span class="kw">key</span>}, <span class="fu">SUM</span>(b<span class="op">-</span>a) <span class="kw">as</span> score</span>
<span id="cb6-18"><a href="#cb6-18"></a><span class="kw">FROM</span> intervals</span>
<span id="cb6-19"><a href="#cb6-19"></a><span class="kw">GROUP</span> <span class="kw">BY</span> ${<span class="kw">key</span>};</span></code></pre></div>
</div>
<div class="hide-on-print">
    <div class="info">Posted by <a href="https://chaoxuprime.com">Chao Xu</a> on <time datetime="2019-04-27">2019-04-27</time>. </div>
    <div class="info">Tags: SQL, algorithm.</div>
</div>]]></description>
    <pubDate>Sat, 27 Apr 2019 00:00:00 UT</pubDate>
    <guid>https://chaoxuprime.com/posts/2019-04-27-union-of-intervals-in-sql.html</guid>
    <dc:creator>Chao Xu</dc:creator>
</item>
<item>
    <title>Maximum weight hierarchical $b$-matching</title>
    <link>https://chaoxuprime.com/posts/2019-04-27-maximum-weight-hierarchical-b-matching.html</link>
    <description><![CDATA[<br />
<div>
<p>We consider the following problem, which appeared in <span class="citation" data-cites="EmekKSZ19">[<a href="#ref-EmekKSZ19" role="doc-biblioref">1</a>]</span>.</p>
<p>Let <span class="math inline">\mathcal{L}</span> be a laminar family consists of sets <span class="math inline">F_1,\ldots,F_k</span>. Let <span class="math inline">u_1,\ldots,u_k</span> to be positive integers. Consider a graph <span class="math inline">G=(V,E)</span> with a weight function <span class="math inline">w:E\to \N</span> and capacity function <span class="math inline">c:E\to \N</span>. We are interested in finding a <span class="math inline">y\leq c</span>, such that for every <span class="math inline">F_i\in \mathcal{L}</span>, we have <span class="math inline">\sum_{v\in F_i} \sum_{e:v\in e\in E} y_e \leq u_i</span>, and <span class="math inline">\sum_{e\in E} y_ew_e</span> is maximized.</p>
<p>Formally, it is the following integer program.</p>
<p><span class="math display">
\begin{aligned}
&amp; \max_{y\in \Z^m} &amp; &amp; \sum_{e} w_e y_e &amp; \\
&amp; \text{s.t.} &amp; &amp; \sum_{v\in F_i} \sum_{e:v\in e\in E} y_e \leq u_i &amp; i\in [k] \\
&amp; &amp; &amp;  0\leq y_e \leq c_e &amp; \forall e\in E \\
\end{aligned}
</span></p>
<p>This is a generalization of the maximum weight <span class="math inline">c</span>-capacitated <span class="math inline">b</span>-matching problem. Indeed, we can simply set <span class="math inline">F_i = \set{v_i}</span> and <span class="math inline">u_i=b_i</span>. However, this problem is actually no more general than the maximum weight <span class="math inline">c</span>-capacitated <span class="math inline">b</span>-matching problem.</p>
<p>Let <span class="math inline">A \in \Z^{m\times n}</span> be a matrix such that <span class="math inline">\sum_{i=1}^m |A_{i,j}|\leq 2</span> for every <span class="math inline">j</span>. We call <span class="math inline">A</span> a bidirected matrix.</p>
<div class="theorem-environment Theorem" data-index="1" type="Theorem">
<span class="theorem-header"><span class="type">Theorem</span><span class="index">1</span></span>
<p>Given <span class="math inline">A \in \Z^{m\times n}</span> a bidirected matrix and vectors <span class="math inline">a,b\in \Z^m</span>, <span class="math inline">c,d,w\in \Z^n</span>. The integer program <span class="math inline">\max_{x\in \Z^n} \set{wx \mid a\leq Ax\leq b, c\leq x\leq d}</span> can be solved in polynomial time. In particular, it is equivalent to the maximum weight <span class="math inline">b</span>-matching problem on graph of size <span class="math inline">poly(m,n)</span>.</p>
</div>
<p>The above theorem can be found in <span class="citation" data-cites="Schrijver03">[<a href="#ref-Schrijver03" role="doc-biblioref">2</a>]</span>. Note that in Schrijver’s book, one requires <span class="math inline">\sum_{i=1}^m |A_{i,j}|=2</span>. It is not hard to see the statement still holds even if we have <span class="math inline">\leq</span> in place of <span class="math inline">=</span>.</p>
<p>We will express the maximum weight hierarchical <span class="math inline">b</span>-matching problem as an integer program over a polytope defined over a bidirected matrix. The integer program is a modification of the integer program in <span class="citation" data-cites="KaparisLM17">[<a href="#ref-KaparisLM17" role="doc-biblioref">3</a>]</span>. The integer program here is simpler, because we are not trying to reduce to <em>perfect</em> <span class="math inline">b</span>-matching.</p>
<p>We define <span class="math inline">F_i&#39; = F_i \setminus \bigcup_{j: F_j\subsetneq F_i} F_j</span>. We also define <span class="math inline">C_i</span> to be the indices <span class="math inline">j</span>, such that for all <span class="math inline">k</span>, <span class="math inline">F_j\subseteq F_k \subsetneq F_i</span> implies <span class="math inline">j=k</span>. <span class="math inline">y_e</span> denote the amount of capacities we assign to <span class="math inline">e</span>, <span class="math inline">x_v</span> denotes the capacitated degree, hence <span class="math inline">x_v = \sum_{e:v\in e\in E} y_e</span>. We define <span class="math inline">z_i = \sum_{v\in F_i} x_v</span>, which can be transformed to <span class="math inline">z_i = \sum_{v\in F_i&#39;} x_v + \sum_{j\in C_i} z_j</span>. Therefore we obtain the following integer program by directly applying substitutions.</p>
<p><span class="math display">
\begin{aligned}
&amp; \max_{x\in \Z^n,y\in \Z^m, z\in \Z^k} &amp; &amp; \sum_{e} w_e y_e &amp; \\
&amp; \text{s.t.} &amp; &amp; \sum_{v\in F_i&#39;} x_v + \sum_{j\in C_i} z_j - z_i= 0 &amp; i\in [k] \\
&amp; &amp; &amp;  \sum_{e: v\in e\in E} y_e -x_v = 0 &amp; \forall v\in V \\
&amp; &amp; &amp;  0\leq y_e \leq c_e &amp; \forall e\in E \\
&amp; &amp; &amp;  0\leq z_i \leq u_i &amp; \forall i\in [k] \\
\end{aligned}
</span></p>
<p>The matrix here is a bidirected matrix. This shows the original problem can be solved in polynomial time.</p>
<h1 id="bibliography" class="unnumbered">References</h1>
<div id="refs" class="references" role="doc-bibliography">
<div id="ref-EmekKSZ19">
<p>[1] Y. Emek, S. Kutten, M. Shalom, S. Zaks, <strong>Hierarchical b-Matching</strong>, arXiv E-Prints. (2019) arXiv:1904.10210.</p>
</div>
<div id="ref-Schrijver03">
<p>[2] A. Schrijver, <strong>Combinatorial Optimization (3 volume, A, B, &amp; C)</strong>, Springer, 2003.</p>
</div>
<div id="ref-KaparisLM17">
<p>[3] I.M. Konstantinos Kaparis Adam N. Letchford, <strong>On matroid parity and matching polytopes</strong>, Department of Management Science, Lancaster University, 2017.</p>
</div>
</div>
</div>
<div class="hide-on-print">
    <div class="info">Posted by <a href="https://chaoxuprime.com">Chao Xu</a> on <time datetime="2019-04-27">2019-04-27</time>. </div>
    <div class="info">Tags: combinatorial optimization, matching, matroid.</div>
</div>]]></description>
    <pubDate>Sat, 27 Apr 2019 00:00:00 UT</pubDate>
    <guid>https://chaoxuprime.com/posts/2019-04-27-maximum-weight-hierarchical-b-matching.html</guid>
    <dc:creator>Chao Xu</dc:creator>
</item>
<item>
    <title>Misleading while being honest</title>
    <link>https://chaoxuprime.com/posts/2019-04-06-misleading-while-being-honest.html</link>
    <description><![CDATA[<br />
<div>
<p>Given a set of data <span class="math inline">A</span>, we can plot it on a <a href="https://en.wikipedia.org/wiki/Radar_chart">radar chart</a>. One can permute the axis to make sure the area of the radar chart is maximized. This was explored in <a href="https://chaoxuprime.com/posts/2012-08-08-maximize-the-area-of-a-radar-chart.html">a previous article</a>.</p>
<p>More interesting problem. Given two sets of data <span class="math inline">A</span> and <span class="math inline">B</span>, we are interested in finding a common radar chart, that make <span class="math inline">A</span> look as good as possible compared to <span class="math inline">B</span>. We might want to optimize the area ratio, area difference, or something else. Again, we are thinking of permuting the axis of the radar chart.</p>
<p>I once mentioned this problem to <a href="https://www.contrib.andrew.cmu.edu/~ravi/">R Ravi</a>, and he suggest I could ask the same question for all kind of different graphs. How to mislead people with graphs while being completely honest? Indeed, this looks like a fun research project. There is a <a href="https://en.wikipedia.org/wiki/Misleading_graph">wikipedia article completely devoted to it</a>. In my <a href="https://chaoxuprime.com/posts/2019-03-28-l1-linear-regression.html">previous post</a>, I’ve discussed how to fitting two seemingly not that related data points through simple transformation.</p>
<p>I’m interested in are algorithmic problems where one want to compute the most misleading chart, I think it would be a great fun project.</p>
</div>
<div class="hide-on-print">
    <div class="info">Posted by <a href="https://chaoxuprime.com">Chao Xu</a> on <time datetime="2019-04-06">2019-04-06</time>. </div>
    <div class="info">Tags: data visualization.</div>
</div>]]></description>
    <pubDate>Sat, 06 Apr 2019 00:00:00 UT</pubDate>
    <guid>https://chaoxuprime.com/posts/2019-04-06-misleading-while-being-honest.html</guid>
    <dc:creator>Chao Xu</dc:creator>
</item>
<item>
    <title>$L_1$ linear regression</title>
    <link>https://chaoxuprime.com/posts/2019-03-28-l1-linear-regression.html</link>
    <description><![CDATA[<br />
<div>
<p>I read an article on the <a href="https://medium.economist.com/mistakes-weve-drawn-a-few-8cdd8a42d368">errors in visualization</a>. The example of forcing a relationship by cherry-picking scales is delightful. I recommend reading it.</p>
<p>I am interested in misleading people while being completely honest. The article inspires the following problem. Given 2 vectors <span class="math inline">\bm{x},\bm{y}\in \R^n</span>. Let <span class="math inline">\bm{1}</span> be the all <span class="math inline">1</span> vector in <span class="math inline">\R^n</span>. We are interested in finding <span class="math inline">a,b\in \R</span>, such that <span class="math inline">\|\bm{y}-(a\bm{x}+b\bm{1})\|_p</span> is minimized. Here <span class="math inline">p</span> is either <span class="math inline">1,2</span> or <span class="math inline">\infty</span>.</p>
<p>Note the problem is precisely the same as the linear regression problem. In the linear regression problem, we are given a point set <span class="math inline">S\subset \R^2</span> of size <span class="math inline">n</span> and we are interested in find a line <span class="math inline">f(x) = ax+b</span>, such that it minimizes the <em>error</em>, defined as</p>
<p><span class="math display">
\sum_{(x,y)\in S} \|y - f(x)\|_p
</span></p>
<p>For <span class="math inline">p=2</span>, there is a <span class="math inline">O(n)</span> time algorithm because there is a closed formula. For <span class="math inline">p=\infty</span>, the problem can be rewritten as a linear program with <span class="math inline">3</span> variables and <span class="math inline">n</span> constraints. Using Megiddo’s result <span class="citation" data-cites="Megiddo84">[<a href="#ref-Megiddo84" role="doc-biblioref">1</a>]</span>, there is a <span class="math inline">O(n)</span> time algorithm to solve this problem.</p>
<p>It is hard to find the worst case complexity when <span class="math inline">p=1</span>. This case is called the <em>least absolute deviations</em>. Statisticians just don’t care about worst case running time as CS people do.</p>
<p>There are a few methods I found. One is to write it as a linear program on <span class="math inline">n+2</span> variables and <span class="math inline">n</span> constraints and solve it using the simplex method. The linear program is as follows.</p>
<p><span class="math display">
\begin{aligned}
&amp; \min_{a,b,t_1,\ldots,t_n}
&amp; &amp; \sum_{i=1}^n t_i &amp; \\
&amp; \text{s.t.} &amp; &amp;  t_i \geq (ax_i+b)-y_i &amp; \forall 1 \leq i \leq n \\
&amp; &amp; &amp;  t_i \leq y_i-(ax_i+b) &amp; \forall 1 \leq i \leq n \\
\end{aligned}
</span></p>
<p>There are a bunch of other algorithms that specializes the simplex algorithm on this particular problem. There are also some iterative methods. Unfortunately, those algorithms depends on the actual numbers in the input. I want a running time that only depends on <span class="math inline">n</span>.</p>
<p>There exists an optimal solution that contains two points in <span class="math inline">S</span>. The native algorithm is to try all possible <span class="math inline">O(n^2)</span> lines. For each line, the algorithm can compute the error in <span class="math inline">O(n)</span> time. The naive algorithm’s running time is <span class="math inline">O(n^3)</span>. There is a smarter algorithm. The optimal line that contains the point can actually be found in <span class="math inline">O(n)</span> time. Indeed, consider the line passes through the point <span class="math inline">(x,y)</span>. We consider changing the slope of the line, while maintaining it still contain <span class="math inline">(x,y)</span>. One can see a minimum will be reached at some line. Indeed, assume we reorder the points, so <span class="math inline">\frac{y_i-y}{x_i-x}\leq \frac{y_{i+1}-y}{x_{i+1}-x}</span> (namely, increasing slope). Let <span class="math inline">k</span> be the smallest integer such that the sum of <span class="math inline">\sum_{i=1}^k |x_i-x|\geq \sum_{i=k+1}^n |x_i-x|</span>. The line determined by <span class="math inline">(x,y)</span> and <span class="math inline">(x_k,y_k)</span> is the desired line. This can be computed in linear time by finding weighted median. Hence one can show the running time is <span class="math inline">O(n^2)</span>. This is the idea of <span class="citation" data-cites="BloomfieldS80">[<a href="#ref-BloomfieldS80" role="doc-biblioref">2</a>]</span>. As far as I know, this seems to be the state of the art in terms of worst case complexity.</p>
<p>After discussing with <a href="https://sites.google.com/site/qizhenghe96/home">Qizheng He</a>, he suggested the following approach. Consider the function <span class="math inline">g_p(s)</span> for <span class="math inline">p\in S</span>. It is defined as the error for the line of slope <span class="math inline">s</span> that contains <span class="math inline">p</span>. The function is bitonic, therefore we can do a ternary search to find the minimum. There are only <span class="math inline">n-1</span> possible slopes, hence the ternary search will take <span class="math inline">O(\log n)</span> queries, where each query asks for the error of the line that goes through <span class="math inline">p</span> and some other point.</p>
<p>Given a line <span class="math inline">f(x)=ax+b</span>, can one compute the error quickly? It is possible to decompose it to few halfspace range counting queries (allowing weights). In halfspace counting queries problem, we are given <span class="math inline">n</span> points with weights, we can preprocess it and obtain a data structure. Each query to a data structure is a halfspace, the output is the sum of all elements in the halfspace. In <span class="math inline">2</span>D, there exists a preprocessing time <span class="math inline">\tilde{O}(n^{4/3})</span> and query time <span class="math inline">\tilde{O}(n^{1/3})</span> data structure <span class="citation" data-cites="Matousek93">[<a href="#ref-Matousek93" role="doc-biblioref">3</a>]</span>. Let <span class="math inline">S^+</span> be the set of points above <span class="math inline">f</span>, and <span class="math inline">S^-</span> be the set of points below <span class="math inline">f</span>. The result is precisely the following.</p>
<p><span class="math display">
\sum_{(x,y)\in S^+} y - ax-b + \sum_{(x,y)\in S^-} ax+b - y
</span></p>
<p>Let’s consider the second sum, <span class="math inline">\sum_{(x,y)\in S^-} ax+b - y = a\sum_{(x,y)\in S^-}x + |S^-|b -\sum_{(x,y)\in S^-}y</span>. Note the <span class="math inline">3</span> terms can each be solved with a halfspace counting query, consider all points lies below <span class="math inline">f</span>. This shows in <span class="math inline">6</span> halfspace counting queries.</p>
<p>How can one do ternary search? This would need us to be able to pick the point that gives us the <span class="math inline">i</span>th largest slope with <span class="math inline">p</span>. We need a data structure such that it can return the <span class="math inline">i</span>th largest point in the radial ordering of the points in <span class="math inline">S</span> around <span class="math inline">p</span>. It is equivalent to <a href="https://cstheory.stackexchange.com/questions/42609/data-structure-for-radial-orderings-of-points-on-the-plane">halfspace range counting up to polylog factors</a>.</p>
<p>Thus, the total running time after building the data structure in <span class="math inline">\tilde{O}(n^{4/3})</span> is <span class="math inline">n</span> times ternary search over <span class="math inline">n</span> elements, where each decision process takes <span class="math inline">\tilde{O}(n^{1/3})</span> time. Therefore the final running time is <span class="math inline">\tilde{O}(n^{4/3})</span> time.</p>
<p>Qizheng mentioned the problem to <a href="http://tmc.web.engr.illinois.edu">Timothy Chan</a>, who gave us some references. There is an easy solution that obtains <span class="math inline">O(n\log^2 n)</span> time algorithm using simple parametric search <span class="citation" data-cites="MegiddoT83">[<a href="#ref-MegiddoT83" role="doc-biblioref">4</a>]</span>. Consider the following linear program. Let <span class="math inline">k</span> be a constant. We are given <span class="math inline">a_1,\ldots,a_k,b_1,\ldots,b_n</span>, <span class="math inline">k</span>D vectors <span class="math inline">\beta_1,\ldots,\beta_m</span> and reals <span class="math inline">\alpha_1,\ldots,\alpha_m</span>. Sets <span class="math inline">J_1,\ldots,J_n</span> a partition of <span class="math inline">[m]</span>.</p>
<p><span class="math display">
\begin{aligned}
&amp; \min_{w_1,\ldots,w_k,x_1,\ldots,x_n}
&amp; &amp; \sum_{i=1}^k a_iw_i + \sum_{i=1}^n b_ix_i &amp; \\
&amp; \text{s.t.} &amp; &amp;  x_i \geq (\sum_{d=1}^k \beta_{j,d} w_d) - \alpha_j &amp; \forall 1 \leq i \leq n, j\in J_i
\end{aligned}
</span></p>
<p>Zemel showed such linear program can be solved in <span class="math inline">O(m)</span> time for constant <span class="math inline">k</span> <span class="citation" data-cites="Zemel84">[<a href="#ref-Zemel84" role="doc-biblioref">5</a>]</span>. The idea is a similar algorithm to Megiddo’s linear time constant dimension LP algorithm <span class="citation" data-cites="Megiddo84">[<a href="#ref-Megiddo84" role="doc-biblioref">1</a>]</span>. For linear regression problem in <span class="math inline">L_1</span> with <span class="math inline">n</span> data points. The linear program we derived is a special case of the above linear program when <span class="math inline">k=2</span> and <span class="math inline">m=O(n)</span>. In fact, Zemel use the same linear program to show constant dimension <span class="math inline">L_1</span> regression can be solved in linear time.</p>
<h1 id="open-problem"><span class="header-section-number">1</span> Open problem</h1>
<p>One can also define another metric, the lexicographical minimum. Such idea was already present in fairness related linear regression <span class="citation" data-cites="KoeppenYO14">[<a href="#ref-KoeppenYO14" role="doc-biblioref">6</a>]</span>. Once we sort the values of <span class="math inline">|y - f(x)|</span> for <span class="math inline">(x,y)\in S</span>, say obtaining <span class="math inline">a_1,\ldots,a_n</span>, where <span class="math inline">a_1\geq a_2 \geq \ldots \geq a_n</span>. We are interested in finding a <span class="math inline">f</span> that minimizes the sequence <span class="math inline">a_1,\ldots,a_n</span>, lexicographically. Can this problem be solved in <span class="math inline">O(n)</span> time?</p>
<h1 id="bibliography" class="unnumbered">References</h1>
<div id="refs" class="references" role="doc-bibliography">
<div id="ref-Megiddo84">
<p>[1] N. Megiddo, <strong>Linear programming in linear time when the dimension is fixed</strong>, J. ACM. 31 (1984) 114–127 <a href="https://doi.org/10.1145/2422.322418">10.1145/2422.322418</a>.</p>
</div>
<div id="ref-BloomfieldS80">
<p>[2] P. Bloomfield, W. Steiger, <strong>Least absolute deviations curve-fitting</strong>, SIAM Journal on Scientific and Statistical Computing. 1 (1980) 290–301 <a href="https://doi.org/10.1137/0901019">10.1137/0901019</a>.</p>
</div>
<div id="ref-Matousek93">
<p>[3] J. Matoušek, <strong>Range searching with efficient hierarchical cuttings</strong>, Discrete &amp; Computational Geometry. 10 (1993) 157–182 <a href="https://doi.org/10.1007/BF02573972">10.1007/BF02573972</a>.</p>
</div>
<div id="ref-MegiddoT83">
<p>[4] N. Megiddo, A. Tamir, <strong>Finding Least-Distances Lines</strong>, SIAM Journal on Algebraic Discrete Methods. 4 (1983) 207–211 <a href="https://doi.org/10.1137/0604021">10.1137/0604021</a>.</p>
</div>
<div id="ref-Zemel84">
<p>[5] E. Zemel, <strong>An O(n) algorithm for the linear multiple choice knapsack problem and related problems</strong>, 18 (1984) 123–128 <a href="https://doi.org/10.1016/0020-0190(84)90014-0">10.1016/0020-0190(84)90014-0</a>.</p>
</div>
<div id="ref-KoeppenYO14">
<p>[6] M. Köeppen, K. Yoshida, K. Ohnishi, Evolving fair linear regression for the representation of human-drawn regression lines, in: 2014 International Conference on Intelligent Networking and Collaborative Systems, 2014: pp. 296–303 <a href="https://doi.org/10.1109/INCoS.2014.89">10.1109/INCoS.2014.89</a>.</p>
</div>
</div>
</div>
<div class="hide-on-print">
    <div class="info">Posted by <a href="https://chaoxuprime.com">Chao Xu</a> on <time datetime="2019-03-28">2019-03-28</time>. </div>
    <div class="info">Tags: combinatorial optimization.</div>
</div>]]></description>
    <pubDate>Thu, 28 Mar 2019 00:00:00 UT</pubDate>
    <guid>https://chaoxuprime.com/posts/2019-03-28-l1-linear-regression.html</guid>
    <dc:creator>Chao Xu</dc:creator>
</item>

    </channel>
</rss>
